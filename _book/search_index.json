[["index.html", "CSDE 502 Winter 2021 Introduction Course logistics", " CSDE 502 Winter 2021 Phil Hurvitz 2021-03-06 12:23 Introduction This is the main workbook for CSDE 502 for Winter 2021. It will contain or link to all lecture notes, code examples, exercises, and assignments. Assignment answer keys will be provided in a separate location accessible only to currently enrolled CSDE 502 students. The course syllabus is available as a PDF: csde502_syllabus_2021.pdf. Course logistics Class meetings All class meetings will happen over Zoom. The Zoom link for this course is https://washington.zoom.us/j/93089524851. Please join the class promptly at the scheduled time (Fridays at 10:30 AM). About halfway through the class session there will be a 10-minute break. Class meetings will follow the structure: Addressing any outstanding issues from previous sessions or assignments. A brief lecture to introduce the topics of the day. A hands-on instructional session. Overview/clarification of assignment. Canvas The course has a Canvas site: CSDE 502 A Wi 21: Population Studies Proseminar. The site will be used primarily for posting and collecting assignments and returning reviewed assignments. Computing All computing for this course should be done on CSDE Terminal Servers (TS). Those students that already have TS access (e.g., CSDE trainees) should be able to use their existing TS1, TS2, or TS3 accounts, but are encouraged to use TS4 for this course so that we will all be using the same environment. More recent student CSDE computing accounts for the general UW student population will use TS4 (csde-ts4.csde.washington.edu). Most students have computers capable of running R and handling relatively large data sets. However, using a common computing environment will help us avoid some of the problems associated with running the same code on different machines that have different processors, RAM, graphics cards, R versions, etc. This will aid in troubleshooting any problems that arise. In order to get access to the CSDE Terminal Servers, see CSDE Computing Accounts. All students at UW who pay the Student Technology Fee are elgible to obtain CSDE computing accounts. For information about the CSDE Terminal Servers, see Choosing a Terminal Server. For instructions on connecting to a Terminal Server, see Computing tutorials. In order to make remote connections to TS4, you will need a remote desktop protocol (RDP) client. Windows has a built-in &quot;Remote Desktop&quot; application. The same is available for Macs at the Apple Store. Windows users may also want to use mRemoteNG, which I find to be a bit more full-featured than the built-in Windows application. For example, mRemoteNG can have any window size, whereas the Windows RDP application has fixed size that must be specified at the time of connection. Linux users are likely to have problems establishing stable RDP connections, although Remmina might work. In addition to the RDP client, in order to access any of CSDE's computing resources, it is necessary to install and enable Husky OnNet, the UW virtual private network (VPN) client. Instructions are available at Download and use Husky OnNet Assignments Each week there will be an assignment made available at 12:00 on the day of class meetings. The assignments are designed to allow students to practice the skills introduced in class sessions. Assignments are due at 09:00 AM on the week following when the assignment was distributed. See the syllabus for additional details. Source code for this document Each of the pages in this book will have a section at the bottom including the source code for the page. --- title: &quot;CSDE 502 Winter 2021&quot; author: &quot;[Phil Hurvitz](https://csde.washington.edu/staff/phil-hurvitz/)&quot; date: &#39;`r format(Sys.time(), &quot;%Y-%m-%d %H:%M&quot;)`&#39; site: bookdown::bookdown_site output: bookdown::gitbook documentclass: book bibliography: [book.bib, packages.bib] biblio-style: apalike link-citations: yes github-repo: rstudio/bookdown-demo description: &quot;These are the class notes and assignments for CSDE 502.&quot; --- # Introduction {-} This is the main workbook for CSDE 502 for Winter 2021. It will contain or link to all lecture notes, code examples, exercises, and assignments. Assignment answer keys will be provided in a separate location accessible only to currently enrolled CSDE 502 students. The course syllabus is available as a PDF: [csde502_syllabus_2021.pdf](csde502_syllabus_2021.pdf). ## Course logistics {-} ### Class meetings {-} All class meetings will happen over Zoom. The Zoom link for this course is [https://washington.zoom.us/j/93089524851](https://washington.zoom.us/j/93089524851). Please join the class promptly at the scheduled time (Fridays at 10:30 AM). About halfway through the class session there will be a 10-minute break. Class meetings will follow the structure: 1. Addressing any outstanding issues from previous sessions or assignments. 1. A brief lecture to introduce the topics of the day. 1. A hands-on instructional session. 1. Overview/clarification of assignment. ### Canvas {-} The course has a Canvas site: [CSDE 502 A Wi 21: Population Studies Proseminar](https://canvas.uw.edu/courses/1434040). The site will be used primarily for posting and collecting assignments and returning reviewed assignments. ### Computing {-} All computing for this course should be done on CSDE Terminal Servers (TS). Those students that already have TS access (e.g., CSDE trainees) should be able to use their existing TS1, TS2, or TS3 accounts, but are encouraged to use TS4 for this course so that we will all be using the same environment. More recent student CSDE computing accounts for the general UW student population will use TS4 (csde-ts4.csde.washington.edu). Most students have computers capable of running R and handling relatively large data sets. However, using a common computing environment will help us avoid some of the problems associated with running the same code on different machines that have different processors, RAM, graphics cards, R versions, etc. This will aid in troubleshooting any problems that arise. In order to get access to the CSDE Terminal Servers, see [CSDE Computing Accounts](https://csde.washington.edu/computing/accounts/). All students at UW who pay the [Student Technology Fee](https://uwstf.org/) are elgible to obtain CSDE computing accounts. For information about the CSDE Terminal Servers, see [Choosing a Terminal Server](https://csde.washington.edu/computing/resources/#TerminalServerChoosing). For instructions on connecting to a Terminal Server, see [Computing tutorials](https://csde.washington.edu/computing/tutorials/). In order to make remote connections to TS4, you will need a remote desktop protocol (RDP) client. Windows has a built-in &quot;Remote Desktop&quot; application. The same is available for Macs at the Apple Store. Windows users may also want to use [mRemoteNG](https://mremoteng.org/), which I find to be a bit more full-featured than the built-in Windows application. For example, mRemoteNG can have any window size, whereas the Windows RDP application has fixed size that must be specified at the time of connection. Linux users are likely to have problems establishing stable RDP connections, although [Remmina](https://sourceforge.net/projects/remmina/) might work. In addition to the RDP client, in order to access any of CSDE&#39;s computing resources, it is necessary to install and enable Husky OnNet, the UW virtual private network (VPN) client. Instructions are available at [Download and use Husky OnNet](https://itconnect.uw.edu/connect/uw-networks/about-husky-onnet/use-husky-onnet/) ### Assignments {-} Each week there will be an assignment made available at 12:00 on the day of class meetings. The assignments are designed to allow students to practice the skills introduced in class sessions. Assignments are due at 09:00 AM on the week following when the assignment was distributed. See the [syllabus](csde502_syllabus_2021.pdf) for additional details. &lt;h4&gt;Source code for this document&lt;/h4&gt; Each of the pages in this book will have a section at the bottom including the source code for the page. ```{r, comment=&#39;&#39;, echo=FALSE} cat(readLines(&quot;index.Rmd&quot;), sep = &#39;\\n&#39;) ``` "],["week1.html", "1 Week 1 1.1 Getting started on Terminal Server 4 1.2 Introduction to R Markdown in RStudio 1.3 File systems", " 1 Week 1 Topics: Getting started; Introduction to R/RStudio/RMarkdown; file systems 1.1 Getting started on Terminal Server 4 First, make sure you have the Husky OnNet VPN application running and have connected to the UW network. You should see the f5 icon in your task area: Connect to TS4: csde-ts4.csde.washington.edu If you are using the Windows Remote Desktop Protocol (RDP) connection, your connection parameters should look like this: If you are using mRemoteNG, the connection parameters will match this: Once you are connected you should see a number of icons on the desktop and application shortcuts in the Start area. Open a Windows Explorer (if you are running RDP in full screen mode you should be able to use the key combination Win-E). Before doing anything, let's change some of the annoying default settings of the Windows Explorer. Tap File &gt; Options. In the View tab, make sure that Always show menus is checked and Hide extensions for known file types is unchecked. The latter setting is very important because we want to see the complete file name for all files at all times. Click Apply to Folders so that these settings become default. Click Yes to the next dialog. Now let's make a folder for the files in this course. Navigate to This PC: You should see the H: drive. This is is the mapped drive that links to your U Drive, and is the place where all of the data for this course is to be stored. Do not store any data on the C: drive! The C: drive can be wiped without any prior notification. Be very careful with your files on the U Drive! If you delete files, there is no &quot;undo&quot; functionality. When you are deleting files, you will get a warning that you should take seriously: Navigate into H: and create a new folder named csde502_winter_2021. Note the use of lowercase letters and underscores rather than spaces. This will be discussed in the section on file systems later in this lesson. 1.2 Introduction to R Markdown in RStudio 1.2.1 Create a project Now we will use RStudio to create the first R Markdown source file and render it to HTML. Start RStudio by either dbl-clicking the desktop shortcut or navigating to the alphabetical R section of the Start menu: Create a new project (File &gt; New Project...). Since we just created the directory to house the project, select Existing Directory. Navigate to that directory and select Open. Click Create Project. You will now have a blank project with only the project file. 1.2.2 Create an R Markdown file from built-in RStudio functionality Let's make an R Markdown file (File &gt; New File &gt; R Markdown...). Do not change any of the metadata ... this is just for a quick example. Click OK and then name the file week_01.Rmd. 1.2.2.1 Render the Rmd file as HTML At the console prompt, enter rmarkdown::render(&quot;W and tap the TAB key. This should bring up a list of files that have the character &quot;w&quot; in the file name. Click week_01.Rmd. The syntax here means &quot;run the render() function from the rmarkdown package on the file week_01.Rmd&quot; After a few moments, the process should complete with a message that the output has been created. You should see week_01.html in the list of files. Click it and select View in Web Browser. You will now see the bare-bones HTML file. Compare the output of this file with the source code in week_01.Rmd. Note there are section headers that begin with hash marks, and R code is indicated with the starting characters ```{r} and the ending characters ``` Next, we will explore some enhancements to the basic R Markdown syntax. 1.2.3 Create an R Markdown file with some enhancements Download this version of week_01.Rmd and overwrite the version you just created. If RStudio prints a message that some packages are required but are not installed, click Install. Change line 3 to include your name and e-mail address. 1.2.3.1 Render and view the enhanced output Repeat the rendering process (rmarkdown::render(&quot;Week_01.Rmd&quot;)) The new HTML file has a number of enhancements, including a table of contents at the upper left, a table that is easier to read, a Leaflet map, captions and cross-references for the figures and table, an image derived from a PNG file referenced by a URL, the code used to generate various parts of the document that are produced by R code, and the complete source code for the document. A dowbnloadable version of the rendered file: week_01.html. Including the source code for the document is especially useful for readers of your documents because it lets them see exactly what you did. An entire research chain can be documented in this way, from reading in raw data, performing data cleaning and analysis, and generating results. 1.3 File systems Although a full treatment of effective uses of file systems is beyond the scope of this course, a few basic rules are worth covering: Never use spaces in folder or file names. Ninety-nine and 44/100ths percent of the time, most modern software will have no problems handling file names with spaces. But that 0.56% of the time when software chokes, you may wonder why your processes are failing. If your directly and file names do not have spaces, then you can at least rule that out! Use lowercase letters in directory and file names. In the olden days (DOS), there was not case sensitivity in file names. UNIX has has always used case sensitive file names. So MyGloriousPhDDissertation.tex and mygloriousphddissertation.tex could actually be different files. Macs, being based on a UNIX kernel, also employ case sensitivity in file names. But Windows? No. Consider the following: there cannot be both foo.txt and FOO.txt in the same directory. So if Windows doesn't care, why should we? Save yourself some keyboarding time and confusion by using only lowercase characters in your file names. Include dates in your file names. If you expect to have multiple files that are sequential versions of a file in progress, an alternative to using a content management system such as git, particularly for binary files such as Word documents or SAS data files, is to have multiple versions of the files but including the date as part of the file name. If you expect to have multiple versions on the same date, include a lowercase alphabetical character; it is improbable that you would have more than 26 versions of a fine on a single calendar date. If you are paranoid, use a suffix number 0000, 0002 .. 9999. If you have ten thousand versions of the same file on a given date, you are probably doing something that is not right. Now that you are convinced that including dates in file names is a good idea, please use the format yyyy-mm-dd or yyyymmdd. If you do so, your file names will sort in temporal order. Make use of directories! Although a folder containing 100,000 files can be handled programatically (if file naming conventions are used), it is not possible for a human being to visually scan 100,000 file names. If you have a lot of files for your project, consider creating directories, e.g., raw_data processed_data analysis_results scripts manuscript Agonize over file names. Optimally when you look at your file names, you will be able to know something about the content of the file. We spend a lot of time doing analysis and creating output. Spending an extra minute thinking about good file names is time well spent. Source code for this document 01-week01.Rmd # Week 1 {#week1} ```{r, echo=FALSE} library(knitr) library(kableExtra) ``` &lt;h2&gt;Topics: Getting started; Introduction to R/RStudio/RMarkdown; file systems&lt;/h2&gt; ## Getting started on Terminal Server 4 First, make sure you have the Husky OnNet VPN application running and have connected to the UW network. You should see the f5 icon in your task area: ![](images/week01/2021-01-07_21_40_25-.png) Connect to TS4: `csde-ts4.csde.washington.edu` If you are using the Windows Remote Desktop Protocol (RDP) connection, your connection parameters should look like this: ![](images/week01/2021-01-07_21_48_03-Remote Desktop Connection.png) If you are using mRemoteNG, the connection parameters will match this: ![](images/week01/2021-01-07_21_37_36-Window.png) Once you are connected you should see a number of icons on the desktop and application shortcuts in the Start area. ![](images/week01/2021-01-07_21_59_38-.png) ![](images/week01/2021-01-07_22_00_14-Window.png) Open a Windows Explorer (if you are running RDP in full screen mode you should be able to use the key combination Win-E). Before doing anything, let&#39;s change some of the annoying default settings of the Windows Explorer. Tap `File &gt; Options`. In the `View` tab, make sure that `Always show menus` is checked and `Hide extensions for known file types` is unchecked. The latter setting is very important because we want to see the complete file name for all files at all times. ![](images/week01/2021-01-07_22_30_46-Folder_Options.png) Click `Apply to Folders` so that these settings become default. Click `Yes` to the next dialog. ![](images/week01/2021-01-07_22_31_37-FolderViews.png) Now let&#39;s make a folder for the files in this course. Navigate to This PC: ![](images/week01/2021-01-07_22_05_59-Window.png) You should see the `H:` drive. This is is the mapped drive that links to your [U Drive](https://itconnect.uw.edu/wares/online-storage/u-drive-central-file-storage-for-users/), and is the place where all of the data for this course is to be stored. __Do not store any data on the `C:` drive!__ The `C:` drive can be wiped without any prior notification. __Be very careful with your files on the U Drive!__ If you delete files, there is no &quot;undo&quot; functionality. When you are deleting files, you will get a warning that you should take seriously: ![](images/week01/2021-01-07_23_01_10-Delete_Folder.png) Navigate into `H:` and create a new folder named `csde502_winter_2021`. Note the use of lowercase letters and underscores rather than spaces. This will be discussed in the section on file systems later in this lesson. ![](images/week01/2021-01-07_22_32_29-new_folder.png) ## Introduction to R Markdown in RStudio ### Create a project Now we will use RStudio to create the first R Markdown source file and render it to HTML. Start RStudio by either dbl-clicking the desktop shortcut or navigating to the alphabetical R section of the Start menu: ![](images/week01/2021-01-07_23_05_49-Window.png) Create a new project (`File &gt; New Project...`). ![](images/week01/2021-01-07_23_08_34-rstudiorappbroker.csde.washington.edu.png) Since we just created the directory to house the project, select `Existing Directory`. ![](images/week01/2021-01-07_23_09_11-csde502_winter_2021_course-RStudiorappbroker.csde.washington.edu.png) Navigate to that directory and select `Open`. ![](images/week01/2021-01-07_23_09_48-ChooseDirectoryrappbroker.csde.washington.edu.png) Click `Create Project`. ![](images/week01/2021-01-07_23_10_02-csde502_winter_2021_course-RStudiorappbroker.csde.washington.edu.png) You will now have a blank project with only the project file. ![](images/week01/2021-01-07_23_11_16-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png) ### Create an R Markdown file from built-in RStudio functionality Let&#39;s make an R Markdown file (`File &gt; New File &gt; R Markdown...`). ![](images/week01/2021-01-07_23_12_31-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png) Do not change any of the metadata ... this is just for a quick example. ![](images/week01/2021-01-07_23_13_41-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png) Click `OK` and then name the file `week_01.Rmd`. ![](images/week01/2021-01-07_23_14_59-SaveFile-Untitled1rappbroker.csde.washington.edu.png) #### Render the Rmd file as HTML At the console prompt, enter `rmarkdown::render(&quot;W` and tap the `TAB` key. This should bring up a list of files that have the character &quot;w&quot; in the file name. Click `week_01.Rmd`. The syntax here means &quot;run the `render()` function from the `rmarkdown` package on the file `week_01.Rmd`&quot; ![](images/week01/2021-01-07_23_15_32-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png) After a few moments, the process should complete with a message that the output has been created. ![](images/week01/2021-01-07_23_16_13-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png) You should see `week_01.html` in the list of files. Click it and select `View in Web Browser`. ![](images/week01/2021-01-07_23_16_39-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png) You will now see the bare-bones HTML file. ![](images/week01/2021-01-07_23_17_10-Untitled.png) Compare the output of this file with the source code in `week_01.Rmd`. Note there are section headers that begin with hash marks, and R code is indicated with the starting characters &lt;code&gt; \\`\\`\\`\\{r\\} &lt;/code&gt; and the ending characters &lt;code&gt; \\`\\`\\` &lt;/code&gt; Next, we will explore some enhancements to the basic R Markdown syntax. ### Create an R Markdown file with some enhancements Download this version of [`week_01.Rmd`](files/week_01.Rmd) and overwrite the version you just created. If RStudio prints a message that some packages are required but are not installed, click `Install`. ![](images/week01/2021-01-07_23_26_55-csde502_winter_2021-RStudiorappbroker.csde.washington.edu.png) Change line 3 to include your name and e-mail address. ![](images/week01/2021-01-08_00_35_18-Window.png) #### Render and view the enhanced output Repeat the rendering process (`rmarkdown::render(&quot;Week_01.Rmd&quot;)`) The new HTML file has a number of enhancements, including a table of contents at the upper left, a table that is easier to read, a Leaflet map, captions and cross-references for the figures and table, an image derived from a PNG file referenced by a URL, the code used to generate various parts of the document that are produced by R code, and the complete source code for the document. A dowbnloadable version of the rendered file: [week_01.html](files/week_01.html). ![](images/week01/2021-01-08_00_19_27-Week01.png) Including the source code for the document is especially useful for readers of your documents because it lets them see exactly what you did. An entire research chain can be documented in this way, from reading in raw data, performing data cleaning and analysis, and generating results. ## File systems Although a full treatment of effective uses of file systems is beyond the scope of this course, a few basic rules are worth covering: 1. Never use spaces in folder or file names. Ninety-nine and 44/100ths percent of the time, most modern software will have no problems handling file names with spaces. But that 0.56% of the time when software chokes, you may wonder why your processes are failing. If your directly and file names do not have spaces, then you can at least rule that out! 1. Use lowercase letters in directory and file names. In the olden days (DOS), there was not case sensitivity in file names. UNIX has has always used case sensitive file names. So `MyGloriousPhDDissertation.tex` and `mygloriousphddissertation.tex` could actually be different files. Macs, being based on a UNIX kernel, also employ case sensitivity in file names. But Windows? No. Consider the following: there cannot be both `foo.txt` and `FOO.txt` in the same directory. ![](images/week01/2021-01-08_01_13_50-CommandPrompt.png) So if Windows doesn&#39;t care, why should we? Save yourself some keyboarding time and confusion by using only lowercase characters in your file names. 1. Include dates in your file names. If you expect to have multiple files that are sequential versions of a file in progress, an alternative to using a content management system such as [git](https://git-scm.com/), particularly for binary files such as Word documents or SAS data files, is to have multiple versions of the files but including the date as part of the file name. If you expect to have multiple versions on the same date, include a lowercase alphabetical character; it is improbable that you would have more than 26 versions of a fine on a single calendar date. If you are paranoid, use a suffix number `0000`, `0002` .. `9999`. If you have ten thousand versions of the same file on a given date, you are probably doing something that is not right. Now that you are convinced that including dates in file names is a good idea, _please_ use the format `yyyy-mm-dd` or `yyyymmdd`. If you do so, your file names will sort in temporal order. 1. Make use of directories! Although a folder containing 100,000 files can be handled programatically (if file naming conventions are used), it is not possible for a human being to visually scan 100,000 file names. If you have a lot of files for your project, consider creating directories, e.g., - raw_data - processed_data - analysis_results - scripts - manuscript 1. Agonize over file names. Optimally when you look at your file names, you will be able to know something about the content of the file. We spend a lot of time doing analysis and creating output. Spending an extra minute thinking about good file names is time well spent. &lt;h4&gt;Source code for this document&lt;/h4&gt; [01-week01.Rmd](01-week01.Rmd) ```{r, comment=&#39;&#39;, echo=FALSE} cat(readLines(&quot;01-week01.Rmd&quot;), sep = &#39;\\n&#39;) ``` "],["week2.html", "2 Week 2 2.1 Code to run for the in-class exercise 2.2 R data types 2.3 R data structures 2.4 tidyverse", " 2 Week 2 Topics: R data structures; tidyverse It is assumed that students in this course have a basic working knowledge of using R, including how to create variables with the assignment operator (&quot;&lt;-&quot;), and how to run simple functions(e.g., mean(dat$age)). Often in courses that include using R for statistical analysis, some of the following foundations are not explained fully. This is not intended to be a comprehensive treatment of R data types and structures, but should provide some background for students who are either relatively new at using R or who have not had a systematic introduction. The other main topic for today is &quot;tidyverse&quot;, which refers to a related set of R packages for data management, analysis, and display. See Hadley Wickham's tidy tools manifesto for the logic behind the suite of tools. For a brief description of the specific R packages, see Tidyverse packages. This is not intended to be a comprehensive introduction, but should provide sufficient background for data handling to support most of the technical aspects of the rest of the course. 2.1 Code to run for the in-class exercise For the exercise in class, download week02.R, which we will use to run the code listed in this R Markdown result. 2.2 R data types There are six fundamental data types in R: logical numeric integer complex character raw The most atomic object in R will exist having one of those data types, described below. An atomic object of the data type can have a value, NA which represents an observation with no data (e.g., a missing measurement), or NULL which isn't really a value at all, but can still have the data type class. You will encounter other data types, such as Date or POSIXct if you are working with dates or time stamps. These other data types are extensions of the fundamental data types. To determine what data type an object is, use is(obj), str(obj), or class(obj). print(is(&quot;a&quot;)) ## [1] &quot;character&quot; &quot;vector&quot; &quot;data.frameRowLabels&quot; &quot;SuperClassMethod&quot; print(str(TRUE)) ## logi TRUE ## NULL print(class(123.45)) ## [1] &quot;numeric&quot; print(class(as.integer(1000))) ## [1] &quot;integer&quot; n &lt;- as.numeric(999999999999999999999) print(class(n)) ## [1] &quot;numeric&quot; 2.2.1 Logical Use logical values for characteristics that are either TRUE or FALSE. Note that if logical elements can also have an NA value if the observation is missing. In the following examples, # evaluate as logical, test whether 1 is greater than two a &lt;- 1 &gt; 2 # create two numerical values, one being NA, representing ages age_john &lt;- 39 age_jane &lt;- NA # logical NA from Jane&#39;s undefined age (jo &lt;- age_john &gt; 50) ## [1] FALSE (ja &lt;- age_jane &gt; 50) ## [1] NA Logical values are often expressed in binary format as 0 = FALSE and =TRUE`. in R these values are interconvertible. Other software (e.g., Excel, MS Access) may convert logical values to numbers that you do not expect. (t &lt;- as.logical(1)) ## [1] TRUE (f &lt;- as.logical(0)) ## [1] FALSE 2.2.2 Numeric Numeric values are numbers with range about 2e-308 to 2e+308, depending on the computer you are using. You can see the possible range by entering .Machine at the R console. These can also include decimals. For more information, see Double-precision floating-point format 2.2.3 Integer Integer values are numerical, but can only take on whole, rather than fractional values, and have a truncated range compared to numeric. For example, see below, if we try to create an integer that is out of range. The object we created is an integer, but because it is out of range, is value is set to NA. i &lt;- as.integer(999999999999999999999) ## Warning: NAs introduced by coercion to integer range print(class(i)) ## [1] &quot;integer&quot; 2.2.4 Complex The complex type is used in mathematics and you are unlikely to use it in applied social science research unless you get into some heavy statistics. See Complex number for a full treatment. 2.2.5 Character Character data include the full set of keys on your keyboard that print out a character, typically [A-Z], [a-z], [0-9], punctuation, etc. The full set of ASCII characters is supported, e.g. the accent aigu in Café: print(class(&quot;Café&quot;)) ## [1] &quot;character&quot; Also numbers can function as characters. Be careful in converting between numerical and character versions. For example, see these ZIP codes: # this is a character my_zip &lt;- &quot;98115&quot; # it is not numeric. my_zip + 2 ## Error in my_zip + 2: non-numeric argument to binary operator # we can convert it to numeric, although it would be silly to do with ZIP codes, which are nominal values as.numeric(my_zip) + 2 ## [1] 98117 # Boston has ZIP codes starting with zeros boston_zip &lt;- &quot;02134&quot; as.numeric(boston_zip) ## [1] 2134 2.2.6 Raw Raw values are used to store raw bytes in hexadecimal format. You are unlikely to use it in applied social science research. For example, the hexadecimal value for the character z is 7a: print(charToRaw(&quot;z&quot;)) ## [1] 7a class(charToRaw(&quot;z&quot;)) ## [1] &quot;raw&quot; 2.3 R data structures There are 5 basic data structures in R, as shown in the graphic: vector matrix array list data frame In addition, the factor data type is very important 2.3.1 Vector A vector is an ordered set of elements of one or more elements of the same data type and are created using the c() constructor function. For example, a single value is a vector: # create a vector of length 1 a &lt;- 1 is(a) ## [1] &quot;numeric&quot; &quot;vector&quot; If you try creating a vector with mixed data types, you may get unexpected results; mixing character elements with other type elements will result in character representations, e.g., c(1, &quot;a&quot;, TRUE, charToRaw(&quot;z&quot;)) ## [1] &quot;1&quot; &quot;a&quot; &quot;TRUE&quot; &quot;7a&quot; Results will depend on the data type you are mixing, for example because logical values can be expressed numerically, the TRUE and FALSE values are converted to 1 and 0, respectively. (c(1:3, TRUE, FALSE)) ## [1] 1 2 3 1 0 But if a character is added, all elements are converted to characters. c(1:3, TRUE, FALSE, &quot;awesome!&quot;) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;TRUE&quot; &quot;FALSE&quot; &quot;awesome!&quot; Order is important, i.e., 1, 2, 3 is not the same as 1, 3, 2 R will maintain the order of elements in vectors unless a process is initiated that changes the order of those elements: # a vector (v &lt;- c(1, 3, 2)) ## [1] 1 3 2 (sort(v)) ## [1] 1 2 3 You can get some information about vectors, such as length and data type: # create a random normal set.seed(5) normvec1000 &lt;- rnorm(n = 1000) length(normvec1000) ## [1] 1000 class(normvec1000) ## [1] &quot;numeric&quot; class(normvec1000 &gt; 1) ## [1] &quot;logical&quot; Elements of vectors are specified with their index number (1 .. n): v &lt;- seq(from = 0, to = 10, by = 2) v[4] ## [1] 6 2.3.2 Matrix A matrix is like a vector, in that it an contain only one data type, but it is two-dimensional, having rows and columns. A simple example: # make a vector 1 to 100 (v &lt;- 1:100) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ## [28] 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ## [55] 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 ## [82] 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 # load to a matrix (m1 &lt;- matrix(v, ncol = 10, byrow = TRUE)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10 ## [2,] 11 12 13 14 15 16 17 18 19 20 ## [3,] 21 22 23 24 25 26 27 28 29 30 ## [4,] 31 32 33 34 35 36 37 38 39 40 ## [5,] 41 42 43 44 45 46 47 48 49 50 ## [6,] 51 52 53 54 55 56 57 58 59 60 ## [7,] 61 62 63 64 65 66 67 68 69 70 ## [8,] 71 72 73 74 75 76 77 78 79 80 ## [9,] 81 82 83 84 85 86 87 88 89 90 ## [10,] 91 92 93 94 95 96 97 98 99 100 # different r, c ordering (m2 &lt;- matrix(v, ncol = 10, byrow = FALSE)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 11 21 31 41 51 61 71 81 91 ## [2,] 2 12 22 32 42 52 62 72 82 92 ## [3,] 3 13 23 33 43 53 63 73 83 93 ## [4,] 4 14 24 34 44 54 64 74 84 94 ## [5,] 5 15 25 35 45 55 65 75 85 95 ## [6,] 6 16 26 36 46 56 66 76 86 96 ## [7,] 7 17 27 37 47 57 67 77 87 97 ## [8,] 8 18 28 38 48 58 68 78 88 98 ## [9,] 9 19 29 39 49 59 69 79 89 99 ## [10,] 10 20 30 40 50 60 70 80 90 100 If you try to force a vector into a matrix whose row \\(\\times\\) col length does not match the length of the vector, the elements will be recycled, which may not be what you want. At least R will give you a warning. (m3 &lt;- matrix(letters, ncol = 10, nrow = 10)) ## Warning in matrix(letters, ncol = 10, nrow = 10): data length [26] is not a sub-multiple or multiple of the number ## of rows [10] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] &quot;a&quot; &quot;k&quot; &quot;u&quot; &quot;e&quot; &quot;o&quot; &quot;y&quot; &quot;i&quot; &quot;s&quot; &quot;c&quot; &quot;m&quot; ## [2,] &quot;b&quot; &quot;l&quot; &quot;v&quot; &quot;f&quot; &quot;p&quot; &quot;z&quot; &quot;j&quot; &quot;t&quot; &quot;d&quot; &quot;n&quot; ## [3,] &quot;c&quot; &quot;m&quot; &quot;w&quot; &quot;g&quot; &quot;q&quot; &quot;a&quot; &quot;k&quot; &quot;u&quot; &quot;e&quot; &quot;o&quot; ## [4,] &quot;d&quot; &quot;n&quot; &quot;x&quot; &quot;h&quot; &quot;r&quot; &quot;b&quot; &quot;l&quot; &quot;v&quot; &quot;f&quot; &quot;p&quot; ## [5,] &quot;e&quot; &quot;o&quot; &quot;y&quot; &quot;i&quot; &quot;s&quot; &quot;c&quot; &quot;m&quot; &quot;w&quot; &quot;g&quot; &quot;q&quot; ## [6,] &quot;f&quot; &quot;p&quot; &quot;z&quot; &quot;j&quot; &quot;t&quot; &quot;d&quot; &quot;n&quot; &quot;x&quot; &quot;h&quot; &quot;r&quot; ## [7,] &quot;g&quot; &quot;q&quot; &quot;a&quot; &quot;k&quot; &quot;u&quot; &quot;e&quot; &quot;o&quot; &quot;y&quot; &quot;i&quot; &quot;s&quot; ## [8,] &quot;h&quot; &quot;r&quot; &quot;b&quot; &quot;l&quot; &quot;v&quot; &quot;f&quot; &quot;p&quot; &quot;z&quot; &quot;j&quot; &quot;t&quot; ## [9,] &quot;i&quot; &quot;s&quot; &quot;c&quot; &quot;m&quot; &quot;w&quot; &quot;g&quot; &quot;q&quot; &quot;a&quot; &quot;k&quot; &quot;u&quot; ## [10,] &quot;j&quot; &quot;t&quot; &quot;d&quot; &quot;n&quot; &quot;x&quot; &quot;h&quot; &quot;r&quot; &quot;b&quot; &quot;l&quot; &quot;v&quot; 2.3.3 Array An array is similar to matrix, but it can have more than one dimension. These can be useful for analyzing time series data or other multidimensional data. We will not be using array data in this course, but a simple example of creating and viewing the contents of an array: # a vector 1 to 27 v &lt;- 1:27 # create an array, 3 x 3 x 3 (a &lt;- array(v, dim = c(3, 3, 3))) ## , , 1 ## ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] 10 13 16 ## [2,] 11 14 17 ## [3,] 12 15 18 ## ## , , 3 ## ## [,1] [,2] [,3] ## [1,] 19 22 25 ## [2,] 20 23 26 ## [3,] 21 24 27 # array index is r, c, m (row, column, matrix), e.g., row 1 column 2 matrix 3: (a[1,2,3]) ## [1] 22 2.3.4 List R lists are ordered collections of objects that do not need to be of the same data type. Those objects can be single-value vectors, multiple-value vectors, matrices, data frames, other lists, etc. Because of this, lists are a very flexible data type. But because they can have as little or as much structure as you want, can become difficult to manage and analyze. Here is an example of a list comprised of single value vectors of different data type. Compare this with the attempt to make a vector comprised of elements of different data type: (l &lt;- list(&quot;a&quot;, 1, TRUE)) ## [[1]] ## [1] &quot;a&quot; ## ## [[2]] ## [1] 1 ## ## [[3]] ## [1] TRUE Let's modify that list a bit: (l &lt;- list(&quot;a&quot;, 1:20, as.logical(c(0,1,1,0)))) ## [[1]] ## [1] &quot;a&quot; ## ## [[2]] ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ## ## [[3]] ## [1] FALSE TRUE TRUE FALSE The top-level indexing for a list is denoted using two sets of square brackets. For example, the first element of our list can be accessed by l[[1]]. For example, the mean of element 2 is obtained by mean(l[[2]]): 10.5. To perform operations on all elements of a list, use lapply(): # show the data types (lapply(X = l, FUN = class)) ## [[1]] ## [1] &quot;character&quot; ## ## [[2]] ## [1] &quot;integer&quot; ## ## [[3]] ## [1] &quot;logical&quot; # mean, maybe? (lapply(X = l, FUN = function(x) {mean(x)})) ## Warning in mean.default(x): argument is not numeric or logical: returning NA ## [[1]] ## [1] NA ## ## [[2]] ## [1] 10.5 ## ## [[3]] ## [1] 0.5 2.3.5 Factor Factors are similar to vectors, in that they are one-dimensional ordered sets. However, factors also use informational labels. For example, you may have a variable with household income as a text value: &quot;&lt;$10,000&quot; &quot;$10,000-$549,999&quot; &quot;$50,000-$99,999&quot; &quot;$100,000-$200,000&quot; &quot;&gt;$200,000&quot; As a vector: (income &lt;- c(&quot;&lt;$10,000&quot; , &quot;$10,000-$49,999&quot; , &quot;$50,000-$99,999&quot; , &quot;$100,000-$200,000&quot; , &quot;&gt;$200,000&quot;)) ## [1] &quot;&lt;$10,000&quot; &quot;$10,000-$49,999&quot; &quot;$50,000-$99,999&quot; &quot;$100,000-$200,000&quot; &quot;&gt;$200,000&quot; Because these are characters, they do not sort in proper numeric order: sort(income) ## [1] &quot;$10,000-$49,999&quot; &quot;$100,000-$200,000&quot; &quot;$50,000-$99,999&quot; &quot;&lt;$10,000&quot; &quot;&gt;$200,000&quot; If these are treated as a factor, the levels can be set for proper ordering: # create a factor from income and set the levels (income_factor &lt;- factor(x = income, levels = income)) ## [1] &lt;$10,000 $10,000-$49,999 $50,000-$99,999 $100,000-$200,000 &gt;$200,000 ## Levels: &lt;$10,000 $10,000-$49,999 $50,000-$99,999 $100,000-$200,000 &gt;$200,000 # sort again (sort(income_factor)) ## [1] &lt;$10,000 $10,000-$49,999 $50,000-$99,999 $100,000-$200,000 &gt;$200,000 ## Levels: &lt;$10,000 $10,000-$49,999 $50,000-$99,999 $100,000-$200,000 &gt;$200,000 As a factor, the data can also be used in statistical models and the magnitude of the variable will also be correctly ordered. 2.3.6 Data frame Other than vectors, data frames are probably the most used data type in R. You can think of data frames as matrices that allow columns with different data type. For example, you might have a data set that represents subject IDs as characters, sex or gender as text, height, weight, and age as numerical values, income as a factor, and smoking status as logical. Because a matrix requires only one data type, it would not be possible to store all of these as a matrix. An example: # income levels inc &lt;- c(&quot;&lt;$10,000&quot; , &quot;$10,000-$49,999&quot; , &quot;$50,000-$99,999&quot; , &quot;$100,000-$200,000&quot; , &quot;&gt;$200,000&quot;) BMI &lt;- data.frame( sid = c(&quot;A1001&quot;, &quot;A1002&quot;, &quot;B1001&quot;), gender = c(&quot;Male&quot;, &quot;Male&quot;,&quot;Female&quot;), height_cm = c(152, 171.5, 165), weight_kg = c(81, 93, 78), age_y = c(42, 38, 26), income = factor(c(&quot;$50,000-$99,999&quot;, &quot;$100,000-$200,000&quot;, &quot;&lt;$10,000&quot;), levels = inc) ) print(BMI) ## sid gender height_cm weight_kg age_y income ## 1 A1001 Male 152.0 81 42 $50,000-$99,999 ## 2 A1002 Male 171.5 93 38 $100,000-$200,000 ## 3 B1001 Female 165.0 78 26 &lt;$10,000 2.4 tidyverse This section will introduce some of the main workhorse functions in tidy data handling. Installing tidyverse is straightforward but it may take some time to download and install all of the packages. Use install.packages(&quot;tidyverse&quot;) For today's lesson we will be using one of the Add Health data sets, AHwave1_v1.dta. # read the dta file dat &lt;- readstata13::read.dta13(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta&quot;) The data set includes variable labels, which make handling the data easier. Here we print the column names and their labels. Wrapping this in a DT::data_table presents a nice interface for showing only a few variables at a time and that allows sorting and searching. x &lt;- data.frame(colname = names(dat), label = attributes(dat)$var.labels) DT::datatable(data = x, caption = &quot;Column names and labels in AHwave1_v1.dta.&quot;) 2.4.1 magrittr The R package magrittr allows the use of &quot;pipes&quot;. In UNIX, pipes were used to take the output of one program and to feed as input to another program. For example, the UNIX command cat prints the contents of a text file. This would print the contents of the file 00README.txt: cat 00README.txt but with large files, the entire contents would scroll by too fast to read. Using a &quot;pipe&quot;, denoted with the vertical bar character | allowed using the more command to print one screen at a time by tapping the Enter key for each screen full of text: cat 00README.txt | more As shown in these two screen captures: The two main pipe operators we will use in magrittr are %&gt;% and '%&lt;&gt;%'. %&gt;% is the pipe operator, which functions as a UNIX pipe, that is, to take something on the left hand side of the operator and feed it to the right hand side. %&lt;&gt;% is the assignment pipe operator, which takes something on the left hand side of the operator, feeds it to the right hand side, and replaces the object on the left-hand side. For a simple example of the pipe, to list only the first 6 lines of a data frame in base R, we use head(), e.g., head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa using a tidy version of this: iris %&gt;% head() ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa In the R base version, we first read head, so we know we will be printing the first 6 elements of something, but we don't know what that &quot;something&quot; is. We have to read ahead to know we are reading the first 6 records of iris. In the tidy version, we start by knowing we are doing something to the data set, after which we know we are printing the first 6 records. In base R functions, the process is evaluated from the inside out. For example, to get the mean sepal length of the setosa species in iris, we would do this: mean(iris[iris$Species == &#39;setosa&#39;, &quot;Sepal.Length&quot;]) ## [1] 5.006 From the inside out, we read that we are making a subset of iris where Species = &quot;setosa&quot;, we are selecting the column &quot;Sepal.Length&quot;, and taking the mean. However, it requires reading from the inside out. For a large set of nested functions, we would have y &lt;- f(g(h((i(x))))), which would require first creating the innermost function (i()) and then working outward. In a tidy approach this would be more like y &lt;- x %&gt;% i() %&gt;% h() %&gt;% g() %&gt;% f()because the first function applied to the data setxisi()`. Revisiting the mean sepal length of setosa irises, example, under a tidy approach we would do this: iris %&gt;% filter(Species == &#39;setosa&#39;) %&gt;% summarise(mean(Sepal.Length)) ## mean(Sepal.Length) ## 1 5.006 Which, read from left to right, translates to &quot;using the iris data frame, make a subset of records where species is setosa, and summarize those records to get the mean value of sepal length.&quot; The tidy version is intended to be easier to write, read, and understand. The command uses the filter() function, which will be described below. 2.4.2 Data subsetting (dplyr) dplyr is the tidyverse R package used most frequently for data manipulation. Selection of records (i.e., subsetting) is done using logical tests to determine what is in the selected set. First we will look at logical tests and then we will cover subsetting rows and columns from data frames. 2.4.2.0.1 Logical tests If elements meet a logical test, they will end up in the selected set. If data frame records have values in variables that meet logical criteria, the records will be selected. Some logical tests are shown below. 2.4.2.0.1.1 ==: equals # numeric tests (1 == 2) ## [1] FALSE (1 == 3 - 2) ## [1] TRUE # character test (actually a factor) (dat$imonth %&gt;% head() %&gt;% str_c(collapse = &quot;, &quot;)) ## [1] &quot;(6) June, (5) May, (6) June, (7) July, (7) July, (6) June&quot; ((dat$imonth == &quot;(6) June&quot;) %&gt;% head()) ## [1] TRUE FALSE TRUE FALSE FALSE TRUE # character test for multiple patterns (dat$imonth %in% c(&quot;(6) June&quot;, &quot;(7) July&quot;) %&gt;% head()) ## [1] TRUE FALSE TRUE TRUE TRUE TRUE 2.4.2.0.1.2 &gt;, &gt;=, &lt;, &lt;=: numeric comparisons 1 &lt; 2 ## [1] TRUE 1 &gt; 2 ## [1] FALSE 1 &lt;= -10:10 ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [19] TRUE TRUE TRUE 1 &gt;= -10:10 ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE ## [19] FALSE FALSE FALSE 2.4.2.0.1.3 !=: not equals 1 != 2 ## [1] TRUE # those of the first 6 days that are not 14 (dat$iday %&gt;% head()) ## [1] 23 5 27 14 14 12 ((dat$iday != 14) %&gt;% head()) ## [1] TRUE TRUE TRUE FALSE FALSE TRUE 2.4.2.0.1.4 !: invert, or &quot;not&quot; Sometimes it is more convenient to negate a single condition rather than enumerating all possible matching conditions. dat$imonth %&gt;% head(20) ## [1] (6) June (5) May (6) June (7) July (7) July (6) June (5) May ## [8] (6) June (6) June (8) August (9) September (5) May (6) June (7) July ## [15] (5) May (5) May (7) July (5) May (8) August (7) July ## 10 Levels: (1) January (4) April (5) May (6) June (7) July (8) August (9) September ... (12) December ((!dat$imonth %in% c(&quot;(6) June&quot;, &quot;(7) July&quot;)) %&gt;% head(20)) ## [1] FALSE TRUE FALSE FALSE FALSE FALSE TRUE FALSE FALSE TRUE TRUE TRUE FALSE FALSE TRUE TRUE FALSE TRUE ## [19] TRUE FALSE 2.4.2.1 Subset rows (filter()) The filter() function creates a subset of records based on a logical test. Logical tests can be combined as &quot;and&quot; statements using the &amp; operator and &quot;or&quot; statements using the | operator. Here we will perform a few filters on a subset of the data. # first 20 records, fist 10 columns dat_sub &lt;- dat[1:20, 1:10] kable(dat_sub, format = &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ## Warning in if (!full_width) {: the condition has length &gt; 1 and only the first element will be used aid imonth iday iyear bio_sex h1gi1m h1gi1y h1gi4 h1gi5a h1gi5b 57100270 June 23 1995 Female October 1977 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57101310 May 5 1995 Female November 1976 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57103171 June 27 1995 Male October 1979 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57103869 July 14 1995 Male January 1977 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57104553 July 14 1995 Female June 1976 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57104649 June 12 1995 Male December 1981 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57104676 May 31 1995 Male October 1983 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57109625 June 7 1995 Male March 1981 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57110897 June 27 1995 Male September 1981 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57111071 August 3 1995 Male June 1981 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57111786 September 7 1995 Male September 1980 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57113943 May 20 1995 Male January 1979 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57116359 June 24 1995 Male April 1980 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57117542 July 11 1995 Male September 1979 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57117997 May 20 1995 Female October 1982 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57118381 May 6 1995 Female October 1982 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57118943 July 19 1995 Female April 1979 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57120005 May 25 1995 Male September 1982 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) 57120046 August 20 1995 Male October 1976 Yes Marked Not marked 57120371 July 20 1995 Female August 1976 No Legitimate skip (not Hispanic) Legitimate skip (not Hispanic) Records from one month: # from May (dat_sub %&gt;% filter(imonth == &quot;(5) May&quot;)) ## aid imonth iday iyear bio_sex h1gi1m h1gi1y h1gi4 h1gi5a ## 1 57101310 (5) May 5 (95) 1995 (2) Female (11) November (76) 1976 (0) No (7) Legitimate skip (not Hispanic) ## 2 57104676 (5) May 31 (95) 1995 (1) Male (10) October (83) 1983 (0) No (7) Legitimate skip (not Hispanic) ## 3 57113943 (5) May 20 (95) 1995 (1) Male (1) January (79) 1979 (0) No (7) Legitimate skip (not Hispanic) ## 4 57117997 (5) May 20 (95) 1995 (2) Female (10) October (82) 1982 (0) No (7) Legitimate skip (not Hispanic) ## 5 57118381 (5) May 6 (95) 1995 (2) Female (10) October (82) 1982 (0) No (7) Legitimate skip (not Hispanic) ## 6 57120005 (5) May 25 (95) 1995 (1) Male (9) September (82) 1982 (0) No (7) Legitimate skip (not Hispanic) ## h1gi5b ## 1 (7) Legitimate skip (not Hispanic) ## 2 (7) Legitimate skip (not Hispanic) ## 3 (7) Legitimate skip (not Hispanic) ## 4 (7) Legitimate skip (not Hispanic) ## 5 (7) Legitimate skip (not Hispanic) ## 6 (7) Legitimate skip (not Hispanic) Records from one month from females: (dat_sub %&gt;% filter(imonth == &quot;(5) May&quot; &amp; bio_sex == &quot;(2) Female&quot;)) ## aid imonth iday iyear bio_sex h1gi1m h1gi1y h1gi4 h1gi5a ## 1 57101310 (5) May 5 (95) 1995 (2) Female (11) November (76) 1976 (0) No (7) Legitimate skip (not Hispanic) ## 2 57117997 (5) May 20 (95) 1995 (2) Female (10) October (82) 1982 (0) No (7) Legitimate skip (not Hispanic) ## 3 57118381 (5) May 6 (95) 1995 (2) Female (10) October (82) 1982 (0) No (7) Legitimate skip (not Hispanic) ## h1gi5b ## 1 (7) Legitimate skip (not Hispanic) ## 2 (7) Legitimate skip (not Hispanic) ## 3 (7) Legitimate skip (not Hispanic) Records from one month and from females or where the day of month was before the 15th, which will probably include some males: (dat_sub %&gt;% filter(imonth == &quot;(5) May&quot; &amp; (bio_sex == &quot;(2) Female&quot;) | iday &lt; 15)) ## aid imonth iday iyear bio_sex h1gi1m h1gi1y h1gi4 ## 1 57101310 (5) May 5 (95) 1995 (2) Female (11) November (76) 1976 (0) No ## 2 57103869 (7) July 14 (95) 1995 (1) Male (1) January (77) 1977 (0) No ## 3 57104553 (7) July 14 (95) 1995 (2) Female (6) June (76) 1976 (0) No ## 4 57104649 (6) June 12 (95) 1995 (1) Male (12) December (81) 1981 (0) No ## 5 57109625 (6) June 7 (95) 1995 (1) Male (3) March (81) 1981 (0) No ## 6 57111071 (8) August 3 (95) 1995 (1) Male (6) June (81) 1981 (0) No ## 7 57111786 (9) September 7 (95) 1995 (1) Male (9) September (80) 1980 (0) No ## 8 57117542 (7) July 11 (95) 1995 (1) Male (9) September (79) 1979 (0) No ## 9 57117997 (5) May 20 (95) 1995 (2) Female (10) October (82) 1982 (0) No ## 10 57118381 (5) May 6 (95) 1995 (2) Female (10) October (82) 1982 (0) No ## h1gi5a h1gi5b ## 1 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 2 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 3 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 4 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 5 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 6 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 7 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 8 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 9 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 10 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) Although these examples are silly and trivial, they show how filter() is used to create a selected set of data 2.4.2.2 Subset columns (select()) A subset of columns can be extracted from data frames using the select() function, most simply using named list of columns to keep. # select 3 columns (dat_sub_sel &lt;- dat_sub %&gt;% select(&quot;aid&quot;, &quot;imonth&quot;, &quot;iday&quot;)) ## aid imonth iday ## 1 57100270 (6) June 23 ## 2 57101310 (5) May 5 ## 3 57103171 (6) June 27 ## 4 57103869 (7) July 14 ## 5 57104553 (7) July 14 ## 6 57104649 (6) June 12 ## 7 57104676 (5) May 31 ## 8 57109625 (6) June 7 ## 9 57110897 (6) June 27 ## 10 57111071 (8) August 3 ## 11 57111786 (9) September 7 ## 12 57113943 (5) May 20 ## 13 57116359 (6) June 24 ## 14 57117542 (7) July 11 ## 15 57117997 (5) May 20 ## 16 57118381 (5) May 6 ## 17 57118943 (7) July 19 ## 18 57120005 (5) May 25 ## 19 57120046 (8) August 20 ## 20 57120371 (7) July 20 # select all but two named columns (dat_sub_sel &lt;- dat_sub %&gt;% select(-&quot;imonth&quot;, -&quot;iday&quot;)) ## aid iyear bio_sex h1gi1m h1gi1y h1gi4 h1gi5a ## 1 57100270 (95) 1995 (2) Female (10) October (77) 1977 (0) No (7) Legitimate skip (not Hispanic) ## 2 57101310 (95) 1995 (2) Female (11) November (76) 1976 (0) No (7) Legitimate skip (not Hispanic) ## 3 57103171 (95) 1995 (1) Male (10) October (79) 1979 (0) No (7) Legitimate skip (not Hispanic) ## 4 57103869 (95) 1995 (1) Male (1) January (77) 1977 (0) No (7) Legitimate skip (not Hispanic) ## 5 57104553 (95) 1995 (2) Female (6) June (76) 1976 (0) No (7) Legitimate skip (not Hispanic) ## 6 57104649 (95) 1995 (1) Male (12) December (81) 1981 (0) No (7) Legitimate skip (not Hispanic) ## 7 57104676 (95) 1995 (1) Male (10) October (83) 1983 (0) No (7) Legitimate skip (not Hispanic) ## 8 57109625 (95) 1995 (1) Male (3) March (81) 1981 (0) No (7) Legitimate skip (not Hispanic) ## 9 57110897 (95) 1995 (1) Male (9) September (81) 1981 (0) No (7) Legitimate skip (not Hispanic) ## 10 57111071 (95) 1995 (1) Male (6) June (81) 1981 (0) No (7) Legitimate skip (not Hispanic) ## 11 57111786 (95) 1995 (1) Male (9) September (80) 1980 (0) No (7) Legitimate skip (not Hispanic) ## 12 57113943 (95) 1995 (1) Male (1) January (79) 1979 (0) No (7) Legitimate skip (not Hispanic) ## 13 57116359 (95) 1995 (1) Male (4) April (80) 1980 (0) No (7) Legitimate skip (not Hispanic) ## 14 57117542 (95) 1995 (1) Male (9) September (79) 1979 (0) No (7) Legitimate skip (not Hispanic) ## 15 57117997 (95) 1995 (2) Female (10) October (82) 1982 (0) No (7) Legitimate skip (not Hispanic) ## 16 57118381 (95) 1995 (2) Female (10) October (82) 1982 (0) No (7) Legitimate skip (not Hispanic) ## 17 57118943 (95) 1995 (2) Female (4) April (79) 1979 (0) No (7) Legitimate skip (not Hispanic) ## 18 57120005 (95) 1995 (1) Male (9) September (82) 1982 (0) No (7) Legitimate skip (not Hispanic) ## 19 57120046 (95) 1995 (1) Male (10) October (76) 1976 (1) Yes (1) Marked ## 20 57120371 (95) 1995 (2) Female (8) August (76) 1976 (0) No (7) Legitimate skip (not Hispanic) ## h1gi5b ## 1 (7) Legitimate skip (not Hispanic) ## 2 (7) Legitimate skip (not Hispanic) ## 3 (7) Legitimate skip (not Hispanic) ## 4 (7) Legitimate skip (not Hispanic) ## 5 (7) Legitimate skip (not Hispanic) ## 6 (7) Legitimate skip (not Hispanic) ## 7 (7) Legitimate skip (not Hispanic) ## 8 (7) Legitimate skip (not Hispanic) ## 9 (7) Legitimate skip (not Hispanic) ## 10 (7) Legitimate skip (not Hispanic) ## 11 (7) Legitimate skip (not Hispanic) ## 12 (7) Legitimate skip (not Hispanic) ## 13 (7) Legitimate skip (not Hispanic) ## 14 (7) Legitimate skip (not Hispanic) ## 15 (7) Legitimate skip (not Hispanic) ## 16 (7) Legitimate skip (not Hispanic) ## 17 (7) Legitimate skip (not Hispanic) ## 18 (7) Legitimate skip (not Hispanic) ## 19 (0) Not marked ## 20 (7) Legitimate skip (not Hispanic) # select columns by position and whose name matches a pattern, in this case the regular expression &quot;^i&quot; meaning &quot;starts with lowercase i&quot; (dat_sub_sel &lt;- dat_sub %&gt;% select(1, matches(&quot;^i&quot;))) ## aid imonth iday iyear ## 1 57100270 (6) June 23 (95) 1995 ## 2 57101310 (5) May 5 (95) 1995 ## 3 57103171 (6) June 27 (95) 1995 ## 4 57103869 (7) July 14 (95) 1995 ## 5 57104553 (7) July 14 (95) 1995 ## 6 57104649 (6) June 12 (95) 1995 ## 7 57104676 (5) May 31 (95) 1995 ## 8 57109625 (6) June 7 (95) 1995 ## 9 57110897 (6) June 27 (95) 1995 ## 10 57111071 (8) August 3 (95) 1995 ## 11 57111786 (9) September 7 (95) 1995 ## 12 57113943 (5) May 20 (95) 1995 ## 13 57116359 (6) June 24 (95) 1995 ## 14 57117542 (7) July 11 (95) 1995 ## 15 57117997 (5) May 20 (95) 1995 ## 16 57118381 (5) May 6 (95) 1995 ## 17 57118943 (7) July 19 (95) 1995 ## 18 57120005 (5) May 25 (95) 1995 ## 19 57120046 (8) August 20 (95) 1995 ## 20 57120371 (7) July 20 (95) 1995 select() can also be used to rename columns: #select one column, rename two columns (dat_sub_sel %&gt;% select(aid, Month = imonth, Day = iday)) ## aid Month Day ## 1 57100270 (6) June 23 ## 2 57101310 (5) May 5 ## 3 57103171 (6) June 27 ## 4 57103869 (7) July 14 ## 5 57104553 (7) July 14 ## 6 57104649 (6) June 12 ## 7 57104676 (5) May 31 ## 8 57109625 (6) June 7 ## 9 57110897 (6) June 27 ## 10 57111071 (8) August 3 ## 11 57111786 (9) September 7 ## 12 57113943 (5) May 20 ## 13 57116359 (6) June 24 ## 14 57117542 (7) July 11 ## 15 57117997 (5) May 20 ## 16 57118381 (5) May 6 ## 17 57118943 (7) July 19 ## 18 57120005 (5) May 25 ## 19 57120046 (8) August 20 ## 20 57120371 (7) July 20 Or column renaming can be done with rename(), which maintains all input data and only changes the named columns: (dat_sub_sel %&gt;% rename(Month = imonth, Day = iday)) ## aid Month Day iyear ## 1 57100270 (6) June 23 (95) 1995 ## 2 57101310 (5) May 5 (95) 1995 ## 3 57103171 (6) June 27 (95) 1995 ## 4 57103869 (7) July 14 (95) 1995 ## 5 57104553 (7) July 14 (95) 1995 ## 6 57104649 (6) June 12 (95) 1995 ## 7 57104676 (5) May 31 (95) 1995 ## 8 57109625 (6) June 7 (95) 1995 ## 9 57110897 (6) June 27 (95) 1995 ## 10 57111071 (8) August 3 (95) 1995 ## 11 57111786 (9) September 7 (95) 1995 ## 12 57113943 (5) May 20 (95) 1995 ## 13 57116359 (6) June 24 (95) 1995 ## 14 57117542 (7) July 11 (95) 1995 ## 15 57117997 (5) May 20 (95) 1995 ## 16 57118381 (5) May 6 (95) 1995 ## 17 57118943 (7) July 19 (95) 1995 ## 18 57120005 (5) May 25 (95) 1995 ## 19 57120046 (8) August 20 (95) 1995 ## 20 57120371 (7) July 20 (95) 1995 2.4.2.3 Subset rows and columns: filter() and select() We can combine filter() and select() with a pipe to create a new data frame with a subset of rows and columns: # records with day of mongh &gt; 15 and the first 3 named columns (x &lt;- dat_sub %&gt;% filter(iday &gt; 15) %&gt;% select(aid, imonth, iday) ) ## aid imonth iday ## 1 57100270 (6) June 23 ## 2 57103171 (6) June 27 ## 3 57104676 (5) May 31 ## 4 57110897 (6) June 27 ## 5 57113943 (5) May 20 ## 6 57116359 (6) June 24 ## 7 57117997 (5) May 20 ## 8 57118943 (7) July 19 ## 9 57120005 (5) May 25 ## 10 57120046 (8) August 20 ## 11 57120371 (7) July 20 2.4.2.4 Create or calculate columns: mutate() mutate() will create new named columns or re-calculate existing columns. Here we will make a column that stratifies birth month, with the cut at June. Although the birth month column (h1gi1m) is a factor, it is unordered, so we need to make it ordered before using the factor label in a numeric comparison. Fortunately, the factor labels were handled in correct order: # is this ordered? is.ordered(dat$h1gi1m) ## [1] FALSE # what are the levels? (levels(dat$h1gi1m)) ## [1] &quot;(1) January&quot; &quot;(2) February&quot; &quot;(3) March&quot; &quot;(4) April&quot; &quot;(5) May&quot; &quot;(6) June&quot; ## [7] &quot;(7) July&quot; &quot;(8) August&quot; &quot;(9) September&quot; &quot;(10) October&quot; &quot;(11) November&quot; &quot;(12) December&quot; ## [13] &quot;(96) Refused&quot; Assign order, create a new column, and print nicely: # make birth month ordered dat$h1gi1m &lt;- factor(dat$h1gi1m, ordered = TRUE) # now is it ordered? is.ordered(dat$h1gi1m) ## [1] TRUE # perform the mutate() using the string representation of the factor for comparison dat %&gt;% filter(iday &gt; 15) %&gt;% select(aid, imonth, iday, birth_month = h1gi1m) %&gt;% mutate(birth_1st_half = (birth_month &lt; &quot;(7) July&quot;)) %&gt;% head(20) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ## Warning in if (!full_width) {: the condition has length &gt; 1 and only the first element will be used aid imonth iday birth_month birth_1st_half 57100270 June 23 October FALSE 57103171 June 27 October FALSE 57104676 May 31 October FALSE 57110897 June 27 September FALSE 57113943 May 20 January TRUE 57116359 June 24 April TRUE 57117997 May 20 October FALSE 57118943 July 19 April TRUE 57120005 May 25 September FALSE 57120046 August 20 October FALSE 57120371 July 20 August FALSE 57121476 May 20 October FALSE 57123494 July 21 February TRUE 57129567 July 26 February TRUE 57130633 August 26 October FALSE 57131909 April 27 July FALSE 57133772 July 19 February TRUE 57134457 July 18 April TRUE 57136630 May 16 May TRUE 57139880 June 19 October FALSE A silly example but showing that mutate() can change values of existing columns: (X &lt;- dat_sub %&gt;% mutate(iday = -1000 + iday)) ## aid imonth iday iyear bio_sex h1gi1m h1gi1y h1gi4 ## 1 57100270 (6) June -977 (95) 1995 (2) Female (10) October (77) 1977 (0) No ## 2 57101310 (5) May -995 (95) 1995 (2) Female (11) November (76) 1976 (0) No ## 3 57103171 (6) June -973 (95) 1995 (1) Male (10) October (79) 1979 (0) No ## 4 57103869 (7) July -986 (95) 1995 (1) Male (1) January (77) 1977 (0) No ## 5 57104553 (7) July -986 (95) 1995 (2) Female (6) June (76) 1976 (0) No ## 6 57104649 (6) June -988 (95) 1995 (1) Male (12) December (81) 1981 (0) No ## 7 57104676 (5) May -969 (95) 1995 (1) Male (10) October (83) 1983 (0) No ## 8 57109625 (6) June -993 (95) 1995 (1) Male (3) March (81) 1981 (0) No ## 9 57110897 (6) June -973 (95) 1995 (1) Male (9) September (81) 1981 (0) No ## 10 57111071 (8) August -997 (95) 1995 (1) Male (6) June (81) 1981 (0) No ## 11 57111786 (9) September -993 (95) 1995 (1) Male (9) September (80) 1980 (0) No ## 12 57113943 (5) May -980 (95) 1995 (1) Male (1) January (79) 1979 (0) No ## 13 57116359 (6) June -976 (95) 1995 (1) Male (4) April (80) 1980 (0) No ## 14 57117542 (7) July -989 (95) 1995 (1) Male (9) September (79) 1979 (0) No ## 15 57117997 (5) May -980 (95) 1995 (2) Female (10) October (82) 1982 (0) No ## 16 57118381 (5) May -994 (95) 1995 (2) Female (10) October (82) 1982 (0) No ## 17 57118943 (7) July -981 (95) 1995 (2) Female (4) April (79) 1979 (0) No ## 18 57120005 (5) May -975 (95) 1995 (1) Male (9) September (82) 1982 (0) No ## 19 57120046 (8) August -980 (95) 1995 (1) Male (10) October (76) 1976 (1) Yes ## 20 57120371 (7) July -980 (95) 1995 (2) Female (8) August (76) 1976 (0) No ## h1gi5a h1gi5b ## 1 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 2 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 3 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 4 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 5 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 6 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 7 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 8 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 9 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 10 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 11 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 12 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 13 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 14 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 15 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 16 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 17 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 18 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ## 19 (1) Marked (0) Not marked ## 20 (7) Legitimate skip (not Hispanic) (7) Legitimate skip (not Hispanic) ... so do be careful! Other functions can be used with mutate include (but are by no means limited to!) if_else(): create a column by assigning values based on logical criteria case_when(): similar to if_else() but for multiple input values recode(): change particular values When we recoded the birth month, the output was a logical data type. If we wanted to create a character or factor, we could use if_else(). Here we are creating a new data frame based on several operations on dat. dat_1 &lt;- dat %&gt;% filter(iday &gt; 15) %&gt;% head(20) %&gt;% select(aid, imonth, iday, birth_month = h1gi1m) %&gt;% mutate(birth_year_half = ifelse(test = birth_month &lt; &quot;(7) July&quot;, yes = &quot;first&quot;, no = &quot;last&quot;)) # make that a factor dat_1$birth_year_half &lt;- factor(dat_1$birth_year_half, levels = c(&quot;first&quot;, &quot;last&quot;)) # print kable(dat_1) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ## Warning in if (!full_width) {: the condition has length &gt; 1 and only the first element will be used aid imonth iday birth_month birth_year_half 57100270 June 23 October last 57103171 June 27 October last 57104676 May 31 October last 57110897 June 27 September last 57113943 May 20 January first 57116359 June 24 April first 57117997 May 20 October last 57118943 July 19 April first 57120005 May 25 September last 57120046 August 20 October last 57120371 July 20 August last 57121476 May 20 October last 57123494 July 21 February first 57129567 July 26 February first 57130633 August 26 October last 57131909 April 27 July last 57133772 July 19 February first 57134457 July 18 April first 57136630 May 16 May first 57139880 June 19 October last If one of your variables contains multiple values and you want to create classes, use case_when(). Here is a verbose example stratifying months into quarters. Also we are using the magrittr assignment pipe to update the input based on the statement, i.e., dat_1 will change based on the commands we use. Be careful using the assignment pipe because it will change your data frame. case_when() will recode in order or the way the command is written, so for months and quarters, it is not necessary to specify both ends of the quarter. Also any cases that are not explicitly handled can be addressed with the TRUE ~ ... argument; in this case, any records that had birth months that were not before September get assigned to quarter 4. dat_1 %&lt;&gt;% mutate(quarter = case_when( birth_month &lt; &quot;(3) March&quot; ~ 1, birth_month &lt; &quot;(6) June&quot; ~ 2, birth_month &lt; &quot;(9) September&quot; ~ 3, TRUE ~ 4)) # print kable(dat_1) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ## Warning in if (!full_width) {: the condition has length &gt; 1 and only the first element will be used aid imonth iday birth_month birth_year_half quarter 57100270 June 23 October last 4 57103171 June 27 October last 4 57104676 May 31 October last 4 57110897 June 27 September last 4 57113943 May 20 January first 1 57116359 June 24 April first 2 57117997 May 20 October last 4 57118943 July 19 April first 2 57120005 May 25 September last 4 57120046 August 20 October last 4 57120371 July 20 August last 3 57121476 May 20 October last 4 57123494 July 21 February first 1 57129567 July 26 February first 1 57130633 August 26 October last 4 57131909 April 27 July last 3 57133772 July 19 February first 1 57134457 July 18 April first 2 57136630 May 16 May first 2 57139880 June 19 October last 4 recode() is used to change the birth_year_half column: (dat_1 %&lt;&gt;% mutate(birth_year_half_split = recode(birth_year_half, &quot;first&quot; = &quot;early&quot;, &quot;last&quot; = &quot;late&quot;))) ## aid imonth iday birth_month birth_year_half quarter birth_year_half_split ## 1 57100270 (6) June 23 (10) October last 4 late ## 2 57103171 (6) June 27 (10) October last 4 late ## 3 57104676 (5) May 31 (10) October last 4 late ## 4 57110897 (6) June 27 (9) September last 4 late ## 5 57113943 (5) May 20 (1) January first 1 early ## 6 57116359 (6) June 24 (4) April first 2 early ## 7 57117997 (5) May 20 (10) October last 4 late ## 8 57118943 (7) July 19 (4) April first 2 early ## 9 57120005 (5) May 25 (9) September last 4 late ## 10 57120046 (8) August 20 (10) October last 4 late ## 11 57120371 (7) July 20 (8) August last 3 late ## 12 57121476 (5) May 20 (10) October last 4 late ## 13 57123494 (7) July 21 (2) February first 1 early ## 14 57129567 (7) July 26 (2) February first 1 early ## 15 57130633 (8) August 26 (10) October last 4 late ## 16 57131909 (4) April 27 (7) July last 3 late ## 17 57133772 (7) July 19 (2) February first 1 early ## 18 57134457 (7) July 18 (4) April first 2 early ## 19 57136630 (5) May 16 (5) May first 2 early ## 20 57139880 (6) June 19 (10) October last 4 late 2.4.2.5 Summarizing/aggregating data We will spend more time later in the course on data summaries, but an introduction with dplyr is worthwhile introducing at this stage. The two main functions are summarise() and group_by(). A simple summary will tabulate the count of respondents and the mean age. The filter ! str_detect(h1gi1y, &quot;Refused&quot;) drops records from respondents who refused to give their birth year. dat %&gt;% filter(! str_detect(h1gi1y, &quot;Refused&quot;)) %&gt;% mutate(yeari = str_replace_all(iyear, &quot;.* &quot;, &quot;&quot;) %&gt;% as.integer(), yearb = str_replace_all(h1gi1y, &quot;.* &quot;, &quot;&quot;) %&gt;% as.integer()) %&gt;% summarise(n = n(), mean_age = mean(yeari - yearb)) ## n mean_age ## 1 6501 16.03676 Here we will summarize age by sex using the group_by() function, and also piping to prop_table() to get the percentage: dat %&gt;% filter(! str_detect(h1gi1y, &quot;Refused&quot;)) %&gt;% mutate(yeari = str_replace_all(iyear, &quot;.* &quot;, &quot;&quot;) %&gt;% as.integer(), yearb = str_replace_all(h1gi1y, &quot;.* &quot;, &quot;&quot;) %&gt;% as.integer()) %&gt;% group_by(bio_sex) %&gt;% summarise(mean_age = mean(yeari - yearb), sd_age = sd(yeari - yearb), n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(pct = prop.table(n) * 100) ## # A tibble: 2 x 5 ## bio_sex mean_age sd_age n pct ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 (1) Male 16.1 1.77 3147 48.4 ## 2 (2) Female 16.0 1.77 3354 51.6 Source code for this document 02-week02.Rmd # Week 2 {#week2} ```{r, echo=FALSE, warning=FALSE, message=FALSE} library(tidyverse) library(magrittr) library(knitr) library(kableExtra) library(readstata13) ``` &lt;h2&gt;Topics: R data structures; tidyverse&lt;/h2&gt; It is assumed that students in this course have a basic working knowledge of using R, including how to create variables with the assignment operator (&quot;`&lt;-`&quot;), and how to run simple functions(e.g., `mean(dat$age)`). Often in courses that include using R for statistical analysis, some of the following foundations are not explained fully. This is not intended to be a comprehensive treatment of R data types and structures, but should provide some background for students who are either relatively new at using R or who have not had a systematic introduction. The other main topic for today is [&quot;tidyverse&quot;](https://www.tidyverse.org/), which refers to a related set of R packages for data management, analysis, and display. See Hadley Wickham&#39;s [tidy tools manifesto](https://tidyverse.tidyverse.org/articles/manifesto.html) for the logic behind the suite of tools. For a brief description of the specific R packages, see [Tidyverse packages](https://www.tidyverse.org/packages/). This is not intended to be a comprehensive introduction, but should provide sufficient background for data handling to support most of the technical aspects of the rest of the course. ## Code to run for the in-class exercise ```{r, echo=FALSE} # generate the R code to run in class # O &lt;- knitr::purl(input = &quot;02-week02.Rmd&quot;, output = &quot;r_code/week02.R&quot;, quiet = TRUE, documentation = 1) ``` For the exercise in class, download [week02.R](r_code/week02.R), which we will use to run the code listed in this R Markdown result. ## R data types There are six fundamental data types in R: 1. logical 1. numeric 1. integer 1. complex 1. character 1. raw The most atomic object in R will exist having one of those data types, described below. An atomic object of the data type can have a value, `NA` which represents an observation with no data (e.g., a missing measurement), or `NULL` which isn&#39;t really a value at all, but can still have the data type class. You will encounter other data types, such as `Date` or `POSIXct` if you are working with dates or time stamps. These other data types are extensions of the fundamental data types. To determine what data type an object is, use `is(obj)`, `str(obj)`, or `class(obj)`. ```{r} print(is(&quot;a&quot;)) print(str(TRUE)) print(class(123.45)) print(class(as.integer(1000))) n &lt;- as.numeric(999999999999999999999) print(class(n)) ``` ### Logical Use `logical` values for characteristics that are either `TRUE` or `FALSE`. Note that if `logical` elements can also have an `NA` value if the observation is missing. In the following examples, ```{r} # evaluate as logical, test whether 1 is greater than two a &lt;- 1 &gt; 2 ``` ```{r} # create two numerical values, one being NA, representing ages age_john &lt;- 39 age_jane &lt;- NA # logical NA from Jane&#39;s undefined age (jo &lt;- age_john &gt; 50) (ja &lt;- age_jane &gt; 50) ``` Logical values are often expressed in binary format as 0 = `FALSE` and ` = `TRUE`. in R these values are interconvertible. Other software (e.g., Excel, MS Access) may convert logical values to numbers that you do not expect. ```{r} (t &lt;- as.logical(1)) (f &lt;- as.logical(0)) ``` ### Numeric `Numeric` values are numbers with range about 2e-308 to 2e+308, depending on the computer you are using. You can see the possible range by entering `.Machine` at the R console. These can also include decimals. For more information, see [Double-precision floating-point format](https://en.wikipedia.org/wiki/Double-precision_floating-point_format) ### Integer `Integer` values are numerical, but can only take on whole, rather than fractional values, and have a truncated range compared to `numeric`. For example, see below, if we try to create an integer that is out of range. The object we created is an integer, but because it is out of range, is value is set to `NA`. ```{r} i &lt;- as.integer(999999999999999999999) print(class(i)) ``` ### Complex The `complex` type is used in mathematics and you are unlikely to use it in applied social science research unless you get into some heavy statistics. See [Complex number](https://en.wikipedia.org/wiki/Complex_number) for a full treatment. ### Character `Character` data include the full set of keys on your keyboard that print out a character, typically [A-Z], [a-z], [0-9], punctuation, etc. The full set of ASCII characters is supported, e.g. the `accent aigu` in CafÃ©: ```{r} print(class(&quot;CafÃ©&quot;)) ``` Also numbers can function as characters. Be careful in converting between numerical and character versions. For example, see these ZIP codes: ```{r error=TRUE} # this is a character my_zip &lt;- &quot;98115&quot; # it is not numeric. my_zip + 2 ``` ```{r} # we can convert it to numeric, although it would be silly to do with ZIP codes, which are nominal values as.numeric(my_zip) + 2 # Boston has ZIP codes starting with zeros boston_zip &lt;- &quot;02134&quot; as.numeric(boston_zip) ``` ### Raw `Raw` values are used to store raw bytes in hexadecimal format. You are unlikely to use it in applied social science research. For example, the hexadecimal value for the character `z` is `7a`: ```{r} print(charToRaw(&quot;z&quot;)) class(charToRaw(&quot;z&quot;)) ``` ## R data structures ![](images/week02/data_structures.png) There are 5 basic data structures in R, as shown in the graphic: 1. vector 1. matrix 1. array 1. list 1. data frame In addition, the `factor` data type is very important ### Vector A vector is an ordered set of elements of one or more elements of the same data type and are created using the `c()` constructor function. For example, a single value is a vector: ```{r} # create a vector of length 1 a &lt;- 1 is(a) ``` If you try creating a vector with mixed data types, you may get unexpected results; mixing character elements with other type elements will result in character representations, e.g., ```{r} c(1, &quot;a&quot;, TRUE, charToRaw(&quot;z&quot;)) ``` Results will depend on the data type you are mixing, for example because logical values can be expressed numerically, the `TRUE` and `FALSE` values are converted to `1` and `0`, respectively. ```{r} (c(1:3, TRUE, FALSE)) ``` But if a character is added, all elements are converted to characters. ```{r} c(1:3, TRUE, FALSE, &quot;awesome!&quot;) ``` Order is important, i.e., `1, 2, 3` is not the same as `1, 3, 2` R will maintain the order of elements in vectors unless a process is initiated that changes the order of those elements: ```{r} # a vector (v &lt;- c(1, 3, 2)) (sort(v)) ``` You can get some information about vectors, such as length and data type: ```{r} # create a random normal set.seed(5) normvec1000 &lt;- rnorm(n = 1000) length(normvec1000) class(normvec1000) class(normvec1000 &gt; 1) ``` Elements of vectors are specified with their index number (1 .. n): ```{r} v &lt;- seq(from = 0, to = 10, by = 2) v[4] ``` ### Matrix A matrix is like a vector, in that it an contain only one data type, but it is two-dimensional, having rows and columns. A simple example: ```{r} # make a vector 1 to 100 (v &lt;- 1:100) # load to a matrix (m1 &lt;- matrix(v, ncol = 10, byrow = TRUE)) # different r, c ordering (m2 &lt;- matrix(v, ncol = 10, byrow = FALSE)) ``` If you try to force a vector into a matrix whose row $\\times$ col length does not match the length of the vector, the elements will be recycled, which may not be what you want. At least R will give you a warning. ```{r} (m3 &lt;- matrix(letters, ncol = 10, nrow = 10)) ``` ### Array An array is similar to matrix, but it can have more than one dimension. These can be useful for analyzing time series data or other multidimensional data. We will not be using array data in this course, but a simple example of creating and viewing the contents of an array: ```{r} # a vector 1 to 27 v &lt;- 1:27 # create an array, 3 x 3 x 3 (a &lt;- array(v, dim = c(3, 3, 3))) # array index is r, c, m (row, column, matrix), e.g., row 1 column 2 matrix 3: (a[1,2,3]) ``` ### List R lists are ordered collections of objects that do not need to be of the same data type. Those objects can be single-value vectors, multiple-value vectors, matrices, data frames, other lists, etc. Because of this, lists are a very flexible data type. But because they can have as little or as much structure as you want, can become difficult to manage and analyze. Here is an example of a list comprised of single value vectors of different data type. Compare this with the attempt to make a vector comprised of elements of different data type: ```{r} (l &lt;- list(&quot;a&quot;, 1, TRUE)) ``` Let&#39;s modify that list a bit: ```{r} (l &lt;- list(&quot;a&quot;, 1:20, as.logical(c(0,1,1,0)))) ``` The top-level indexing for a list is denoted using two sets of square brackets. For example, the first element of our list can be accessed by `l[[1]]`. For example, the mean of element 2 is obtained by `mean(l[[2]])`: ``r mean(l[[2]])``. To perform operations on all elements of a list, use `lapply()`: ```{r} # show the data types (lapply(X = l, FUN = class)) # mean, maybe? (lapply(X = l, FUN = function(x) {mean(x)})) ``` ### Factor Factors are similar to vectors, in that they are one-dimensional ordered sets. However, factors also use informational labels. For example, you may have a variable with household income as a text value: * &quot;&lt;$10,000&quot; * &quot;$10,000-$549,999&quot; * &quot;$50,000-$99,999&quot; * &quot;$100,000-$200,000&quot; * &quot;&gt;$200,000&quot; As a vector: ```{r} (income &lt;- c(&quot;&lt;$10,000&quot; , &quot;$10,000-$49,999&quot; , &quot;$50,000-$99,999&quot; , &quot;$100,000-$200,000&quot; , &quot;&gt;$200,000&quot;)) ``` Because these are characters, they do not sort in proper numeric order: ```{r} sort(income) ``` If these are treated as a factor, the levels can be set for proper ordering: ```{r} # create a factor from income and set the levels (income_factor &lt;- factor(x = income, levels = income)) # sort again (sort(income_factor)) ``` As a factor, the data can also be used in statistical models and the magnitude of the variable will also be correctly ordered. ### Data frame Other than vectors, data frames are probably the most used data type in R. You can think of data frames as matrices that allow columns with different data type. For example, you might have a data set that represents subject IDs as characters, sex or gender as text, height, weight, and age as numerical values, income as a factor, and smoking status as logical. Because a matrix requires only one data type, it would not be possible to store all of these as a matrix. An example: ```{r} # income levels inc &lt;- c(&quot;&lt;$10,000&quot; , &quot;$10,000-$49,999&quot; , &quot;$50,000-$99,999&quot; , &quot;$100,000-$200,000&quot; , &quot;&gt;$200,000&quot;) BMI &lt;- data.frame( sid = c(&quot;A1001&quot;, &quot;A1002&quot;, &quot;B1001&quot;), gender = c(&quot;Male&quot;, &quot;Male&quot;,&quot;Female&quot;), height_cm = c(152, 171.5, 165), weight_kg = c(81, 93, 78), age_y = c(42, 38, 26), income = factor(c(&quot;$50,000-$99,999&quot;, &quot;$100,000-$200,000&quot;, &quot;&lt;$10,000&quot;), levels = inc) ) print(BMI) ``` ## tidyverse This section will introduce some of the main workhorse functions in tidy data handling. Installing tidyverse is straightforward but it may take some time to download and install all of the packages. Use ``` install.packages(&quot;tidyverse&quot;) ``` For today&#39;s lesson we will be using one of the Add Health data sets, [AHwave1_v1.dta](data/AHwave1_v1.dta). ```{r warning=FALSE} # read the dta file dat &lt;- readstata13::read.dta13(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta&quot;) ``` The data set includes variable labels, which make handling the data easier. Here we print the column names and their labels. Wrapping this in a `DT::data_table` presents a nice interface for showing only a few variables at a time and that allows sorting and searching. ```{r} x &lt;- data.frame(colname = names(dat), label = attributes(dat)$var.labels) DT::datatable(data = x, caption = &quot;Column names and labels in AHwave1_v1.dta.&quot;) ``` ### magrittr{#magrittr} ![](images/week02/unepipe.jpeg) The R package [`magrittr`](https://cran.r-project.org/web/packages/magrittr/index.html) allows the use of &quot;pipes&quot;. In UNIX, pipes were used to take the output of one program and to feed as input to another program. For example, the UNIX command `cat` prints the contents of a text file. This would print the contents of the file `00README.txt`: ```cat 00README.txt``` but with large files, the entire contents would scroll by too fast to read. Using a &quot;pipe&quot;, denoted with the vertical bar character `|` allowed using the `more` command to print one screen at a time by tapping the `Enter` key for each screen full of text: ```cat 00README.txt | more``` As shown in these two screen captures: ![](images/week02/cat_more.png) ![](images/week02/cat_more2.png) The two main pipe operators we will use in `magrittr` are `%&gt;%` and &#39;%&lt;&gt;%&#39;. `%&gt;%` is the pipe operator, which functions as a UNIX pipe, that is, to take something on the left hand side of the operator and feed it to the right hand side. `%&lt;&gt;%` is the assignment pipe operator, which takes something on the left hand side of the operator, feeds it to the right hand side, and replaces the object on the left-hand side. For a simple example of the pipe, to list only the first 6 lines of a data frame in base R, we use `head()`, e.g., ```{r} head(iris) ``` using a tidy version of this: ```{r} iris %&gt;% head() ``` In the R base version, we first read `head`, so we know we will be printing the first 6 elements of something, but we don&#39;t know what that &quot;something&quot; is. We have to read ahead to know we are reading the first 6 records of `iris`. In the tidy version, we start by knowing we are doing something to the data set, after which we know we are printing the first 6 records. In base R functions, the process is evaluated from the inside out. For example, to get the mean sepal length of the _setosa_ species in iris, we would do this: ```{r} mean(iris[iris$Species == &#39;setosa&#39;, &quot;Sepal.Length&quot;]) ``` From the inside out, we read that we are making a subset of `iris` where Species = &quot;setosa&quot;, we are selecting the column &quot;Sepal.Length&quot;, and taking the mean. However, it requires reading from the inside out. For a large set of nested functions, we would have ` y &lt;- f(g(h((i(x)))))`, which would require first creating the innermost function (`i()`) and then working outward. In a tidy approach this would be more like y &lt;- x %&gt;% i() %&gt;% h() %&gt;% g() %&gt;% f()` because the first function applied to the data set `x` is `i()`. Revisiting the mean sepal length of _setosa_ irises, example, under a tidy approach we would do this: ```{r} iris %&gt;% filter(Species == &#39;setosa&#39;) %&gt;% summarise(mean(Sepal.Length)) ``` Which, read from left to right, translates to &quot;using the iris data frame, make a subset of records where species is _setosa_, and summarize those records to get the mean value of sepal length.&quot; The tidy version is intended to be easier to write, read, and understand. The command uses the `filter()` function, which will be described below. ### Data subsetting (dplyr) `dplyr` is the tidyverse R package used most frequently for data manipulation. Selection of records (i.e., subsetting) is done using logical tests to determine what is in the selected set. First we will look at logical tests and then we will cover subsetting rows and columns from data frames. ##### Logical tests If elements meet a logical test, they will end up in the selected set. If data frame records have values in variables that meet logical criteria, the records will be selected. Some logical tests are shown below. ###### `==`: equals ```{r} # numeric tests (1 == 2) ``` ```{r} (1 == 3 - 2) ``` ```{r} # character test (actually a factor) (dat$imonth %&gt;% head() %&gt;% str_c(collapse = &quot;, &quot;)) ((dat$imonth == &quot;(6) June&quot;) %&gt;% head()) ``` ```{r} # character test for multiple patterns (dat$imonth %in% c(&quot;(6) June&quot;, &quot;(7) July&quot;) %&gt;% head()) ``` ###### `&gt;`, `&gt;=`, `&lt;`, `&lt;=`: numeric comparisons ```{r} 1 &lt; 2 ``` ```{r} 1 &gt; 2 ``` ```{r} 1 &lt;= -10:10 ``` ```{r} 1 &gt;= -10:10 ``` ###### `!=`: not equals ```{r} 1 != 2 ``` ```{r} # those of the first 6 days that are not 14 (dat$iday %&gt;% head()) ((dat$iday != 14) %&gt;% head()) ``` ###### `!`: invert, or &quot;not&quot; Sometimes it is more convenient to negate a single condition rather than enumerating all possible matching conditions. ```{r} dat$imonth %&gt;% head(20) ((!dat$imonth %in% c(&quot;(6) June&quot;, &quot;(7) July&quot;)) %&gt;% head(20)) ``` #### Subset rows (`filter()`) The `filter()` function creates a subset of records based on a logical test. Logical tests can be combined as &quot;and&quot; statements using the `&amp;` operator and &quot;or&quot; statements using the `|` operator. Here we will perform a few filters on a subset of the data. ```{r} # first 20 records, fist 10 columns dat_sub &lt;- dat[1:20, 1:10] kable(dat_sub, format = &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ``` Records from one month: ```{r} # from May (dat_sub %&gt;% filter(imonth == &quot;(5) May&quot;)) ``` Records from one month from females: ```{r} (dat_sub %&gt;% filter(imonth == &quot;(5) May&quot; &amp; bio_sex == &quot;(2) Female&quot;)) ``` Records from one month and from females or where the day of month was before the 15th, which will probably include some males: ```{r} (dat_sub %&gt;% filter(imonth == &quot;(5) May&quot; &amp; (bio_sex == &quot;(2) Female&quot;) | iday &lt; 15)) ``` Although these examples are silly and trivial, they show how `filter()` is used to create a selected set of data #### Subset columns (`select()`) A subset of columns can be extracted from data frames using the `select()` function, most simply using named list of columns to keep. ```{r} # select 3 columns (dat_sub_sel &lt;- dat_sub %&gt;% select(&quot;aid&quot;, &quot;imonth&quot;, &quot;iday&quot;)) ``` ```{r} # select all but two named columns (dat_sub_sel &lt;- dat_sub %&gt;% select(-&quot;imonth&quot;, -&quot;iday&quot;)) ``` ```{r} # select columns by position and whose name matches a pattern, in this case the regular expression &quot;^i&quot; meaning &quot;starts with lowercase i&quot; (dat_sub_sel &lt;- dat_sub %&gt;% select(1, matches(&quot;^i&quot;))) ``` `select()` can also be used to rename columns: ```{r} #select one column, rename two columns (dat_sub_sel %&gt;% select(aid, Month = imonth, Day = iday)) ``` Or column renaming can be done with `rename()`, which maintains all input data and only changes the named columns: ```{r} (dat_sub_sel %&gt;% rename(Month = imonth, Day = iday)) ``` #### Subset rows and columns: `filter()` and `select()` We can combine `filter()` and `select()` with a pipe to create a new data frame with a subset of rows and columns: ```{r} # records with day of mongh &gt; 15 and the first 3 named columns (x &lt;- dat_sub %&gt;% filter(iday &gt; 15) %&gt;% select(aid, imonth, iday) ) ``` #### Create or calculate columns: `mutate()` `mutate()` will create new named columns or re-calculate existing columns. Here we will make a column that stratifies birth month, with the cut at June. Although the birth month column (`h1gi1m`) is a factor, it is unordered, so we need to make it ordered before using the factor label in a numeric comparison. Fortunately, the factor labels were handled in correct order: ```{r} # is this ordered? is.ordered(dat$h1gi1m) ``` ```{r} # what are the levels? (levels(dat$h1gi1m)) ``` Assign order, create a new column, and print nicely: ```{r} # make birth month ordered dat$h1gi1m &lt;- factor(dat$h1gi1m, ordered = TRUE) # now is it ordered? is.ordered(dat$h1gi1m) ``` ```{r} # perform the mutate() using the string representation of the factor for comparison dat %&gt;% filter(iday &gt; 15) %&gt;% select(aid, imonth, iday, birth_month = h1gi1m) %&gt;% mutate(birth_1st_half = (birth_month &lt; &quot;(7) July&quot;)) %&gt;% head(20) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ``` A silly example but showing that `mutate()` can change values of existing columns: ```{r} (X &lt;- dat_sub %&gt;% mutate(iday = -1000 + iday)) ``` ... so do be careful! Other functions can be used with mutate include (but are by no means limited to!) * `if_else()`: create a column by assigning values based on logical criteria * `case_when()`: similar to `if_else()` but for multiple input values * `recode()`: change particular values When we recoded the birth month, the output was a `logical` data type. If we wanted to create a `character` or `factor`, we could use `if_else()`. Here we are creating a new data frame based on several operations on `dat`. ```{r} dat_1 &lt;- dat %&gt;% filter(iday &gt; 15) %&gt;% head(20) %&gt;% select(aid, imonth, iday, birth_month = h1gi1m) %&gt;% mutate(birth_year_half = ifelse(test = birth_month &lt; &quot;(7) July&quot;, yes = &quot;first&quot;, no = &quot;last&quot;)) # make that a factor dat_1$birth_year_half &lt;- factor(dat_1$birth_year_half, levels = c(&quot;first&quot;, &quot;last&quot;)) # print kable(dat_1) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ``` If one of your variables contains multiple values and you want to create classes, use `case_when()`. Here is a verbose example stratifying months into quarters. Also we are using the `magrittr` assignment pipe to update the input based on the statement, i.e., `dat_1` will change based on the commands we use. __Be careful using the assignment pipe because it will change your data frame.__ `case_when()` will recode in order or the way the command is written, so for months and quarters, it is not necessary to specify both ends of the quarter. Also any cases that are not explicitly handled can be addressed with the `TRUE ~ ...` argument; in this case, any records that had birth months that were not before September get assigned to quarter 4. ```{r} dat_1 %&lt;&gt;% mutate(quarter = case_when( birth_month &lt; &quot;(3) March&quot; ~ 1, birth_month &lt; &quot;(6) June&quot; ~ 2, birth_month &lt; &quot;(9) September&quot; ~ 3, TRUE ~ 4)) # print kable(dat_1) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ``` `recode()` is used to change the `birth_year_half` column: ```{r} (dat_1 %&lt;&gt;% mutate(birth_year_half_split = recode(birth_year_half, &quot;first&quot; = &quot;early&quot;, &quot;last&quot; = &quot;late&quot;))) ``` #### Summarizing/aggregating data We will spend more time later in the course on data summaries, but an introduction with `dplyr` is worthwhile introducing at this stage. The two main functions are `summarise()` and `group_by()`. A simple summary will tabulate the count of respondents and the mean age. The filter `! str_detect(h1gi1y, &quot;Refused&quot;)` drops records from respondents who refused to give their birth year. ```{r} dat %&gt;% filter(! str_detect(h1gi1y, &quot;Refused&quot;)) %&gt;% mutate(yeari = str_replace_all(iyear, &quot;.* &quot;, &quot;&quot;) %&gt;% as.integer(), yearb = str_replace_all(h1gi1y, &quot;.* &quot;, &quot;&quot;) %&gt;% as.integer()) %&gt;% summarise(n = n(), mean_age = mean(yeari - yearb)) ``` Here we will summarize age by sex using the `group_by()` function, and also piping to `prop_table()` to get the percentage: ```{r} dat %&gt;% filter(! str_detect(h1gi1y, &quot;Refused&quot;)) %&gt;% mutate(yeari = str_replace_all(iyear, &quot;.* &quot;, &quot;&quot;) %&gt;% as.integer(), yearb = str_replace_all(h1gi1y, &quot;.* &quot;, &quot;&quot;) %&gt;% as.integer()) %&gt;% group_by(bio_sex) %&gt;% summarise(mean_age = mean(yeari - yearb), sd_age = sd(yeari - yearb), n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(pct = prop.table(n) * 100) ``` &lt;h4&gt;Source code for this document&lt;/h4&gt; [02-week02.Rmd](01-week02.Rmd) ```{r, comment=&#39;&#39;, echo=FALSE} cat(readLines(&quot;02-week02.Rmd&quot;), sep = &#39;\\n&#39;) ``` "],["week3.html", "3 Week 3 3.1 Graphics in R Markdown 3.2 Tables in R Markdown 3.3 Captions to support tables, figures, and equations 3.4 R Markdown to Microsoft Word 3.5 R Markdown output 3.6 Advantages and disadvantages of PDF 3.7 Bibliography in R Markdown", " 3 Week 3 .border1 { border-width: 1px; border-color: black; border-style: solid; } Topics: Graphics and Tables in R; Captions and cross-references; R Markdown to MS Word; Bibliography Because of its extensibility, HTML can be considered a preferred output from R Markdown. However, document formats are often necessary, particularly for term papers, theses/dissertations, and manuscripts for submission to scholarly journals. In this week's lesson, we will focus on the creation of these two output types, including adding bibliographies (which also applies to HTML output), and some basic ggplot graphics. For both PDF and Word output, much of the structure of your Rmd files will be the same as for HTML output. The major difference is how tables are handled, which we will explore in some detail. Static graphics are handled similarly across all output formats, other than HTML output can support dynamic graphics, such as the Leaflet map we saw in the first lesson, and responsive graphics as in Shiny. 3.1 Graphics in R Markdown Data-driven graphics in Rmd files are typically created as base R graphics or with the ggplot2 package. This tutorial is not intended to provide anywhere near a comprehensive treatment of creating graphics from data, but will provide instruction on some options for creating and including data-driven graphics as well as inserting graphics from image files. See Tips and tricks for working with images and figures in R Markdown documents for a good explanation. 3.1.1 Base R graphics To include base R graphics, simply place the code to generate the graphic in an R code block, e.g., using the Add Health data from last week (AHWave1_v1.dta): ```{r} # since loading the data takes awhile, only do this if necessary if(!exists(&quot;dat&quot;)){ dat &lt;- read.dta13(&quot;data/AHwave1_v1.dta&quot;) } # birth year = h1gi1y # drop &quot;Refused&quot; birth year # for birth year and interview year, replace anything before white space, convert to numeric # subtract interview year - birth year ages &lt;- dat %&gt;% filter(! str_detect(h1gi1y, &quot;Refused&quot;)) %&gt;% select(iyear, h1gi1y) %&gt;% mutate(yi = str_replace(iyear, &quot;.*\\\\s&quot;, &quot;&quot;) %&gt;% as.numeric(), yb = str_replace(h1gi1y, &quot;.*\\\\s&quot;, &quot;&quot;) %&gt;% as.numeric(), age = yi - yb) # create a histogram using base graphics hist(ages$age, xlab = &quot;age (years)&quot;, las = 1) ``` ... which will render the graph: 3.1.2 ggplot2 graphics The ggplot2 package creates compelling graphics that use a common syntax. The main difference between base R graphics and ggplot2 graphics is that simply issuing the plot() or related command (e.g., hist(), barplot()) adds the graphic to the output, whereas with ggplot() it is necessary to issue a command that prints the graphic. Following the previous example: # how many unique bins? bins &lt;- length(unique(ages$age)) # create the graphic g &lt;- ggplot(data = ages, mapping = aes(x = age)) + geom_histogram(bins = bins) # print the graphic print(g) 3.1.3 Embedding graphics files Journals frequently require graphics files to be submitted separately from the manuscript. In this case, the graphic can be created and saved as a file and then inserted in the Rmd using code, but also accessed as a a stand-alone file. Let's take the previous example, but add correlation coefficients and other embellishments, create a graphics file and add the graphics into the Rmd. The base graphics file is created using the pdf() function, although png() also works if that is the desired output format. PDF is a vector format, so it generally renders better over different zoom levels. pdf(file = &quot;ah_age_hist.pdf&quot;, width = 5, height = 5) hist(ages$age, xlab = &quot;age (years)&quot;, las = 1) x &lt;- dev.off() Here we create a PNG format file: png(file = &quot;ah_age_hist.png&quot;, width = 5, height = 5, units = &quot;in&quot;, res = 300) hist(ages$age, xlab = &quot;age (years)&quot;, las = 1) x &lt;- dev.off() ggplot2 graphics can be saved using ggsave(), e.g., for both PDF and PNG outputs. The dpi argument is important for bitmap images. ggsave(filename = &quot;ah_age_hist_ggplot.pdf&quot;, plot = g, device = &quot;pdf&quot;, width = 5, height = 5) ggsave(filename = &quot;ah_age_hist_ggplot.png&quot;, plot = g, device = &quot;png&quot;, width = 5, height = 5, units = &quot;in&quot;, dpi = 300) Graphics can be added using several methods. 3.1.3.1 knitr The knitr::include_graphics() function can be used to insert image files, with the caution that inserted PDF files may produce unwanted results. The syntax is: ```{r} include_graphics(&quot;graphics_filename&quot;) ``` and the code chunk can include out.width, out.height and other options. Here we insert a PDF with no code chunk options, which presents the image with a scroll bar, rather than the full image: include_graphics(&quot;ah_age_hist.pdf&quot;) Here we specify in the code chunk options out.height = &quot;360px&quot;, out.width='360px', fig.align='left', include_graphics(&quot;ah_age_hist.pdf&quot;) ... and with code chunk options out.height = &quot;400px&quot;, out.width='100%', fig.align='left' include_graphics(&quot;ah_age_hist.pdf&quot;) It seems that embedding PDF files is not optimal. Here we insert a PNG: with no code chunk options: include_graphics(&quot;ah_age_hist_ggplot.png&quot;) and with code chunk option out.width = &quot;50%&quot; include_graphics(&quot;ah_age_hist_ggplot.png&quot;) So embedding bitmapped images appears to work better than embedding PDF files. 3.1.3.2 Markdown: ![caption](filename) The native Markdown syntax: ![](filename) includes a graphics file with an optional caption, e.g., here, a PDF with no caption, ![](ah_age_hist.pdf) The structure ![]() indicates this is an inserted graphic; a caption can be specified by including text within the square brackets, e.g., displays the caption below the inserted image (but with no caption number!). ![Add Health respondent age histogram](ah_age_hist_ggplot.pdf) Add Health respondent age histogram ... although it seems that inserting a PDF does odd things with image scrolling, while a PNG inserts the complete image without scroll bars. ![Add Health respondent age histogram](ah_age_hist_ggplot.png): Add Health respondent age histogram 3.1.3.3 HTML &lt;img&gt; tag If the file is to be rendered as HTML, and the image is a bitmap, rather than vector PDF graphics, the &lt;img&gt; tag can be used. Different utilities can be used to convert PDF to bitmapped formats, e.g., ImageMagick and GraphicsMagick. &lt;img src=&quot;ah_age_hist_ggplot.png&quot;&gt; Including a percentage of page width: &lt;img src=&quot;ah_age_hist_ggplot.png&quot; width=&quot;30%&quot;&gt; 3.2 Tables in R Markdown We will look at three methods of including tables in R Markdown documents, using the packages knitr (with kableExtra), pander, and stargazer. For the example table, we will use the frequency table of health \\(\\times\\) White and African American from Assignment 2: dat &lt;- readstata13::read.dta13(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta&quot;) # ordered factor; use fct_rev to establish the correct ordering where better health ranks higher dat %&lt;&gt;% mutate(h1gh1 = fct_rev(as.ordered(h1gh1))) # stratify health; first we need to catch the &quot;don&#39;t know&quot; and &quot;refused&quot; as NAs dat %&lt;&gt;% mutate(health = case_when( h1gh1 &lt;= &quot;(6) Refused&quot; ~ as.character(NA), h1gh1 &gt; &quot;(3) Good&quot; ~ &quot;high&quot;, h1gh1 &lt;= &quot;(3) Good&quot; ~ &quot;low&quot; )) # tabulate by White tabhealth_white &lt;- dat %&gt;% group_by(health, white = h1gi6a) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(&quot;%&quot; = round(n / sum(n) * 100, 2)) # tabulate by African Americal tabhealth_afram &lt;- dat %&gt;% group_by(health, afram = h1gi6b) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(&quot;%&quot; = round(n / sum(n) * 100, 2)) # column-bind and remove the second &quot;health&quot; column sum_health_white_afram &lt;- cbind(tabhealth_white, tabhealth_afram) %&gt;% select(-5) 3.2.1 kntir (kable()) and kableExtra The simple table using kable() is not too nice to read. kable(sum_health_white_afram) health...1 white n...3 %...4 afram n...7 %...8 high Not marked 1486 33.36 Not marked 3309 74.28 high Marked 2962 66.49 Marked 1139 25.57 high Refused 2 0.04 Refused 2 0.04 high Don't know 5 0.11 Don't know 5 0.11 low Not marked 704 34.49 Not marked 1553 76.09 low Marked 1328 65.07 Marked 479 23.47 low Refused 1 0.05 Refused 1 0.05 low Don't know 8 0.39 Don't know 8 0.39 NA Not marked 1 12.50 Not marked 4 50.00 NA Marked 4 50.00 Marked 1 12.50 NA Refused 1 12.50 Refused 1 12.50 NA Don't know 2 25.00 Don't know 2 25.00 So we add some kabelExtra options, : kable(sum_health_white_afram, col.names = c(&quot;health&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;)) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ## Warning in if (!full_width) {: the condition has length &gt; 1 and only the first element will be used health race n % race n % high Not marked 1486 33.36 Not marked 3309 74.28 high Marked 2962 66.49 Marked 1139 25.57 high Refused 2 0.04 Refused 2 0.04 high Don't know 5 0.11 Don't know 5 0.11 low Not marked 704 34.49 Not marked 1553 76.09 low Marked 1328 65.07 Marked 479 23.47 low Refused 1 0.05 Refused 1 0.05 low Don't know 8 0.39 Don't know 8 0.39 NA Not marked 1 12.50 Not marked 4 50.00 NA Marked 4 50.00 Marked 1 12.50 NA Refused 1 12.50 Refused 1 12.50 NA Don't know 2 25.00 Don't know 2 25.00 However, because some column names are duplicated, it is necessary to add some column grouping: kable(sum_health_white_afram, col.names = c(&quot;health&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;)) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;White&quot; = 3, &quot;African American&quot; = 3)) ## Warning in if (!full_width) {: the condition has length &gt; 1 and only the first element will be used White African American health race n % race n % high Not marked 1486 33.36 Not marked 3309 74.28 high Marked 2962 66.49 Marked 1139 25.57 high Refused 2 0.04 Refused 2 0.04 high Don't know 5 0.11 Don't know 5 0.11 low Not marked 704 34.49 Not marked 1553 76.09 low Marked 1328 65.07 Marked 479 23.47 low Refused 1 0.05 Refused 1 0.05 low Don't know 8 0.39 Don't know 8 0.39 NA Not marked 1 12.50 Not marked 4 50.00 NA Marked 4 50.00 Marked 1 12.50 NA Refused 1 12.50 Refused 1 12.50 NA Don't know 2 25.00 Don't know 2 25.00 We could also add some row groupings: sum_health_white_afram %&gt;% select(-1) %&gt;% kable(col.names = c(&quot;race&quot;, &quot;n&quot;, &quot;%&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;), align=c(rep(&#39;r&#39;,times=6))) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) %&gt;% add_header_above(c(&quot;White&quot; = 3, &quot;African American&quot; = 3)) %&gt;% pack_rows(&quot;health high&quot;, 1, 4) %&gt;% pack_rows(&quot;health low&quot;, 5, 8) %&gt;% pack_rows(&quot;health N/A&quot;, 9, 12) ## Warning in if (!full_width) {: the condition has length &gt; 1 and only the first element will be used White African American race n % race n % health high Not marked 1486 33.36 Not marked 3309 74.28 Marked 2962 66.49 Marked 1139 25.57 Refused 2 0.04 Refused 2 0.04 Don't know 5 0.11 Don't know 5 0.11 health low Not marked 704 34.49 Not marked 1553 76.09 Marked 1328 65.07 Marked 479 23.47 Refused 1 0.05 Refused 1 0.05 Don't know 8 0.39 Don't know 8 0.39 health N/A Not marked 1 12.50 Not marked 4 50.00 Marked 4 50.00 Marked 1 12.50 Refused 1 12.50 Refused 1 12.50 Don't know 2 25.00 Don't know 2 25.00 3.2.2 stargazer The stargazer package is especially good for PDF outputs, but is fairly limited for HTML output. stargazer(sum_health_white_afram, type = &quot;html&quot;, summary = FALSE, rownames = FALSE) health...1 white n...3 %...4 afram n...7 %...8 high 1 1486 33.36 1 3309 74.28 high 2 2962 66.49 2 1139 25.57 high 3 2 0.04 3 2 0.04 high 4 5 0.11 4 5 0.11 low 1 704 34.49 1 1553 76.09 low 2 1328 65.07 2 479 23.47 low 3 1 0.05 3 1 0.05 low 4 8 0.39 4 8 0.39 1 1 12.5 1 4 50 2 4 50 2 1 12.5 3 1 12.5 3 1 12.5 4 2 25 4 2 25 3.2.3 pander pander can be used to create output HTML tables as well, although also with fewer options than knitr with kableExtra. pander(sum_health_white_afram) health...1 white n...3 %...4 afram n...7 %...8 high (0) Not marked 1486 33.36 (0) Not marked 3309 74.28 high (1) Marked 2962 66.49 (1) Marked 1139 25.57 high (6) Refused 2 0.04 (6) Refused 2 0.04 high (8) Don't know 5 0.11 (8) Don't know 5 0.11 low (0) Not marked 704 34.49 (0) Not marked 1553 76.09 low (1) Marked 1328 65.07 (1) Marked 479 23.47 low (6) Refused 1 0.05 (6) Refused 1 0.05 low (8) Don't know 8 0.39 (8) Don't know 8 0.39 NA (0) Not marked 1 12.5 (0) Not marked 4 50 NA (1) Marked 4 50 (1) Marked 1 12.5 NA (6) Refused 1 12.5 (6) Refused 1 12.5 NA (8) Don't know 2 25 (8) Don't know 2 25 3.3 Captions to support tables, figures, and equations There are several ways to support captions in R Markdown. The two main requirements for good captions: (1) automatic sequential numbering, and (2) ability to cross-reference. Here are some options for adding captions: 3.3.1 Figures 3.3.1.1 R Markdown code chunk fig.cap Code chunks can include fig_cap as an option, as shown below. However, in standard Rmd \\(\\rightarrow\\) HTML there does not appear to be a method for cross-referencing. The code chunk would look like ```{r plotcars, fig.cap=\"Cars: speed and distance\"} plot(cars) ``` Figure 3.1: Cars: speed and distance 3.3.1.2 bookdown with html_document2 output type Using the bookdown package with html_document2 output type, it is possible to cross-reference using the chunk name. For example, download and run this code fig_cap_bookdown.Rmd Which renders a file: There seems to be no difference in the HTML output using output: bookdown::html_document2: versus output: html_document: so the former is suggested as one way to include captions that support cross-referencing. 3.3.2 Tables: kable() &quot;caption&quot; Tables created with kable() can include the caption option. For example: kable(x = sum_health_white_afram, caption = &quot;Self-reported health by race&quot;) Table 3.1: Self-reported health by race health...1 white n...3 %...4 afram n...7 %...8 high Not marked 1486 33.36 Not marked 3309 74.28 high Marked 2962 66.49 Marked 1139 25.57 high Refused 2 0.04 Refused 2 0.04 high Don't know 5 0.11 Don't know 5 0.11 low Not marked 704 34.49 Not marked 1553 76.09 low Marked 1328 65.07 Marked 479 23.47 low Refused 1 0.05 Refused 1 0.05 low Don't know 8 0.39 Don't know 8 0.39 NA Not marked 1 12.50 Not marked 4 50.00 NA Marked 4 50.00 Marked 1 12.50 NA Refused 1 12.50 Refused 1 12.50 NA Don't know 2 25.00 Don't know 2 25.00 But there appears to be no direct way of cross-referencing within standard Rmd \\(\\rightarrow\\) HTML. 3.3.2.1 bookdown with html_document2 output type Similarly for figures, the bookdown package with html_document2 output type, it is possible to cross-reference using the chunk name. For example, download and run this code table_cap_bookdown.Rmd Which renders a file: 3.3.3 Equations Equations should be numbered in manuscripts. Using bookdown makes this quite easy. The equations themselves require \\(\\LaTeX\\) syntax. There are numerous web sites with examples and tutorials for creating mathematical expressions with \\(\\LaTeX\\) In this example, we include Einstein's famous equation: \\begin{equation} E=mc^2 (\\#eq:emc) \\end{equation} and the sum of squares: \\begin{equation} \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6} (\\#eq:sumn) \\end{equation} The label for the equation is set with (\\#eq:emc) and can be referenced using \\@ref(eq:emc). Operationalized, we see: Einstein's equation, energy equals mass times the square of the speed of light is shown in (3.1). \\[\\begin{equation} E=mc^2 \\tag{3.1} \\end{equation}\\] To make a sum of squares of n first integers, see (3.2). \\[\\begin{equation} \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6} \\tag{3.2} \\end{equation}\\] 3.3.4 captioner for any captioning and cross-referencing figures and tables The captioner package provides a flexible framework for captioning both tables and figures. The R code to do this: library(captioner) table_nums &lt;- captioner(prefix = &quot;Table&quot;) figure_nums &lt;- captioner(prefix = &quot;Figure&quot;) The table_nums() and figure_nums() functions are used to create captions and cross-references, and are not tied to any specific figure or table, as is the case with kable table captions and R code chunk fig.cap. A caption is created, e.g., for a figure: `r figure_nums(name = &quot;figname&quot;, caption = &quot;My Caption&quot;)` and referenced, e.g., `r figure_nums(name = &quot;figname&quot;, display = &quot;cite&quot;)` It does not matter whether the reference precedes or comes after the caption itself. Another benefit to using captioner is that the output can be formatted using markdown syntax. For example, to format the caption in italics, use underscores: _`r figure_nums(name = &quot;figname&quot;, caption = &quot;My Caption&quot;)`_ Although this method requires a bit more coding, it allows great flexibility. A comlete example: As shown in Figure 1, the distribution of age has a slight negative skew. # how many unique bins? bins &lt;- length(unique(ages$age)) # create the graphic g &lt;- ggplot(data = ages, mapping = aes(x = age)) + geom_histogram(bins = bins) # print the graphic print(g) Figure 1: Add Health age histogram Similarly, we can present the same data as a frequency table, as shown in Table 1. Table 1: Add Health age frequency table ages %&gt;% group_by(age) %&gt;% summarise(n = n()) %&gt;% mutate(cumsum = cumsum(n), &quot;%&quot; = round(n / sum(n) * 100, 1), &quot;cum %&quot; = round(cumsum(n / sum(n) * 100), 1)) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ## Warning in if (!full_width) {: the condition has length &gt; 1 and only the first element will be used age n cumsum % cum % 12 9 9 0.1 0.1 13 578 587 8.9 9.0 14 903 1490 13.9 22.9 15 1081 2571 16.6 39.5 16 1162 3733 17.9 57.4 17 1169 4902 18.0 75.4 18 1149 6051 17.7 93.1 19 389 6440 6.0 99.1 20 43 6483 0.7 99.7 21 18 6501 0.3 100.0 3.4 R Markdown to Microsoft Word Microsoft Word (&quot;Word&quot;), is used widely to document research. Because of its advanced word processing and &quot;track changes&quot; capabilities, it is commonly used for preparation of manuscripts. Using R to generate output for Word is often a tedious process (e.g., create CSV files \\(\\rightarrow\\) paste the contents \\(\\rightarrow\\) convert to table; export R graphics with png() or ggsave() \\(\\rightarrow\\) insert the file). RMarkdown can be used to generate Word documents. This should be thought of as a one-way operation. That is to say, when a team works on a manuscript using Word, the typical work flow is that the lead author creates the first draft. Other authors make changes to the document using tracked changes. When the manuscript circulates over all authors, the lead author decides which changes to accept and which to reject, resulting in a new version. The process continues until the group of authors agrees that the manuscript is ready for publication. Unfortunately there is no backwards path to take an existing Word docx and regenerate an Rmd (e.g., after you and your colleagues made a lot of changes to the Word docx). Nevertheless using this method could save you some &quot;busy work&quot; time in Word, as well as to provide a common stylistic template for your R outputs if you will be generating Word documents. To export to a Word document, the following work flow should be followed: Create a bare-bones Rmd file that contains all of the elements you want in your output, but little actual content. Render the Rmd file to a Word docx file. Open the docx file in Word and make any stylistic changes using Word styles (see the workshop Microsoft Word for the Social Sciences) Use the style-edited docx file as a template in the Rmd file. Write your complete Rmd file with the content you want to have placed in the Word docx file and then render. The output docx file will have the same stylistic configuration as the template docx. A more detailed work flow: To use Word output, first make a minimal RMarkdown document with Word output. Save the Rmd file and knit to to Word. The output document will have the elements from the Rmd file. The important part of this is that the Word document will have a number of styles. Make any changes to the styles or margins. This will become the template for the output containing the actual scientific content. Do not add, remove, or rename any styles in this document! Save a copy of the document with any stylistic changes. For example, here are some changes to the header styles: Presumably, all of the styles in the output docx can be modified: After you have made any changes, save the file as a &quot;template&quot;: In the YAML header of the Rmd file with your scientific content, this construction, in which you specify the path name to the template document. output: word_document: reference_docx: &quot;template.docx&quot; When the Rmd file is rendered to a Word document, the stylistic changes will be applied to the output. For example, just changing the head matter of the previous document and re-rendering shows that the heading styles were applied as defined. Although this overall functionality is somewhat limited, if you do have some Rmd code that generates some scientific content, and you want to output to a Word document with predefined formats, this will save you some busy work of reformatting. 3.5 R Markdown output There are two different basic output formats available, document and presentation. As of this writing, the list of specific output types includes: beamer_presentation context_document github_document html_document ioslides_presentation latex_document md_document odt_document pdf_document powerpoint_presentation rtf_document slidy_presentation word_document Various packages can also specify their own output types, e.g., bookdown::html_document2 or `tufte::tufte_html. 3.5.1 R Markdown rendering to specific formats Remdering R Markdown files is done at the R console using the rmarkdown::render() function, e.g., rmarkdown::render(input = &quot;input_filename.Rmd&quot;) or by clicking the Knit control in RSTudio. If the YAML header specifies multiple output formats, the first listed format will be used for the output if other options are not specified in the render() function call. For example, for this header, the default output format is bookdown::html_document2 --- title: &quot;A Document&quot; author: &quot;Jane Doe&quot; date: &quot;2021-01-23&quot; output: bookdown::html_document2: default pdf_document: default html_document: default word_document: default --- The RStudio interface will present the listed choices in the Knit pick list in the GUI, so the desired output format can be selected interactively: Other supported outputs can be created, including those that are not listed in the YAML header by specifying the output format in the render() function, e.g. to create a Slidy presentation: rmarkdown::render(input = &quot;input_filename.Rmd&quot;, output_format = &quot;slidy_presentation&quot;) To render a PDF file, use e.g., rmarkdown::render(input = &quot;input_filename.Rmd&quot;, output_format = &quot;pdf_document&quot;) Using code rather than the RStudio GUI allows more flexible automation; you could have an R script that runs the render() function as part of a multi-step workflow. For example, if you had a continuous data collection process, the work flow could be coded and run with cron to generate a new PDF (or other file type) file on a daily basis. 3.5.2 Testing output_type() Because different output formats support (or do not support) different features, a test can be made for the output format to determine which code to run, using is_html_output() and is_latex_output(). Any R code within the Rmd file can be run or not run based on these tests. For a working example, download and render the file output_type_test. Using a single source, the output rendered as HTML appears as whereas the PDF output is rendered as There appears to be no similar test for MS Word output, so for creating Word documents from Rmd files, it is suggested to create the Rmd from scratch with the intention of creating only Word output. 3.6 Advantages and disadvantages of PDF Portable document format (PDF) has a number of advantages: Document formatting is maintained. Font face and positioning of elements is consistent. When some other formats are shared (e.g., MS Word), formatting is inconsistent. The format is widely used and able to be created from a variety of different proprietary and open software applications. Files are often parsimonious in size. When large images are embedded, the file sizes can grow, but there are often options for downscaling images for smaller file size. Files can be protected with passwords. Files are supported across all operating systems (Windows, Mac, Linux, UNIX). Multiple different elements can be included (text, images, tables). The format has stood the test of time, having been introduced 1993. The standard was opened in 2008, allowing developers to create PDF outputs. This has led to PDF being the standard for fixed-format documents. The disadvantages: 1. Direct editing of PDF files is not straightforward (usually requires dedicated software), and often results in undesired layout changes. Therefore this is not a good format for collaborative editing. 1. Copy-and-paste from PDF often results in missing or extra spaces or strange characters. 1. R functions that produce HTML output cannot be used in PDF outputs. 3.7 Bibliography in R Markdown The pandoc engine that performs document conversion can generate bibliographies. See Bibliographies and Citations for detailed information. For this exercise, we will be using \\({B\\kern-0.1emi\\kern-0.017emb}\\kern-0.15em\\TeX\\) formatted references. The YAML header needs to be formatted to include the bibliography file, which should either have a complete path name or be located in the same directory as the Rmd file. Similarly, any CSL (Citation Style Language) file should be specified. CSL files can be obtained from the Zotero Style Repository The YAML header would include something of the form: --- title: &quot;My glorious, shiny dissertation&quot; output: bookdown::html_document2 bibliography: myreferences_20200121.bib csl: biomed-central.csl --- When citations are made to references, the corresponding record will be automatically added to the end of the document. For examples of syntax for both APA-like and AMA-like references and bibliographies, see the files APA: HTML; Rmd AMA: HTML; Rmd Source code for this document 03-week03.Rmd # Week 3 {#week3} ```{r, echo=FALSE} library(tidyverse) library(magrittr) library(kableExtra) library(stargazer) library(pander) library(psych) library(readstata13) library(knitr) library(pander) library(stargazer) library(animation) library(captioner) table_nums &lt;- captioner(prefix = &quot;Table&quot;) figure_nums &lt;- captioner(prefix = &quot;Figure&quot;) ``` &lt;style&gt; .border1 { border-width: 1px; border-color: black; border-style: solid; } &lt;/style&gt; &lt;h2&gt;Topics: Graphics and Tables in R; Captions and cross-references; R Markdown to MS Word; Bibliography&lt;/h2&gt; Because of its extensibility, HTML can be considered a preferred output from R Markdown. However, document formats are often necessary, particularly for term papers, theses/dissertations, and manuscripts for submission to scholarly journals. In this week&#39;s lesson, we will focus on the creation of these two output types, including adding bibliographies (which also applies to HTML output), and some basic `ggplot` graphics. For both PDF and Word output, much of the structure of your Rmd files will be the same as for HTML output. The major difference is how tables are handled, which we will explore in some detail. Static graphics are handled similarly across all output formats, other than HTML output can support dynamic graphics, such as the Leaflet map we saw in the first lesson, and responsive graphics as in [Shiny](https://shiny.rstudio.com/). ## Graphics in R Markdown Data-driven graphics in Rmd files are typically created as base R graphics or with the `ggplot2` package. This tutorial is not intended to provide anywhere near a comprehensive treatment of creating graphics from data, but will provide instruction on some options for creating and including data-driven graphics as well as inserting graphics from image files. See [Tips and tricks for working with images and figures in R Markdown documents](http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/) for a good explanation. ### Base R graphics To include base R graphics, simply place the code to generate the graphic in an R code block, e.g., using the Add Health data from last week ([AHWave1_v1.dta](data/AHWave1_v1.dta)): ```` ```{r}`r &#39;&#39;` # since loading the data takes awhile, only do this if necessary if(!exists(&quot;dat&quot;)){ dat &lt;- read.dta13(&quot;data/AHwave1_v1.dta&quot;) } # birth year = h1gi1y # drop &quot;Refused&quot; birth year # for birth year and interview year, replace anything before white space, convert to numeric # subtract interview year - birth year ages &lt;- dat %&gt;% filter(! str_detect(h1gi1y, &quot;Refused&quot;)) %&gt;% select(iyear, h1gi1y) %&gt;% mutate(yi = str_replace(iyear, &quot;.*\\\\s&quot;, &quot;&quot;) %&gt;% as.numeric(), yb = str_replace(h1gi1y, &quot;.*\\\\s&quot;, &quot;&quot;) %&gt;% as.numeric(), age = yi - yb) # create a histogram using base graphics hist(ages$age, xlab = &quot;age (years)&quot;, las = 1) ``` ```` ... which will render the graph: ```{r, echo=FALSE, warning=FALSE} # since loading the data takes awhile, only do this if necessary if(!exists(&quot;dat&quot;)){ dat &lt;- read.dta13(&quot;data/AHwave1_v1.dta&quot;) } # birth year = h1gi1y # drop &quot;Refused&quot; birth year # for birth year and interview year, replace anything before white space, convert to numeric # subtract interview year - birth year ages &lt;- dat %&gt;% filter(! str_detect(h1gi1y, &quot;Refused&quot;)) %&gt;% select(iyear, h1gi1y) %&gt;% mutate(yi = str_replace(iyear, &quot;.*\\\\s&quot;, &quot;&quot;) %&gt;% as.numeric(), yb = str_replace(h1gi1y, &quot;.*\\\\s&quot;, &quot;&quot;) %&gt;% as.numeric(), age = yi - yb) hist(ages$age, xlab = &quot;age (years)&quot;, las = 1) ``` ### `ggplot2` graphics The `ggplot2` package creates compelling graphics that use a common syntax. The main difference between base R graphics and `ggplot2` graphics is that simply issuing the `plot()` or related command (e.g., `hist()`, `barplot()`) adds the graphic to the output, whereas with `ggplot()` it is necessary to issue a command that prints the graphic. Following the previous example: ```{r} # how many unique bins? bins &lt;- length(unique(ages$age)) # create the graphic g &lt;- ggplot(data = ages, mapping = aes(x = age)) + geom_histogram(bins = bins) # print the graphic print(g) ``` ### Embedding graphics files Journals frequently require graphics files to be submitted separately from the manuscript. In this case, the graphic can be created and saved as a file and then inserted in the Rmd using code, but also accessed as a a stand-alone file. Let&#39;s take the previous example, but add correlation coefficients and other embellishments, create a graphics file and add the graphics into the Rmd. The base graphics file is created using the `pdf()` function, although `png()` also works if that is the desired output format. PDF is a vector format, so it generally renders better over different zoom levels. ```{r, message=FALSE} pdf(file = &quot;ah_age_hist.pdf&quot;, width = 5, height = 5) hist(ages$age, xlab = &quot;age (years)&quot;, las = 1) x &lt;- dev.off() ``` Here we create a PNG format file: ```{r, message=FALSE} png(file = &quot;ah_age_hist.png&quot;, width = 5, height = 5, units = &quot;in&quot;, res = 300) hist(ages$age, xlab = &quot;age (years)&quot;, las = 1) x &lt;- dev.off() ``` `ggplot2` graphics can be saved using `ggsave()`, e.g., for both PDF and PNG outputs. The `dpi` argument is important for bitmap images. ```{r} ggsave(filename = &quot;ah_age_hist_ggplot.pdf&quot;, plot = g, device = &quot;pdf&quot;, width = 5, height = 5) ggsave(filename = &quot;ah_age_hist_ggplot.png&quot;, plot = g, device = &quot;png&quot;, width = 5, height = 5, units = &quot;in&quot;, dpi = 300) ``` Graphics can be added using several methods. #### `knitr` The `knitr::include_graphics()` function can be used to insert image files, with the caution that inserted PDF files may produce unwanted results. The syntax is: ```` ```{r}`r &#39;&#39;` include_graphics(&quot;graphics_filename&quot;) ``` ```` and the code chunk can include `out.width`, `out.height` and other options. \\ Here we insert a PDF with no code chunk options, which presents the image with a scroll bar, rather than the full image: ```{r} include_graphics(&quot;ah_age_hist.pdf&quot;) ``` Here we specify in the code chunk options `out.height = &quot;360px&quot;, out.width=&#39;360px&#39;, fig.align=&#39;left&#39;`, ```{r, out.height = &quot;360px&quot;, out.width=&#39;360px&#39;, fig.align=&#39;left&#39;} include_graphics(&quot;ah_age_hist.pdf&quot;) ``` \\ ... and with code chunk options `out.height = &quot;400px&quot;, out.width=&#39;100%&#39;, fig.align=&#39;left&#39;` ```{r, out.height = &quot;400px&quot;, out.width=&#39;100%&#39;, fig.align=&#39;left&#39;} include_graphics(&quot;ah_age_hist.pdf&quot;) ``` \\ It seems that embedding PDF files is not optimal. Here we insert a PNG: with no code chunk options: ```{r} include_graphics(&quot;ah_age_hist_ggplot.png&quot;) ``` and with code chunk option `out.width = &quot;50%&quot;` ```{r, out.width = &quot;50%&quot;} include_graphics(&quot;ah_age_hist_ggplot.png&quot;) ``` So embedding bitmapped images appears to work better than embedding PDF files. #### Markdown: `![caption](filename)` The native Markdown syntax: ``` ![](filename) ``` includes a graphics file with an optional caption, e.g., here, a PDF with no caption, `![](ah_age_hist.pdf)` ![](ah_age_hist.pdf) \\ The structure `![]()` indicates this is an inserted graphic; a caption can be specified by including text within the square brackets, e.g., displays the caption below the inserted image (but with no caption number!). ```![Add Health respondent age histogram](ah_age_hist_ggplot.pdf)``` ![Add Health respondent age histogram](ah_age_hist_ggplot.pdf) ... although it seems that inserting a PDF does odd things with image scrolling, while a PNG inserts the complete image without scroll bars. ```![Add Health respondent age histogram](ah_age_hist_ggplot.png)```: ![Add Health respondent age histogram](ah_age_hist_ggplot.png) #### HTML `&lt;img&gt;` tag If the file is to be rendered as HTML, _and_ the image is a bitmap, rather than vector PDF graphics, the `&lt;img&gt;` tag can be used. Different utilities can be used to convert PDF to bitmapped formats, e.g., [ImageMagick](https://imagemagick.org/index.php) and [GraphicsMagick](http://www.graphicsmagick.org/). ```&lt;img src=&quot;ah_age_hist_ggplot.png&quot;&gt;``` &lt;img src=&quot;ah_age_hist_ggplot.png&quot;&gt; Including a percentage of page width: ```&lt;img src=&quot;ah_age_hist_ggplot.png&quot; width=&quot;30%&quot;&gt;``` &lt;img src=&quot;ah_age_hist_ggplot.png&quot; width=&quot;30%&quot;&gt; ## Tables in R Markdown We will look at three methods of including tables in R Markdown documents, using the packages `knitr` (with `kableExtra`), `pander`, and `stargazer`. For the example table, we will use the frequency table of health $\\times$ White and African American from Assignment 2: ```{r, warning=FALSE, message=FALSE, error=FALSE} dat &lt;- readstata13::read.dta13(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta&quot;) # ordered factor; use fct_rev to establish the correct ordering where better health ranks higher dat %&lt;&gt;% mutate(h1gh1 = fct_rev(as.ordered(h1gh1))) # stratify health; first we need to catch the &quot;don&#39;t know&quot; and &quot;refused&quot; as NAs dat %&lt;&gt;% mutate(health = case_when( h1gh1 &lt;= &quot;(6) Refused&quot; ~ as.character(NA), h1gh1 &gt; &quot;(3) Good&quot; ~ &quot;high&quot;, h1gh1 &lt;= &quot;(3) Good&quot; ~ &quot;low&quot; )) # tabulate by White tabhealth_white &lt;- dat %&gt;% group_by(health, white = h1gi6a) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(&quot;%&quot; = round(n / sum(n) * 100, 2)) # tabulate by African Americal tabhealth_afram &lt;- dat %&gt;% group_by(health, afram = h1gi6b) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(&quot;%&quot; = round(n / sum(n) * 100, 2)) # column-bind and remove the second &quot;health&quot; column sum_health_white_afram &lt;- cbind(tabhealth_white, tabhealth_afram) %&gt;% select(-5) ``` ### `kntir` (`kable()`) and `kableExtra` The simple table using `kable()` is not too nice to read. ```{r} kable(sum_health_white_afram) ``` So we add some `kabelExtra` options, : ```{r} kable(sum_health_white_afram, col.names = c(&quot;health&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;)) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ``` However, because some column names are duplicated, it is necessary to add some column grouping: ```{r} kable(sum_health_white_afram, col.names = c(&quot;health&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;)) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;White&quot; = 3, &quot;African American&quot; = 3)) ``` We could also add some row groupings: ```{r} sum_health_white_afram %&gt;% select(-1) %&gt;% kable(col.names = c(&quot;race&quot;, &quot;n&quot;, &quot;%&quot;, &quot;race&quot;, &quot;n&quot;, &quot;%&quot;), align=c(rep(&#39;r&#39;,times=6))) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) %&gt;% add_header_above(c(&quot;White&quot; = 3, &quot;African American&quot; = 3)) %&gt;% pack_rows(&quot;health high&quot;, 1, 4) %&gt;% pack_rows(&quot;health low&quot;, 5, 8) %&gt;% pack_rows(&quot;health N/A&quot;, 9, 12) ``` ### `stargazer` The [`stargazer`](https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf) package is especially good for PDF outputs, but is fairly limited for HTML output. ```{r results=&#39;asis&#39;} stargazer(sum_health_white_afram, type = &quot;html&quot;, summary = FALSE, rownames = FALSE) ``` ### `pander` `pander` can be used to create output HTML tables as well, although also with fewer options than `knitr` with `kableExtra`. ```{r} pander(sum_health_white_afram) ``` ## Captions to support tables, figures, and equations There are several ways to support captions in R Markdown. The two main requirements for good captions: (1) automatic sequential numbering, and (2) ability to cross-reference. Here are some options for adding captions: ### Figures #### R Markdown code chunk `fig.cap` Code chunks can include `fig_cap` as an option, as shown below. However, in standard Rmd $\\rightarrow$ HTML there does not appear to be a method for cross-referencing. The code chunk would look like &lt;pre&gt;&lt;code&gt;```{r plotcars, fig.cap=&quot;Cars: speed and distance&quot;} plot(cars) ```&lt;/code&gt;&lt;/pre&gt; ```{r plotcars, fig.cap=&quot;Cars: speed and distance&quot;, echo=FALSE} plot(cars) ``` #### `bookdown` with `html_document2` output type Using the `bookdown` package with `html_document2` output type, it is possible to cross-reference using the chunk name. For example, download and run this code [fig_cap_bookdown.Rmd](files/fig_cap_bookdown.Rmd) Which renders a file: ![](images/week03/fig_ref.png) There seems to be no difference in the HTML output using ``` output: bookdown::html_document2: ``` versus ``` output: html_document: ```` so the former is suggested as one way to include captions that support cross-referencing. ### Tables: `kable()` &quot;caption&quot; Tables created with `kable()` can include the `caption` option. For example: ```{r} kable(x = sum_health_white_afram, caption = &quot;Self-reported health by race&quot;) ``` But there appears to be no direct way of cross-referencing within standard Rmd $\\rightarrow$ HTML. #### `bookdown` with `html_document2` output type Similarly for figures, the `bookdown` package with `html_document2` output type, it is possible to cross-reference using the chunk name. For example, download and run this code [table_cap_bookdown.Rmd](files/table_cap_bookdown.Rmd) Which renders a file: ![](images/week03/tab_ref.png) ### Equations Equations should be numbered in manuscripts. Using `bookdown` makes this quite easy. The equations themselves require $\\LaTeX$ syntax. There are numerous web sites with examples and tutorials for creating mathematical expressions with $\\LaTeX$ In this example, we include Einstein&#39;s famous equation: &lt;pre&gt; \\begin{equation} E=mc^2 (\\#eq:emc) \\end{equation} &lt;/pre&gt; and the sum of squares: &lt;pre&gt; \\begin{equation} \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6} (\\#eq:sumn) \\end{equation} &lt;/pre&gt; The label for the equation is set with `(\\#eq:emc)` and can be referenced using `\\@ref(eq:emc)`. Operationalized, we see: Einstein&#39;s equation, energy equals mass times the square of the speed of light is shown in \\@ref(eq:emc). \\begin{equation} E=mc^2 (\\#eq:emc) \\end{equation} To make a sum of squares of _n_ first integers, see \\@ref(eq:sumn). \\begin{equation} \\sum_{i=1}^n i^2 = \\frac{n(n+1)(2n+1)}{6} (\\#eq:sumn) \\end{equation} ### `captioner` for any captioning and cross-referencing figures and tables The `captioner` package provides a flexible framework for captioning both tables and figures. The R code to do this: ``` library(captioner) table_nums &lt;- captioner(prefix = &quot;Table&quot;) figure_nums &lt;- captioner(prefix = &quot;Figure&quot;) ``` The `table_nums()` and `figure_nums()` functions are used to create captions and cross-references, and are not tied to any specific figure or table, as is the case with `kable` table captions and R code chunk `fig.cap`. A caption is created, e.g., for a figure: `` `r figure_nums(name = &quot;figname&quot;, caption = &quot;My Caption&quot;)` `` and referenced, e.g., `` `r figure_nums(name = &quot;figname&quot;, display = &quot;cite&quot;)` `` It does not matter whether the reference precedes or comes after the caption itself. Another benefit to using `captioner` is that the output can be formatted using markdown syntax. For example, to format the caption in italics, use underscores: `` _`r figure_nums(name = &quot;figname&quot;, caption = &quot;My Caption&quot;)`_ `` Although this method requires a bit more coding, it allows great flexibility. A comlete example: As shown in `r figure_nums(name = &quot;ageplot&quot;, display = &quot;cite&quot;)`, the distribution of age has a slight negative skew. ```{r, fig.width=3, fig.height=3} # how many unique bins? bins &lt;- length(unique(ages$age)) # create the graphic g &lt;- ggplot(data = ages, mapping = aes(x = age)) + geom_histogram(bins = bins) # print the graphic print(g) ``` _`r figure_nums(name = &quot;ageplot&quot;, caption = &quot;Add Health age histogram&quot;)`_ Similarly, we can present the same data as a frequency table, as shown in `r table_nums(name = &quot;agetab&quot;, display = &quot;cite&quot;)`. _`r table_nums(name = &quot;agetab&quot;, caption = &quot;Add Health age frequency table&quot;)`_ ```{r} ages %&gt;% group_by(age) %&gt;% summarise(n = n()) %&gt;% mutate(cumsum = cumsum(n), &quot;%&quot; = round(n / sum(n) * 100, 1), &quot;cum %&quot; = round(cumsum(n / sum(n) * 100), 1)) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = F, position = &quot;left&quot;) ``` ## R Markdown to Microsoft Word Microsoft Word (&quot;Word&quot;), is used widely to document research. Because of its advanced word processing and &quot;track changes&quot; capabilities, it is commonly used for preparation of manuscripts. Using R to generate output for Word is often a tedious process (e.g., create CSV files $\\rightarrow$ paste the contents $\\rightarrow$ convert to table; export R graphics with `png()` or `ggsave()` $\\rightarrow$ insert the file). RMarkdown can be used to generate Word documents. This should be thought of as a one-way operation. That is to say, when a team works on a manuscript using Word, the typical work flow is that the lead author creates the first draft. Other authors make changes to the document using tracked changes. When the manuscript circulates over all authors, the lead author decides which changes to accept and which to reject, resulting in a new version. The process continues until the group of authors agrees that the manuscript is ready for publication. Unfortunately there is no backwards path to take an existing Word docx and regenerate an Rmd (e.g., after you and your colleagues made a lot of changes to the Word docx). Nevertheless using this method could save you some &quot;busy work&quot; time in Word, as well as to provide a common stylistic template for your R outputs if you will be generating Word documents. To export to a Word document, the following work flow should be followed: 1. Create a bare-bones Rmd file that contains all of the elements you want in your output, but little actual content. 1. Render the Rmd file to a Word docx file. 1. Open the docx file in Word and make any stylistic changes __using Word styles__ (see the workshop [Microsoft Word for the Social Sciences](https://csde.washington.edu/workshop/microsoft-word-for-the-social-sciences/)) 1. Use the style-edited docx file as a template in the Rmd file. 1. Write your complete Rmd file with the content you want to have placed in the Word docx file and then render. The output docx file will have the same stylistic configuration as the template docx. A more detailed work flow: To use Word output, first make a minimal RMarkdown document with Word output. ![](images/week03/20200419_233754-C__Users_phurvitz_nextcloud_uw_csde_courses_msword_soc_sci_-_RStudio.png) Save the Rmd file and knit to to Word. ![](images/week03/20200419_233851-Window.png) The output document will have the elements from the Rmd file. ![](images/week03/20200419_234510-minimal.docx_[Read-Only]_[Compatibility_Mode]_-_Word.png) The important part of this is that the Word document will have a number of styles. Make any changes to the styles or margins. This will become the template for the output containing the actual scientific content. ___Do not add, remove, or rename any styles in this document!___ Save a copy of the document with any stylistic changes. For example, here are some changes to the header styles: ![](images/week03/20200420_002233-Window.png) Presumably, all of the styles in the output docx can be modified: ![](images/week03/20210121_020407-Window.png) After you have made any changes, save the file as a &quot;template&quot;: ![](images/week03/20200419_235426-Save_As.png) In the YAML header of the Rmd file with your scientific content, this construction, in which you specify the path name to the template document. ``` output: word_document: reference_docx: &quot;template.docx&quot; ``` When the Rmd file is rendered to a Word document, the stylistic changes will be applied to the output. For example, just changing the head matter of the previous document and re-rendering shows that the heading styles were applied as defined. ![](images/week03/20200420_002536-minimal.docx_[Read-Only]_[Compatibility_Mode]_-_Word.png) Although this overall functionality is somewhat limited, if you do have some Rmd code that generates some scientific content, and you want to output to a Word document with predefined formats, this will save you some busy work of reformatting. ## R Markdown output There are two different basic output formats available, document and presentation. As of this writing, the list of specific output types includes: * `beamer_presentation` * `context_document` * `github_document` * `html_document` * `ioslides_presentation` * `latex_document` * `md_document` * `odt_document` * `pdf_document` * `powerpoint_presentation` * `rtf_document` * `slidy_presentation` * `word_document` Various packages can also specify their own output types, e.g., `bookdown::html_document2` or `tufte::tufte_html. ### R Markdown rendering to specific formats Remdering R Markdown files is done at the R console using the `rmarkdown::render()` function, e.g., ``` rmarkdown::render(input = &quot;input_filename.Rmd&quot;) ``` or by clicking the `Knit` control in RSTudio. If the YAML header specifies multiple output formats, the first listed format will be used for the output if other options are not specified in the `render()` function call. For example, for this header, the default output format is `bookdown::html_document2` ``` --- title: &quot;A Document&quot; author: &quot;Jane Doe&quot; date: &quot;2021-01-23&quot; output: bookdown::html_document2: default pdf_document: default html_document: default word_document: default --- ``` The RStudio interface will present the listed choices in the `Knit` pick list in the GUI, so the desired output format can be selected interactively: &lt;img src=&quot;../images/week03/20210124_010442-C__Users_phurvitz_OneDrive_uw_courses_csde502_csde502_winter_2021_course - RStud.png&quot; class=&quot;border1&quot;&gt; Other supported outputs can be created, including those that are not listed in the YAML header by specifying the output format in the `render()` function, e.g. to create a [Slidy](https://www.w3.org/Talks/Tools/Slidy2/#(1)) presentation: ``` rmarkdown::render(input = &quot;input_filename.Rmd&quot;, output_format = &quot;slidy_presentation&quot;) ``` To render a PDF file, use e.g., ``` rmarkdown::render(input = &quot;input_filename.Rmd&quot;, output_format = &quot;pdf_document&quot;) ``` Using code rather than the RStudio GUI allows more flexible automation; you could have an R script that runs the `render()` function as part of a multi-step workflow. For example, if you had a continuous data collection process, the work flow could be coded and run with [cron](https://www.rdocumentation.org/packages/cronR) to generate a new PDF (or other file type) file on a daily basis. ### Testing `output_type()` Because different output formats support (or do not support) different features, a test can be made for the output format to determine which code to run, using `is_html_output()` and `is_latex_output()`. Any R code within the Rmd file can be run or not run based on these tests. For a working example, download and render the file [output_type_test](files/output_type_test.Rmd). Using a single source, the [output rendered as HTML](files/output_type_test.html) appears as ![](images/week03/20210124_190945-R Markdown Output Type Test - Work - MicrosoftEdge.png) whereas the [PDF output](files/output_type_test.pdf) is rendered as ![](images/week03/20210124_191706-output_type_test.pdf - [R Markdown Output Type Test] - SumatraPDF.png) There appears to be no similar test for MS Word output, so for creating Word documents from Rmd files, it is suggested to create the Rmd from scratch with the intention of creating only Word output. ## Advantages and disadvantages of PDF Portable document format (PDF) has a number of advantages: 1. Document formatting is maintained. Font face and positioning of elements is consistent. When some other formats are shared (e.g., MS Word), formatting is inconsistent. 1. The format is widely used and able to be created from a variety of different proprietary and open software applications. 1. Files are often parsimonious in size. When large images are embedded, the file sizes can grow, but there are often options for downscaling images for smaller file size. 1. Files can be protected with passwords. 1. Files are supported across all operating systems (Windows, Mac, Linux, UNIX). 1. Multiple different elements can be included (text, images, tables). 1. The format has stood the test of time, having been introduced 1993. The standard was opened in 2008, allowing developers to create PDF outputs. This has led to PDF being the standard for fixed-format documents. The disadvantages: 1. Direct editing of PDF files is not straightforward (usually requires dedicated software), and often results in undesired layout changes. Therefore this is not a good format for collaborative editing. 1. Copy-and-paste from PDF often results in missing or extra spaces or strange characters. 1. R functions that produce HTML output cannot be used in PDF outputs. ## Bibliography in R Markdown The `pandoc` engine that performs document conversion can generate bibliographies. See [Bibliographies and Citations](https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html) for detailed information. For this exercise, we will be using ${B\\kern-0.1emi\\kern-0.017emb}\\kern-0.15em\\TeX$ formatted references. The YAML header needs to be formatted to include the bibliography file, which should either have a complete path name or be located in the same directory as the Rmd file. Similarly, any CSL (Citation Style Language) file should be specified. CSL files can be obtained from the [Zotero Style Repository ](https://www.zotero.org/styles) The YAML header would include something of the form: ``` --- title: &quot;My glorious, shiny dissertation&quot; output: bookdown::html_document2 bibliography: myreferences_20200121.bib csl: biomed-central.csl --- ``` When citations are made to references, the corresponding record will be automatically added to the end of the document. For examples of syntax for both APA-like and AMA-like references and bibliographies, see the files * APA: [HTML](files/bibliography.html); [Rmd](files/bibliography.Rmd) * AMA: [HTML](files/bibliography_ama.html); [Rmd](files/bibliography_ama.Rmd) &lt;h4&gt;Source code for this document&lt;/h4&gt; [03-week03.Rmd](03-week03.Rmd) ```{r, comment=&#39;&#39;, echo=FALSE} cat(readLines(&quot;03-week03.Rmd&quot;), sep = &#39;\\n&#39;) ``` "],["week4.html", "4 Week 4 4.1 Environments 4.2 Functions 4.3 Sampling", " 4 Week 4 Topics: Functions and sampling This week's topics are functions and sampling, the latter including a cursory treatment of loops and bootstrapping. 4.1 Environments Functions exist in environments, which are &quot;frames&quot; or collections containing objects including variables, functions, etc.). There is a global environment (.GlobalEnv) that contains all of the data, functions, in the current R session. Those objects can be enumerated with the ls() function. The reason environments are mentioned at this time is because functions instantiate environments that exist while the function is running. More on this in a bit.... 4.2 Functions Functions are sets of statements in R that are grouped together to perform a specific task or set of tasks. Functions are either built in, included in packages, or user-defined. Functions are used mainly to simplify running a series of individual commands or functions, for situations where the same process will need to be run multiple times on different inputs, or when control structures are needed (e.g., looping, logical branching). 4.2.1 Function Components The different parts of a function are: (Usually) Name: This is the actual name of the function. It is stored in an R environment as an object with this name. (Optional) Arguments: Arguments specify the inputs or options to the function. When a function is invoked, you pass a value to the argument. Arguments are optional; that is, a function may contain no arguments. Also arguments can have default values. Body: The function body contains a collection of statements that defines what the function does. Return value: The return value of a function is the last expression in the function body to be evaluated. Another important concept for functions is environments. 4.2.1.1 Name Most functions are created with code of the form function_name &lt;- function(argument(s)){ statement(s) } For example, to square a vector of numerical values: f_square &lt;- function(x){ x^2 } the function name is f_square. Some functions are not named, and are referred to as &quot;anonymous&quot; functions. For example, functions can be used within the apply family of functions. Here is an oprationalized example. # create a list of three vectors of random numbers of different random lengths # set.seed() makes the random process reproducible. set.seed(10) # vector lengths v.len &lt;- rnorm(n = 3, mean = 30, sd = 10) %&gt;% round(0) # make the random vectors set.seed(5) v1 &lt;- rnorm(n = v.len[1]) set.seed(3) v2 &lt;- rnorm(n = v.len[2]) set.seed(6) v3 &lt;- rnorm(n = v.len[3]) # create the list L &lt;- list(v1, v2, v3) # get the first value from each vector in the list lapply(X = L, FUN = function(x) {x[1]}) ## [[1]] ## [1] -0.8408555 ## ## [[2]] ## [1] -0.9619334 ## ## [[3]] ## [1] 0.269606 The last line of the code chunk is: lapply(X = L, FUN = function(x) {x[1]}) in which the body of the function is x[1], i.e., obtain the first element of a vector. But the function itself is not named, and hence &quot;anonymous.&quot; 4.2.1.2 Arguments Most functions require arguments. Arguments are used to instantiate variables within the function's environment that can be used later in the body of the function. Each argument is named, and the name is used within the function as a local variable within the function's environment. Following our example from above, f_square takes an argument named &quot;x&quot; that is a numeric vector. Here, let's modify the function to demonstrate that within the environment of the function, x is a variable: f_square_2 &lt;- function(x){ message(&quot;input:&quot;) print(x) message(&quot;output:&quot;) x^2 } f_square_2(c(1,2,3)) ## input: ## [1] 1 2 3 ## output: ## [1] 1 4 9 We can try running the function using different (or no) arguments: Here, using a vector of a single NA numeric f_square(as.numeric(NA)) ## [1] NA ... or a vector that contains a numeric NA: f_square(c(1, 2, NA)) ## [1] 1 4 NA ... or a null: f_square(NULL) ## numeric(0) ... or a vector containing a null: f_square(c(1, 2, NULL)) ## [1] 1 4 ... or with no argument at all: f_square() ## Error in f_square() : argument &quot;x&quot; is missing, with no default Some functions do not require arguments, e.g., to get the current date or time: Sys.Date() ## [1] &quot;2021-03-06&quot; Sys.time() ## [1] &quot;2021-03-06 12:23:29 PST&quot; ... and if we try to use an argument we get an error: Sys.Date(1) ## Error in Sys.Date(1) : unused argument (1) 4.2.1.2.1 Default values for arguments If you want an argument to have a default value, it is specified in the listed arguments in the form argument = value. Following our previous f_square_2() function, we can modify to print the input based on the logical argument verbose: f_square_3 &lt;- function(x, verbose = FALSE){ # only run the next lines if verbose is true if(verbose){ message(&quot;input:&quot;) print(x) message(&quot;output:&quot;) } x^2 } Here we run with the default verbose option (FALSE): f_square_3(x = c(1, 2, 3)) ## [1] 1 4 9 ... and with verbose = TRUE: f_square_3(x = c(1, 2, 3), verbose = TRUE) ## input: ## [1] 1 2 3 ## output: ## [1] 1 4 9 A more meaningful example demonstrates stratification of counts into intensity bins using accelerometry data. We will be using accelerometry from one day's data from one subject in a study. The cut points for accelerometry were identified at 0, 2690, 6167, and 9642 counts per minute, from Sasaki et al. (2011). __Sasaki JE, John D, Freedson PS. Validation and comparison of ActiGraph activity monitors. J Sci Med Sport. 2011;14(5):411-416. doi:10.1016/j.jsams.2011.04.003__ The variable vm3 is the vector magnitude measured with the accelerometer for each minute. Data: accelerometry.csv. acc &lt;- read.csv(&quot;files/accelerometry.csv&quot;) head(acc) ## time_acc vm3 ## 1 2018-09-13 02:59:00-07 0 ## 2 2018-09-13 02:58:00-07 0 ## 3 2018-09-13 02:57:00-07 0 ## 4 2018-09-13 02:56:00-07 0 ## 5 2018-09-13 02:55:00-07 0 ## 6 2018-09-13 02:54:00-07 0 The following function codes intensity by the aforementioned cut points by default and using default labels: f_acc_intensity &lt;- function(x, cuts = c(-Inf, 2690, 6167, 9642, Inf), labels = c(&quot;sedentary/low&quot;, &quot;moderate&quot;, &quot;vigorous&quot;, &quot;very vigorous&quot;)){ cut(x = acc$vm3, breaks = cuts, labels = labels) } ... and when run with the defaults to tabulate the minutes spent in different PA levels acc$intens_default &lt;- f_acc_intensity(acc$vm3) table(acc$intens_default) ## ## sedentary/low moderate vigorous very vigorous ## 1435 4 1 0 But we could run this with different thresholds and levels, where SPLA = &quot;sedentary/low physical activity&quot; and MVPA = &quot;moderate-to-very vigorous physical activity): acc$intens_2lev &lt;- f_acc_intensity(x = acc$vm3, cuts = c(-Inf, 2690, Inf), labels = c(&quot;SLPA&quot;, &quot;MVVPA&quot;)) table(acc$intens_2lev) ## ## SLPA MVVPA ## 1435 5 4.2.1.2.2 The ... argument When functions do not have a known a priori number or set of arguments, or when a large number of arguments is to be passed to another function the ... argument is used. We will not cover this but you are encouraged to read more: How to Use the Dots Argument in R; The three-dots construct in R. 4.2.1.3 Body The function's body contains all of the code to perform the purpose of the function. Following our initial example, the body of the function is simply x^2 The body can be as simple or complicated as it needs to be in order to achieve the desired result. 4.2.1.4 Return value The return value is either the last evaluated expression in the function or an object specified using the return() function. In our original f_square() function, the return value is x^2 since no other return() value was specified, e.g., for a vector of one element: f_square &lt;- function(x){ x^2 } f_square(3) ## [1] 9 or a vector with multiple elements: f_square(c(1,2,3)) ## [1] 1 4 9 An simple example of explicitly specifying return values is shown in this numerical comparison function: f_compare &lt;- function(x, y){ # either missing? if(nargs() != 2) return(&quot;invalid number of arguments&quot;) # numeric? if(!is.numeric(x) | !is.numeric(y)){ return(sprintf(&quot;%s or %s is not numeric.&quot;, x, y)) } # comparisons follow if(x &gt; y){ return(sprintf(&quot;%s is greater than %s&quot;, x, y)) } if(x &lt; y) { return(sprintf(&quot;%s is less than %s&quot;, x, y)) } if(x == y){ return(sprintf(&quot;%s equals %s&quot;, x, y)) } } If you want to handle an expected error, you can print an informative message and use return(invisible()), which returns nothing at all (whereas return() results in a NULL) e.g., here without invisible(): f_readfile &lt;- function(fname){ if(!file.exists(fname)){ warning(paste(fname, &quot;does not exist!&quot;)) return() } else { read.csv(fname) } } f_readfile(&quot;foobar.txt&quot;) ## Warning in f_readfile(&quot;foobar.txt&quot;): foobar.txt does not exist! ## NULL ... and with invisible(): f_readfile &lt;- function(fname){ if(!file.exists(fname)){ warning(paste(fname, &quot;does not exist!&quot;)) return(invisible()) } else { read.csv(fname) } } f_readfile(&quot;foobar.txt&quot;) ## Warning in f_readfile(&quot;foobar.txt&quot;): foobar.txt does not exist! 4.2.1.5 Function environments As mentioned before, functions instantiate environments that exist only while the function is being evaluated. This means that functions can include named variables that have the same name as a variable in a different environment. For example here is a function that only lists what objects are in the local and global environments: # declare a few variables x &lt;- 1 y &lt;- &quot;hello&quot; # a simple function f &lt;- function(x){ # create a local variable y &lt;- x + 2 # another function inside this function g &lt;- function(x){ x * 3 } # what variables are in this environment? print(&quot;----------&quot;) print(&quot;objects in this function&#39;s environment:&quot;) print(ls()) # what is in the global env? print(&quot;----------&quot;) print(&quot;objects in the global environment:&quot;) print(ls(envir = .GlobalEnv)) # return the output of the function print(&quot;----------&quot;) y } f(1) ## [1] &quot;----------&quot; ## [1] &quot;objects in this function&#39;s environment:&quot; ## [1] &quot;g&quot; &quot;x&quot; &quot;y&quot; ## [1] &quot;----------&quot; ## [1] &quot;objects in the global environment:&quot; ## [1] &quot;a&quot; &quot;acc&quot; &quot;age_jane&quot; &quot;age_john&quot; ## [5] &quot;ages&quot; &quot;bins&quot; &quot;bins2&quot; &quot;BMI&quot; ## [9] &quot;boston_zip&quot; &quot;census_vars&quot; &quot;ci_95&quot; &quot;cmd&quot; ## [13] &quot;csvfname&quot; &quot;csvsize&quot; &quot;ctdat&quot; &quot;d&quot; ## [17] &quot;dat&quot; &quot;dat_1&quot; &quot;dat_sub&quot; &quot;dat_sub_sel&quot; ## [21] &quot;dtafname&quot; &quot;excel_fname&quot; &quot;f&quot; &quot;F&quot; ## [25] &quot;f_acc_intensity&quot; &quot;f_compare&quot; &quot;f_readfile&quot; &quot;f_square&quot; ## [29] &quot;f_square_2&quot; &quot;f_square_3&quot; &quot;figure_nums&quot; &quot;fname&quot; ## [33] &quot;fnames&quot; &quot;foo&quot; &quot;fstfname&quot; &quot;fstsize&quot; ## [37] &quot;g&quot; &quot;i&quot; &quot;inc&quot; &quot;income&quot; ## [41] &quot;income_factor&quot; &quot;iris_summary&quot; &quot;ja&quot; &quot;jo&quot; ## [45] &quot;l&quot; &quot;L&quot; &quot;labels&quot; &quot;m&quot; ## [49] &quot;m1&quot; &quot;m2&quot; &quot;m3&quot; &quot;my_zip&quot; ## [53] &quot;mystr&quot; &quot;mytext&quot; &quot;myUrl&quot; &quot;n&quot; ## [57] &quot;n_fnames&quot; &quot;normvec1000&quot; &quot;p&quot; &quot;pal&quot; ## [61] &quot;pal2&quot; &quot;pb&quot; &quot;pop&quot; &quot;s&quot; ## [65] &quot;sqlc&quot; &quot;states_5&quot; &quot;subjects&quot; &quot;sum_health_white_afram&quot; ## [69] &quot;t&quot; &quot;tabhealth_afram&quot; &quot;tabhealth_white&quot; &quot;table_nums&quot; ## [73] &quot;tbs&quot; &quot;tempdirfiles&quot; &quot;tmp&quot; &quot;tmpdir&quot; ## [77] &quot;txt&quot; &quot;urls&quot; &quot;v&quot; &quot;v.len&quot; ## [81] &quot;v1&quot; &quot;v2&quot; &quot;v3&quot; &quot;vals&quot; ## [85] &quot;x&quot; &quot;X&quot; &quot;xlsclip&quot; &quot;y&quot; ## [89] &quot;zip_bad&quot; &quot;zip_good&quot; &quot;zipfile&quot; ## [1] &quot;----------&quot; ## [1] 3 Once the function completes, all objects in its local environment are purged. If you are running a complicated function that creates intermediate values that you want to examine for troubleshooting, this kind of thing can be done, to assign a variable with a specific value to a different environment created specifically for examining the intermediate products of the function: # create an environment for holding intermediate objects created in the function run foo &lt;- new.env() g &lt;- function(x){ # code for a bunch of complicated operations # ... # generates an intermediate data frame named &quot;bar&quot; bar &lt;- head(iris) # save to the other env assign(x = &quot;bar&quot;, value = bar, envir = foo) # more code to do more complicated stuff # ... foobar &lt;- head(cars) # assign this too assign(x = &quot;foobar&quot;, value = foobar, envir = foo) # yet more complicated stuff here # ... } When the function runs, the objects bar and foobar are placed in the foo environment. We can examine those: # run the function g() # what is in envornment &quot;foo&quot;? ls(envir = foo) ## [1] &quot;bar&quot; &quot;foobar&quot; And we can view their values: print(foo$bar) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa print(foo$foobar) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 7 22 ## 5 8 16 ## 6 9 10 4.3 Sampling The general topic of sampling is far greater than what we can cover in this course. However, a few examples may be helpful for students who have little experience in sampling. The main R function for sampling is sample(), which draws a random sample from a vector or data frame. Options for sample() include the size of the sample, whether or not to replace sampled individuals to the pool, and a probability weight of the same length (or number of rows) as the population from which the sample is drawn. 4.3.1 Sampling with replacement Sampling with replacement is similar to rolling a die. Each roll of the die has a 1/6 probability of coming up with each value. For example: # create a vector to represent the faces of a die d &lt;- 1:6 # now make a sample of 100,000 rolls of the die s &lt;- sample(x = d, size = 100000, replace = TRUE) # tabulate the result (tbs &lt;- table(s)) ## s ## 1 2 3 4 5 6 ## 16391 16931 16557 16728 16609 16784 # proportions (prop.table(tbs)) ## s ## 1 2 3 4 5 6 ## 0.16391 0.16931 0.16557 0.16728 0.16609 0.16784 The probability of rolling two of the same number in a row is 1/6 \\(\\times\\) 1/6, or \\(\\approx\\) 0.028 4.3.2 Sampling without replacement Sampling without replacement removes from the population the individual that was sampled. For example, the probability of selecting an ace from a whole deck of cards is 4/52, or \\(\\approx\\) 0.077. If we drew once from the deck and returned the card back to the deck to draw again, both samples would be independent. The probability of drawing two aces would be 4/52 \\(\\times\\) 4/52, or \\(\\approx\\) 0.0059. That is an example of sampling with replacement. Performing the same sample without replacement, i.e., finding an ace, removing it, and then sampling again would have a probability of drawing two aces being 4/52 \\(\\times\\) 3/51, or \\(\\approx\\) 0.0045. For a population of sufficient size relative to the sample, sampling with or without replacement will lead to nearly identical results. Let's use an example of a population of 50,000 persons, where 30,000 are female and 20,000 are male. If we were to sample two persons with replacement, the probability that they would both be female would be 30000/50000 \\(\\times\\) 30000/50000, or 0.36. If we sample without replacement, the probability of selecting a female in the first sample of one would be 30000/50000, and the second sample of 1 would have a probability of selecting a female 29999/49999, with a joint probability of \\(\\approx\\) 0.359995. 4.3.3 Bootstrapping Bootstrapping is used to estimate the characteristics of a population by repeating a large number of random samples (with replacement) and then calculating summary statistics on the set of samples. The reason replacement is used is that each sample represents a &quot;snapshot&quot; of the population. As the number of samples increases, the summary continues to approach the true population characteristics. We will use a simple example from our previously created hypothetical population. If we had no idea what the male/female split was, we could generate a large number of small-is samples and the take the mean. Here we will use an R loop. A loop is constructed using the form for (element in set){ do something } A few simple examples follow. Print each letter in the first 5 letters of the alphabet. In this example, the iterated element is a letter. The built in vector letters is used: for (i in head(letters, 5)){ print(i) } ## [1] &quot;a&quot; ## [1] &quot;b&quot; ## [1] &quot;c&quot; ## [1] &quot;d&quot; ## [1] &quot;e&quot; A similar approach, but using a numerical index: states_5 &lt;- head(state.name, 5) for (i in 1:length(states_5)){ s &lt;- states_5[i] print(s) } ## [1] &quot;Alabama&quot; ## [1] &quot;Alaska&quot; ## [1] &quot;Arizona&quot; ## [1] &quot;Arkansas&quot; ## [1] &quot;California&quot; The bootstrap will use 5,000 samples of size 100 from our hypothetical population to estimate the proportion of females. # create the population # 1 indicates female and 0 indicates male pop &lt;- c(rep(1, 5e4 * 3 / 5), rep(0, 5e4 * 2 / 5)) # initialize a vector F &lt;- NULL # run the bootstrap for (i in seq(from = 1, to = 5000, by = 1)){ # sample once s &lt;- sample(x = pop, size = 100, replace = TRUE) # calculate percent female p &lt;- sum(s) / length(s) # concatenate the result with the running result F &lt;- c(F, p) } # mean and standard deviation of the bootstrap mean(F) ## [1] 0.600582 sd(F) ## [1] 0.04883276 Using the bootstrap results, we can estimate the 95% confidence interval around the mean using the Rmisc::CI() function, and make a density plot showing the mean and the confidence interval. # 95% CI ci_95 &lt;- Rmisc::CI(x = F, ci = 0.95) # plot with 95 % CI plot(density(F), main = &quot;density plot of bootstrap&quot;) abline(v = ci_95, col=c(2,1,2)) If we already had an enumeration of the population, this method would be unnecessary. However, most survey-derived data are generated from samples. If the sample is representative of the underlying population, the sample can be considered an acceptable proxy. Source code for this document 04-week04.Rmd # Week 4 {#week4} ```{r, echo=FALSE, warning=FALSE, message=FALSE} library(tidyverse) library(magrittr) library(knitr) library(kableExtra) library(readstata13) ``` &lt;h2&gt;Topics: Functions and sampling&lt;/h2&gt; This week&#39;s topics are functions and sampling, the latter including a cursory treatment of loops and bootstrapping. ## Environments Functions exist in `environments`, which are &quot;frames&quot; or collections containing objects including variables, functions, etc.). There is a global environment (`.GlobalEnv`) that contains all of the data, functions, in the current R session. Those objects can be enumerated with the `ls()` function. The reason environments are mentioned at this time is because functions instantiate environments that exist while the function is running. More on this in a bit.... ## Functions Functions are sets of statements in R that are grouped together to perform a specific task or set of tasks. Functions are either built in, included in packages, or user-defined. Functions are used mainly to simplify running a series of individual commands or functions, for situations where the same process will need to be run multiple times on different inputs, or when control structures are needed (e.g., looping, logical branching). ### Function Components The different parts of a function are: 1. (Usually) Name: This is the actual name of the function. It is stored in an R environment as an object with this name. 1. (Optional) Arguments: Arguments specify the inputs or options to the function. When a function is invoked, you pass a value to the argument. Arguments are optional; that is, a function may contain no arguments. Also arguments can have default values. 1. Body: The function body contains a collection of statements that defines what the function does. 1. Return value: The return value of a function is the last expression in the function body to be evaluated. Another important concept for functions is environments. #### Name Most functions are created with code of the form ``` function_name &lt;- function(argument(s)){ statement(s) } ``` For example, to square a vector of numerical values: ```{r} f_square &lt;- function(x){ x^2 } ``` the function name is `f_square`. Some functions are not named, and are referred to as &quot;anonymous&quot; functions. For example, functions can be used within the `apply` family of functions. Here is an oprationalized example. ```{r} # create a list of three vectors of random numbers of different random lengths # set.seed() makes the random process reproducible. set.seed(10) # vector lengths v.len &lt;- rnorm(n = 3, mean = 30, sd = 10) %&gt;% round(0) # make the random vectors set.seed(5) v1 &lt;- rnorm(n = v.len[1]) set.seed(3) v2 &lt;- rnorm(n = v.len[2]) set.seed(6) v3 &lt;- rnorm(n = v.len[3]) # create the list L &lt;- list(v1, v2, v3) # get the first value from each vector in the list lapply(X = L, FUN = function(x) {x[1]}) ``` The last line of the code chunk is: ``` lapply(X = L, FUN = function(x) {x[1]}) ``` in which the body of the function is `x[1]`, i.e., obtain the first element of a vector. But the function itself is not named, and hence &quot;anonymous.&quot; #### Arguments Most functions require arguments. Arguments are used to instantiate variables within the function&#39;s environment that can be used later in the body of the function. Each argument is named, and the name is used within the function as a local variable within the function&#39;s environment. Following our example from above, `f_square` takes an argument named &quot;x&quot; that is a numeric vector. Here, let&#39;s modify the function to demonstrate that within the environment of the function, `x` is a variable: ```{r} f_square_2 &lt;- function(x){ message(&quot;input:&quot;) print(x) message(&quot;output:&quot;) x^2 } f_square_2(c(1,2,3)) ``` We can try running the function using different (or no) arguments: Here, using a vector of a single NA numeric ```{r} f_square(as.numeric(NA)) ``` ... or a vector that contains a numeric NA: ```{r} f_square(c(1, 2, NA)) ``` ... or a null: ```{r} f_square(NULL) ``` ... or a vector containing a null: ```{r} f_square(c(1, 2, NULL)) ``` ... or with no argument at all: ``` f_square() ``` &lt;font color=&quot;red&quot;&gt; ``` ## Error in f_square() : argument &quot;x&quot; is missing, with no default ``` &lt;/font&gt; Some functions do not require arguments, e.g., to get the current date or time: ```{r} Sys.Date() Sys.time() ``` ... and if we try to use an argument we get an error: ``` Sys.Date(1) ``` &lt;font color=&quot;red&quot;&gt; ``` ## Error in Sys.Date(1) : unused argument (1) ``` &lt;/font&gt; ##### Default values for arguments If you want an argument to have a default value, it is specified in the listed arguments in the form `argument = value`. Following our previous `f_square_2()` function, we can modify to print the input based on the logical argument `verbose`: ```{r, collapse=TRUE} f_square_3 &lt;- function(x, verbose = FALSE){ # only run the next lines if verbose is true if(verbose){ message(&quot;input:&quot;) print(x) message(&quot;output:&quot;) } x^2 } ``` Here we run with the default `verbose` option (`FALSE`): ```{r} f_square_3(x = c(1, 2, 3)) ``` ... and with `verbose = TRUE`: ```{r} f_square_3(x = c(1, 2, 3), verbose = TRUE) ``` A more meaningful example demonstrates stratification of counts into intensity bins using accelerometry data. We will be using accelerometry from one day&#39;s data from one subject in a study. The cut points for accelerometry were identified at 0, 2690, 6167, and 9642 counts per minute, from Sasaki et al. (2011). __Sasaki JE, John D, Freedson PS. Validation and comparison of ActiGraph activity monitors. J Sci Med Sport. 2011;14(5):411-416. doi:10.1016/j.jsams.2011.04.003__ The variable `vm3` is the vector magnitude measured with the accelerometer for each minute. Data: [accelerometry.csv](files/accelerometry.csv). ```{r} acc &lt;- read.csv(&quot;files/accelerometry.csv&quot;) head(acc) ``` The following function codes intensity by the aforementioned cut points by default and using default labels: ```{r} f_acc_intensity &lt;- function(x, cuts = c(-Inf, 2690, 6167, 9642, Inf), labels = c(&quot;sedentary/low&quot;, &quot;moderate&quot;, &quot;vigorous&quot;, &quot;very vigorous&quot;)){ cut(x = acc$vm3, breaks = cuts, labels = labels) } ``` ... and when run with the defaults to tabulate the minutes spent in different PA levels ```{r} acc$intens_default &lt;- f_acc_intensity(acc$vm3) table(acc$intens_default) ``` But we could run this with different thresholds and levels, where SPLA = &quot;sedentary/low physical activity&quot; and MVPA = &quot;moderate-to-very vigorous physical activity): ```{r} acc$intens_2lev &lt;- f_acc_intensity(x = acc$vm3, cuts = c(-Inf, 2690, Inf), labels = c(&quot;SLPA&quot;, &quot;MVVPA&quot;)) table(acc$intens_2lev) ``` ##### The `...` argument When functions do not have a known _a priori_ number or set of arguments, or when a large number of arguments is to be passed to another function the `...` argument is used. We will not cover this but you are encouraged to read more: [How to Use the Dots Argument in R](https://www.dummies.com/programming/r/how-to-use-the-dots-argument-in-r/); [The three-dots construct in R](https://www.r-bloggers.com/2013/01/the-three-dots-construct-in-r/). #### Body The function&#39;s body contains all of the code to perform the purpose of the function. Following our initial example, the body of the function is simply ``` x^2 ``` The body can be as simple or complicated as it needs to be in order to achieve the desired result. #### Return value The return value is either the last evaluated expression in the function or an object specified using the `return()` function. In our original `f_square()` function, the return value is `x^2` since no other `return()` value was specified, e.g., for a vector of one element: ```{r} f_square &lt;- function(x){ x^2 } f_square(3) ``` or a vector with multiple elements: ```{r} f_square(c(1,2,3)) ``` An simple example of explicitly specifying return values is shown in this numerical comparison function: ```{r} f_compare &lt;- function(x, y){ # either missing? if(nargs() != 2) return(&quot;invalid number of arguments&quot;) # numeric? if(!is.numeric(x) | !is.numeric(y)){ return(sprintf(&quot;%s or %s is not numeric.&quot;, x, y)) } # comparisons follow if(x &gt; y){ return(sprintf(&quot;%s is greater than %s&quot;, x, y)) } if(x &lt; y) { return(sprintf(&quot;%s is less than %s&quot;, x, y)) } if(x == y){ return(sprintf(&quot;%s equals %s&quot;, x, y)) } } ``` If you want to handle an expected error, you can print an informative message and use `return(invisible())`, which returns nothing at all (whereas `return()` results in a `NULL`) e.g., here without `invisible()`: ```{r} f_readfile &lt;- function(fname){ if(!file.exists(fname)){ warning(paste(fname, &quot;does not exist!&quot;)) return() } else { read.csv(fname) } } f_readfile(&quot;foobar.txt&quot;) ``` ... and with `invisible()`: ```{r} f_readfile &lt;- function(fname){ if(!file.exists(fname)){ warning(paste(fname, &quot;does not exist!&quot;)) return(invisible()) } else { read.csv(fname) } } f_readfile(&quot;foobar.txt&quot;) ``` #### Function environments As mentioned before, functions instantiate environments that exist only while the function is being evaluated. This means that functions can include named variables that have the same name as a variable in a different environment. For example here is a function that only lists what objects are in the local and global environments: ```{r} # declare a few variables x &lt;- 1 y &lt;- &quot;hello&quot; # a simple function f &lt;- function(x){ # create a local variable y &lt;- x + 2 # another function inside this function g &lt;- function(x){ x * 3 } # what variables are in this environment? print(&quot;----------&quot;) print(&quot;objects in this function&#39;s environment:&quot;) print(ls()) # what is in the global env? print(&quot;----------&quot;) print(&quot;objects in the global environment:&quot;) print(ls(envir = .GlobalEnv)) # return the output of the function print(&quot;----------&quot;) y } f(1) ``` Once the function completes, all objects in its local environment are purged. If you are running a complicated function that creates intermediate values that you want to examine for troubleshooting, this kind of thing can be done, to assign a variable with a specific value to a different environment created specifically for examining the intermediate products of the function: ```{r} # create an environment for holding intermediate objects created in the function run foo &lt;- new.env() g &lt;- function(x){ # code for a bunch of complicated operations # ... # generates an intermediate data frame named &quot;bar&quot; bar &lt;- head(iris) # save to the other env assign(x = &quot;bar&quot;, value = bar, envir = foo) # more code to do more complicated stuff # ... foobar &lt;- head(cars) # assign this too assign(x = &quot;foobar&quot;, value = foobar, envir = foo) # yet more complicated stuff here # ... } ``` When the function runs, the objects `bar` and `foobar` are placed in the `foo` environment. We can examine those: ```{r} # run the function g() # what is in envornment &quot;foo&quot;? ls(envir = foo) ``` And we can view their values: ```{r} print(foo$bar) ``` ```{r} print(foo$foobar) ``` ## Sampling The general topic of sampling is far greater than what we can cover in this course. However, a few examples may be helpful for students who have little experience in sampling. The main R function for sampling is `sample()`, which draws a random sample from a vector or data frame. Options for `sample()` include the size of the sample, whether or not to replace sampled individuals to the pool, and a probability weight of the same length (or number of rows) as the population from which the sample is drawn. ### Sampling with replacement Sampling with replacement is similar to rolling a die. Each roll of the die has a 1/6 probability of coming up with each value. For example: ```{r} # create a vector to represent the faces of a die d &lt;- 1:6 # now make a sample of 100,000 rolls of the die s &lt;- sample(x = d, size = 100000, replace = TRUE) # tabulate the result (tbs &lt;- table(s)) # proportions (prop.table(tbs)) ``` The probability of rolling two of the same number in a row is 1/6 $\\times$ 1/6, or $\\approx$ 0.028 ### Sampling without replacement Sampling without replacement removes from the population the individual that was sampled. For example, the probability of selecting an ace from a whole deck of cards is 4/52, or $\\approx$ 0.077. If we drew once from the deck and returned the card back to the deck to draw again, both samples would be independent. The probability of drawing two aces would be 4/52 $\\times$ 4/52, or $\\approx$ 0.0059. _That_ is an example of sampling _with_ replacement. Performing the same sample _without_ replacement, i.e., finding an ace, removing it, and then sampling again would have a probability of drawing two aces being 4/52 $\\times$ 3/51, or $\\approx$ 0.0045. For a population of sufficient size relative to the sample, sampling with or without replacement will lead to nearly identical results. Let&#39;s use an example of a population of 50,000 persons, where 30,000 are female and 20,000 are male. If we were to sample two persons with replacement, the probability that they would both be female would be 30000/50000 $\\times$ 30000/50000, or 0.36. If we sample without replacement, the probability of selecting a female in the first sample of one would be 30000/50000, and the second sample of 1 would have a probability of selecting a female 29999/49999, with a joint probability of $\\approx$ 0.359995. ### Bootstrapping Bootstrapping is used to estimate the characteristics of a population by repeating a large number of random samples (with replacement) and then calculating summary statistics on the set of samples. The reason replacement is used is that each sample represents a &quot;snapshot&quot; of the population. As the number of samples increases, the summary continues to approach the true population characteristics. We will use a simple example from our previously created hypothetical population. If we had no idea what the male/female split was, we could generate a large number of small-is samples and the take the mean. Here we will use an R loop. A loop is constructed using the form ``` for (element in set){ do something } ``` A few simple examples follow. Print each letter in the first 5 letters of the alphabet. In this example, the iterated element is a letter. The built in vector `letters` is used: ```{r} for (i in head(letters, 5)){ print(i) } ``` A similar approach, but using a numerical index: ```{r} states_5 &lt;- head(state.name, 5) for (i in 1:length(states_5)){ s &lt;- states_5[i] print(s) } ``` The bootstrap will use 5,000 samples of size 100 from our hypothetical population to estimate the proportion of females. ```{r} # create the population # 1 indicates female and 0 indicates male pop &lt;- c(rep(1, 5e4 * 3 / 5), rep(0, 5e4 * 2 / 5)) # initialize a vector F &lt;- NULL # run the bootstrap for (i in seq(from = 1, to = 5000, by = 1)){ # sample once s &lt;- sample(x = pop, size = 100, replace = TRUE) # calculate percent female p &lt;- sum(s) / length(s) # concatenate the result with the running result F &lt;- c(F, p) } # mean and standard deviation of the bootstrap mean(F) sd(F) ``` Using the bootstrap results, we can estimate the 95% confidence interval around the mean using the `Rmisc::CI()` function, and make a density plot showing the mean and the confidence interval. ```{r} # 95% CI ci_95 &lt;- Rmisc::CI(x = F, ci = 0.95) # plot with 95 % CI plot(density(F), main = &quot;density plot of bootstrap&quot;) abline(v = ci_95, col=c(2,1,2)) ``` If we already had an enumeration of the population, this method would be unnecessary. However, most survey-derived data are generated from samples. If the sample is representative of the underlying population, the sample can be considered an acceptable proxy. &lt;h4&gt;Source code for this document&lt;/h4&gt; [04-week04.Rmd](04-week04.Rmd) ```{r, comment=&#39;&#39;, echo=FALSE} cat(readLines(&quot;04-week04.Rmd&quot;), sep = &#39;\\n&#39;) ``` "],["week5.html", "5 Week 5 5.1 Why use version control? 5.2 Why use Git? 5.3 Limitations of version control systems 5.4 A brief Git tutorial 5.5 Conclusion 5.6 Source code", " 5 Week 5 Topic: Git This week's topic is a brief introduction to Git, the free and open source version control system for text-based files. Much of the material in this lesson is derived from the Software Carpentry Git tutorial. 5.1 Why use version control? Version control is simply having control over various versions of your documents. In the context of code-based research using text files such as .R, .Rmd, .tex, .sql, .do, at the simplest level, version control means having the ability to track changes to your files. In more advanced levels, you should be able to revert to previous versions, collaborate with others and know who did what and when, or to merge together edits made by more than one person We covered one form of version control in a previous assignment and in the section of this document on File systems. The version control system was simply keeping copies of existing files and naming new files according to a temporal sequence, with date being the suggested method of nomenclature. While keeping backup, dated copies of files is not necessarily a bad approach, it suffers from a few major limitations, including: because it relies on saving different versions of a file, it can lead to a proliferation of files it is not often easy to know what changes were made from version to version Jorge Cham's (Piled Higher and Deeper) comic points out what happens to a typical graduate student's &quot;final&quot; version: 5.2 Why use Git? Version controls systems have been in use since the early 1980s. Commonly used applications are RCS, CVS, SVN, and Subversion. However, some of these require centralized servers, are limited in their capabilities, and are not free. Git has multiple advantages: free supports complex work flows with branching, merging, etc., allowing multiple collaborators to work on the same set of files at the same time does not require a centralized server (version control can be managed completely within a single computer) it is possible to use online repositories, such as github.com can be used within RStudio has a large community of users (i.e., free advice) 5.3 Limitations of version control systems Although version control systems are quite useful, there are some potential drawbacks. requires learning yet another somewhat-complicated system requires mindfulness recorded changes are best performed interactively can only &quot;undo&quot; changes that were committed designed for text files; cannot deal with binary files, e.g., Word or other formats 5.4 A brief Git tutorial Here we will be using the basic functions of Git while building up an Rmd file. 5.4.1 Setting up Git in RStudio We will be working on CSDE Terminal Server 4 (see Getting started on Terminal Server 4). Start RStudio and open a web browser. 5.4.2 Creating a repository Using the web browser, go to github.com and create a repository named git_r. Make the repository public and add a README file. Switch back to RStudio and select File &gt; New Project and in the choice of project types, select Version Control. This will streamline the process of linking the RStudio project with github. Choose Git as the type of version control. Enter the complete URL of your new Git repository. The project directly name should automatically be set as the basename pf the URL. If not, enter git_r. Because we need to define where on the local file system the project files will be stored, click Browse and navigate to your H: drive (note that this is your UDrive). After you have specified the repository URL, project directory name, and parent directory of the project directory, click Create Project. 5.4.3 Tracking changes One of the files we will change is week_01.Rmd, so download this to the main folder of your project. The first file we will make changes to is README.md. Add some text explaining what purpose the repository serves. Save the changes to the README.md file. If you do not see updates in the Git tab, click the Refresh listing button. You may need to do this frequently if your file changes are frequent. Note the status of files will only change when the files are saved. You should see a blue &quot;M&quot; next to the README.md file. Click the check box for Staged to prepare to commit the changes to the file and prepare to push to the remote server. Click Commit and a new window will open. Any deletions are shown with a light red background. Additions are shown with a light green background, and text that has not changed will have a white background. Enter some explanatory text in the Commit message panel. This message will help identify historical commits. The explanatory text should succinctly describe any changes you have made. The idea is to make commits each time you have substantially changed your code. If you wait too long between commits, the number of changes in a single commit may be unmanageable. But if commits are made too frequently, the number of commits may become unmanageable. Think of this similarly to how often you might make a new version of a document. Next, we will perform an initial pull/push. It is recommended in multi-user environments to perform a pull from the online repository before pushing. This lets you download to your local file system any files that have been updated by others. In the Git tab, click the Pull icon. Since no changes have been made to the online files, we see the message &quot;Already up to date&quot;. Next, click the Push icon to upload any changed files. At some point in the process of establishing the connection to github, you may get some popups asking you to sign in. If this happens, proceed with the authorization. When the authorization is completed, the push will proceed. Your screen will look different, but the last line of text here shows a truncated version of the unique hash (identifier) of the push transaction. This has will allow you to download previous versions of the file in case you made commits and pushes that caused unintended consequences. If you refresh the page for your repository, you should see the updates you made to the README.md file. This is the basic process for updating files, committing changes, and pushing to github. Perform the same steps (click Staged then Commit for week_01.Rmd). Because this is a new file that was not in the github repository, when it is committed, it will show in all green since all of the text has been added. Repeat the pull/push cycle and then refresh your browser to show that the file was added to the online github repository. If you click the file name you will see the contents. Let's make some changes to this file. Back in RStudio, add to the list of packages to load at line 51. library(htmltools) # popup on Leaflet map Change the description at line 122 to read ... for a Leaflet map that has the Space Needle, Savery Hall, and the Woodland Park Zoo. and change the code chunk to add two additional points and text popups for the point markers. The chunk should contain the following code: # the Space Needle snxy &lt;- data.frame(name = &quot;Space Needle&quot;, x = -122.3493, y = 47.6205) space_needle &lt;- st_as_sf(snxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) # Savery Hall shxy &lt;- data.frame(name = &quot;Savery Hall&quot;, x = -122.3083, y = 47.6572) savery_hall &lt;- st_as_sf(shxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) # the Woodland Park Zoo zooxy &lt;- data.frame(name = &quot;Woodland Park Zoo&quot;, x = -122.3543, y = 47.6685) wp_zoo &lt;- st_as_sf(zooxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) # rbind() to put two points in one data frame pts &lt;- rbind(space_needle, savery_hall, wp_zoo) # a leaflet m &lt;- leaflet() %&gt;% addTiles() %&gt;% addCircleMarkers(data = pts, label = ~htmlEscape(name)) m Save the edits to the file and then tap the &quot;knit&quot; button or enter at the console prompt rmarkdown::render(&quot;week_01.Rmd&quot;) to generate the HTML file. You should see that now there are three point markers, and if you hover over any of the markers you will see the name popup. 5.4.4 Git bash shell Another interface you can use is the Git bash shell. To open the shell, click Tools &gt; Shell. All of the GUI commands we have used in RStudio are available in the shell. In fact, very little of the functionality of Git is available within RStudio. To take full advantage of Git, it is necessary to use the shell. There are a number of excellent tutorials on the use of the shell. For now because this is an introductory lesson, we will focus mainly on the RStudio interface, The shell should be set to the project folder; if not you can enter e.g., cd /H/git_r (note that this corresponds to the Windows folder H:\\git_r). At the prompt, enter git status. This will show the status of all files, in this case showing that week_01.Rmd has been modified, and that there are some files that are not being tracked. 5.4.5 Ignoring specific files Sometimes we are not interested in particular files being committed or pushed to the repository. For version control, we are interested in managing the code that is used to create outputs rather than the outputs themselves, with the idea being that if you have the code, you can recreate any outputs. So there are files that can be ignored, which are specified in the .gitignore file. Open the file and add the line *.html. This tells Git not to bother managing HTML files (under the assumption that these are the output of rendering Rmd files). Save the .gitignore file and re-run git status at the shell (by tapping the up arrow key on your keyboard and tapping Enter). You should see that the HTML file does not show up in the list of changed or untracked files. Add the line *.Rproj to the .gitignore file--this file should not be necessary in the repository. Likewise, if you refresh the Git tab in RStudio, the HTML file is no longer listed. We will perform a few more tasks with the shell. Enter add .gitignore and add week_01.Rmd. This is the equivalent of clicking the Staged check box Refreshing the Git tab will show that these two files are staged. 5.4.6 Exploring file change history Click Commit to prepare to commit the changes (addition of .gitignore and the changes to week_01.Rmd). As previously mentioned, deleted lines are shown in light red, added lines in light green, and unchanged lines with no highlighting. Click the entry for week_01.Rmd and the changes are apparent. Line numbers on the far left are the original line numbers. The next column to the right shows updated line numbers. This allows you to compare the currently saved version against the previous version of the file. Committing changes with the shell is done by entering git commit -m &quot;somecomment&quot; This has the same effect as clicking Commit in RStudio and entering the comment. Note that if we have not made some initial user configurations, Git will print some informative text about your identity. To avoid this and to tag future commits, use the git config --global commands, e.g., git config --global user.name &quot;My Full Name&quot; git config --global user.email &quot;myemailaddress@mydomain&quot; Once the commit is performed, either with the RStudio GUI or with the shell, you can verify that no files are listed to be possibly staged. Perform another pull/push cycle and then refresh your web browser. Click on the commit comment. You will see the changes to the two files in the last commit/push. The .gitignore file has all of its lines in green, indicating they are all new with respect to the repository. The file week_01.Rmd shows the same changes on github as we saw in the local view before pushing the commit to the server. 5.4.7 Restoring a previous version What good are all of these tracked changes if we cannot revert to a previous version of a file? Here we will make some intentional bad edits to a file, commit and push, but then retrieve a previous version of the file. Any version can be recovered. Note that this does not mean you can recover any and all edits to a file. It only means you can recover what changed between commits. For example, if I made a commit/push at noon, then made a lot of changes and saved the file multiple times before 5 PM and then made a commit/push, there would only be two versions of the file available. For this reason it is worth making commit/push cycles every time you thing you might want to revert to a previous version. The intentional bad change to week_01.Rmd is the complete removal of the code that produces the Leaflet map. See the following image. Perform the standard cycle: stage, commit (with comment), pull, push. You should see the large swath of deleted lines Back in the github, find and click the file name. The file contents will show the most recent saved version (missing the Leaflet map lines). Click on the History link, which will show all of the commits. Click the commit where you followed the questionable advice from your adviser. The missing lines are evident. What we would like to do is to go back to the version before the large deletion of lines. Identify the previous commit and click the clipboard icon to the left of the first characters of the commit hash. This will copy the hash, which is necessary for restoring that version. Back in the shell, enter git show *****:week_01.Rmd where ***** is the hash. You will see the text that was present at that commit, which includes the deleted Leaflet map. To restore this previous version to a new file, enter git show *****:week_01.Rmd &gt; week_01_someadditionaldescription.Rmd This prints the contents of the previously committed file and redirects the output to the named file after the &gt; sign. If you open that file, you will see the restored text. 5.5 Conclusion This was a brief introduction to the main functionality of Git with RStudio and github. If you expect to perform even a modest amount of coding, you could benefit from Git as a way to keep track of your work, collaborate with others, and avoid programming disasters due to inadvertent deletion of overwriting of files. 5.6 Source code 05-week05.Rmd cat(readLines(&quot;05-week05.Rmd&quot;), sep = &#39;\\n&#39;) # Week 5 {#week5} ```{r, echo=FALSE, warning=FALSE, message=FALSE} library(tidyverse) library(magrittr) library(knitr) library(kableExtra) library(readstata13) ``` &lt;h2&gt;Topic: Git&lt;/h2&gt; This week&#39;s topic is a brief introduction to [Git](https://git-scm.com/), the free and open source version control system for text-based files. Much of the material in this lesson is derived from the [Software Carpentry Git tutorial](https://swcarpentry.github.io/git-novice/). ## Why use version control? Version control is simply having control over various versions of your documents. In the context of code-based research using text files such as `.R`, `.Rmd`, `.tex`, `.sql`, `.do`, at the simplest level, version control means having the ability to track changes to your files. In more advanced levels, you should be able to revert to previous versions, collaborate with others and know who did what and when, or to merge together edits made by more than one person We covered one form of version control in a previous assignment and in the section of this document on [File systems](#file-systems). The version control system was simply keeping copies of existing files and naming new files according to a temporal sequence, with date being the suggested method of nomenclature. While keeping backup, dated copies of files is not necessarily a bad approach, it suffers from a few major limitations, including: 1. because it relies on saving different versions of a file, it can lead to a proliferation of files 1. it is not often easy to know what changes were made from version to version Jorge Cham&#39;s ([Piled Higher and Deeper](http://www.phdcomics.com)) comic points out what happens to a typical graduate student&#39;s &quot;final&quot; version: [![](images/week05/phd101212s.png)](http://www.phdcomics.com) ## Why use Git? Version controls systems have been in use since the early 1980s. Commonly used applications are RCS, CVS, SVN, and Subversion. However, some of these require centralized servers, are limited in their capabilities, and are not free. Git has multiple advantages: * free * supports complex work flows with branching, merging, etc., allowing multiple collaborators to work on the same set of files at the same time * does not require a centralized server (version control can be managed completely within a single computer) * it is possible to use online repositories, such as github.com * can be used within RStudio * has a large community of users (i.e., free advice) ## Limitations of version control systems Although version control systems are quite useful, there are some potential drawbacks. 1. requires learning yet another somewhat-complicated system 1. requires mindfulness * recorded changes are best performed interactively * can only &quot;undo&quot; changes that were committed 1. designed for text files; cannot deal with binary files, e.g., Word or other formats ## A brief Git tutorial Here we will be using the basic functions of Git while building up an Rmd file. ### Setting up Git in RStudio We will be working on CSDE Terminal Server 4 (see [Getting started on Terminal Server 4](#getting-started-on-terminal-server-4)). Start RStudio and open a web browser. ### Creating a repository Using the web browser, go to [github.com](http://github.com) and create a repository named `git_r`. ![](images/week05/2021-02-04_21_21_47.png) Make the repository public and add a README file. ![](images/week05/2021-02-04_21_37_13.png) Switch back to RStudio and select `File &gt; New Project` and in the choice of project types, select `Version Control`. This will streamline the process of linking the RStudio project with github. ![](images/week05/2021-02-04_21_39_10.png) Choose `Git` as the type of version control. ![](images/week05/2021-02-04_21_39_46.png) Enter the complete URL of your new Git repository. The project directly name should automatically be set as the basename pf the URL. If not, enter `git_r`. ![](images/week05/2021-02-04_21_52_48.png) Because we need to define where on the local file system the project files will be stored, click `Browse` and navigate to your `H:` drive (note that this is your UDrive). ![](images/week05/2021-02-04_21_53_32.png) After you have specified the repository URL, project directory name, and parent directory of the project directory, click `Create Project`. ![](images/week05/2021-02-04_21_54_04.png) ### Tracking changes One of the files we will change is [week_01.Rmd](files/week_01.Rmd), so download this to the main folder of your project. The first file we will make changes to is `README.md`. Add some text explaining what purpose the repository serves. ![](images/week05/2021-02-04_22_09_11.png) Save the changes to the README.md file. If you do not see updates in the Git tab, click the `Refresh listing` button. You may need to do this frequently if your file changes are frequent. Note the status of files will only change when the files are saved. ![](images/week05/2021-02-04_22_37_42.png) You should see a blue &quot;M&quot; next to the README.md file. Click the check box for `Staged` to prepare to commit the changes to the file and prepare to push to the remote server. ![](images/week05/2021-02-04_22_11_45.png) Click `Commit` and a new window will open. Any deletions are shown with a light red background. Additions are shown with a light green background, and text that has not changed will have a white background. Enter some explanatory text in the `Commit message` panel. This message will help identify historical commits. The explanatory text should succinctly describe any changes you have made. The idea is to make commits each time you have substantially changed your code. If you wait too long between commits, the number of changes in a single commit may be unmanageable. But if commits are made too frequently, the number of commits may become unmanageable. Think of this similarly to how often you might make a new version of a document. ![](images/week05/2021-02-04_22_15_28.png) Next, we will perform an initial pull/push. It is recommended in multi-user environments to perform a pull from the online repository before pushing. This lets you download to your local file system any files that have been updated by others. In the Git tab, click the `Pull` icon. ![](images/week05/2021-02-04_22_17_19.png) Since no changes have been made to the online files, we see the message &quot;Already up to date&quot;. ![](images/week05/2021-02-04_22_17_41.png) Next, click the `Push` icon to upload any changed files. ![](images/week05/2021-02-04_22_17_58.png) At some point in the process of establishing the connection to github, you may get some popups asking you to sign in. If this happens, proceed with the authorization. ![](images/week05/2021-02-04_22_19_18.png) ![](images/week05/2021-02-04_22_19_59.png) ![](images/week05/2021-02-04_22_20_08.png) When the authorization is completed, the push will proceed. Your screen will look different, but the last line of text here shows a truncated version of the unique hash (identifier) of the push transaction. This has will allow you to download previous versions of the file in case you made commits and pushes that caused unintended consequences. ![](images/week05/2021-02-04_22_20_32.png) If you refresh the page for your repository, you should see the updates you made to the README.md file. This is the basic process for updating files, committing changes, and pushing to github. ![](images/week05/2021-02-04_22_21_18.png) Perform the same steps (click `Staged` then `Commit` for week_01.Rmd). Because this is a new file that was not in the github repository, when it is committed, it will show in all green since all of the text has been added. ![](images/week05/2021-02-04_22_46_24.png) Repeat the pull/push cycle and then refresh your browser to show that the file was added to the online github repository. ![](images/week05/2021-02-04_22_48_45.png) If you click the file name you will see the contents. ![](images/week05/2021-02-04_22_49_07.png) Let&#39;s make some changes to this file. Back in RStudio, add to the list of packages to load at line 51. ``` library(htmltools) # popup on Leaflet map ``` Change the description at line 122 to read ``` ... for a Leaflet map that has the Space Needle, Savery Hall, and the Woodland Park Zoo. ``` and change the code chunk to add two additional points and text popups for the point markers. The chunk should contain the following code: ``` # the Space Needle snxy &lt;- data.frame(name = &quot;Space Needle&quot;, x = -122.3493, y = 47.6205) space_needle &lt;- st_as_sf(snxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) # Savery Hall shxy &lt;- data.frame(name = &quot;Savery Hall&quot;, x = -122.3083, y = 47.6572) savery_hall &lt;- st_as_sf(shxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) # the Woodland Park Zoo zooxy &lt;- data.frame(name = &quot;Woodland Park Zoo&quot;, x = -122.3543, y = 47.6685) wp_zoo &lt;- st_as_sf(zooxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) # rbind() to put two points in one data frame pts &lt;- rbind(space_needle, savery_hall, wp_zoo) # a leaflet m &lt;- leaflet() %&gt;% addTiles() %&gt;% addCircleMarkers(data = pts, label = ~htmlEscape(name)) m ``` Save the edits to the file and then tap the &quot;knit&quot; button or enter at the console prompt `rmarkdown::render(&quot;week_01.Rmd&quot;)` to generate the HTML file. You should see that now there are three point markers, and if you hover over any of the markers you will see the name popup. ![](images/week05/2021-02-04_22_32_50.png) ### Git bash shell Another interface you can use is the Git bash shell. To open the shell, click `Tools &gt; Shell`. ![](images/week05/2021-02-04_22_01_34.png) All of the GUI commands we have used in RStudio are available in the shell. In fact, very little of the functionality of Git is available within RStudio. To take full advantage of Git, it is necessary to use the shell. There are a number of excellent tutorials on the use of the shell. For now because this is an introductory lesson, we will focus mainly on the RStudio interface, The shell should be set to the project folder; if not you can enter e.g., `cd /H/git_r` (note that this corresponds to the Windows folder `H:\\git_r`). At the prompt, enter `git status`. This will show the status of all files, in this case showing that `week_01.Rmd` has been modified, and that there are some files that are not being tracked. ![](images/week05/2021-02-04_23_36_02.png) ### Ignoring specific files Sometimes we are not interested in particular files being committed or pushed to the repository. For version control, we are interested in managing the code that is used to create outputs rather than the outputs themselves, with the idea being that if you have the code, you can recreate any outputs. So there are files that can be ignored, which are specified in the `.gitignore` file. Open the file and add the line `*.html`. This tells Git not to bother managing HTML files (under the assumption that these are the output of rendering Rmd files). ![](images/week05/2021-02-04_23_40_15.png) Save the `.gitignore` file and re-run `git status` at the shell (by tapping the up arrow key on your keyboard and tapping Enter). You should see that the HTML file does not show up in the list of changed or untracked files. ![](images/week05/2021-02-04_23_42_51.png) Add the line `*.Rproj` to the `.gitignore` file--this file should not be necessary in the repository. Likewise, if you refresh the Git tab in RStudio, the HTML file is no longer listed. ![](images/week05/2021-02-04_23_43_13.png) We will perform a few more tasks with the shell. Enter `add .gitignore` and `add week_01.Rmd`. This is the equivalent of clicking the `Staged` check box ![](images/week05/2021-02-04_23_45_14.png) Refreshing the Git tab will show that these two files are staged. ![](images/week05/2021-02-04_23_45_37.png) ### Exploring file change history Click `Commit` to prepare to commit the changes (addition of `.gitignore` and the changes to `week_01.Rmd`). As previously mentioned, deleted lines are shown in light red, added lines in light green, and unchanged lines with no highlighting. Click the entry for `week_01.Rmd` and the changes are apparent. Line numbers on the far left are the original line numbers. The next column to the right shows updated line numbers. This allows you to compare the currently saved version against the previous version of the file. ![](images/week05/2021-02-04_23_48_02.png) Committing changes with the shell is done by entering ` git commit -m &quot;somecomment&quot; ` This has the same effect as clicking `Commit` in RStudio and entering the comment. Note that if we have not made some initial user configurations, Git will print some informative text about your identity. To avoid this and to tag future commits, use the `git config --global` commands, e.g., ` git config --global user.name &quot;My Full Name&quot; git config --global user.email &quot;myemailaddress@mydomain&quot; ` ![](images/week05/2021-02-04_23_51_55.png) Once the commit is performed, either with the RStudio GUI or with the shell, you can verify that no files are listed to be possibly staged. ![](images/week05/2021-02-04_23_53_10.png) Perform another pull/push cycle and then refresh your web browser. Click on the commit comment. ![](images/week05/2021-02-05_00_10_46.png) You will see the changes to the two files in the last commit/push. The `.gitignore` file has all of its lines in green, indicating they are all new with respect to the repository. The file `week_01.Rmd` shows the same changes on github as we saw in the local view before pushing the commit to the server. ![](images/week05/2021-02-05_00_12_20.png) ### Restoring a previous version What good are all of these tracked changes if we cannot revert to a previous version of a file? Here we will make some intentional bad edits to a file, commit and push, but then retrieve a previous version of the file. Any version can be recovered. Note that this does not mean you can recover any and all edits to a file. It only means you can recover what changed between commits. For example, if I made a commit/push at noon, then made a lot of changes and saved the file multiple times before 5 PM and then made a commit/push, there would only be two versions of the file available. For this reason it is worth making commit/push cycles every time you thing you might want to revert to a previous version. The intentional bad change to `week_01.Rmd` is the complete removal of the code that produces the Leaflet map. See the following image. ![](images/week05/2021-02-05_00_13_13.png) Perform the standard cycle: stage, commit (with comment), pull, push. ![](images/week05/2021-02-05_00_14_07.png) ![](images/week05/2021-02-05_00_14_24.png) ![](images/week05/2021-02-05_00_16_23.png) ![](images/week05/2021-02-05_00_17_10.png) You should see the large swath of deleted lines ![](images/week05/2021-02-05_00_21_01.png) ![](images/week05/2021-02-05_00_22_10.png) Back in the github, find and click the file name. ![](images/week05/2021-02-05_00_24_21.png) The file contents will show the most recent saved version (missing the Leaflet map lines). Click on the `History` link, which will show all of the commits. ![](images/week05/2021-02-05_00_25_05.png) Click the commit where you followed the questionable advice from your adviser. ![](images/week05/2021-02-05_00_25_23.png) The missing lines are evident. What we would like to do is to go back to the version before the large deletion of lines. ![](images/week05/2021-02-05_00_25_40.png) Identify the previous commit and click the clipboard icon to the left of the first characters of the commit hash. This will copy the hash, which is necessary for restoring that version. ![](images/week05/2021-02-05_00_39_46.png) Back in the shell, enter ``` git show *****:week_01.Rmd ``` where `*****` is the hash. ![](images/week05/2021-02-05_00_40_36.png) You will see the text that was present at that commit, which includes the deleted Leaflet map. ![](images/week05/2021-02-05_00_40_59.png) To restore this previous version to a new file, enter ``` git show *****:week_01.Rmd &gt; week_01_someadditionaldescription.Rmd ``` This prints the contents of the previously committed file and redirects the output to the named file after the `&gt;` sign. ![](images/week05/2021-02-05_00_45_16.png) If you open that file, you will see the restored text. ![](images/week05/2021-02-05_00_46_04.png) ## Conclusion This was a brief introduction to the main functionality of Git with RStudio and github. If you expect to perform even a modest amount of coding, you could benefit from Git as a way to keep track of your work, collaborate with others, and avoid programming disasters due to inadvertent deletion of overwriting of files. ## Source code [05-week05.Rmd](05-week05.Rmd) ```{r comment=&#39;&#39;} cat(readLines(&quot;05-week05.Rmd&quot;), sep = &#39;\\n&#39;) ``` "],["week6.html", "6 Week 6 6.1 The Add Health study data 6.2 Documentation 6.3 Data sets 6.4 Searching through documentation 6.5 Conclusion 6.6 Source code", " 6 Week 6 Topic: Add Health data: exploring variables and data documentation 6.1 The Add Health study data The Add Health web site describes the study: Initiated in 1994 and supported by five program project grants from the Eunice Kennedy Shriver National Institute of Child Health and Human Development (NICHD) with co-funding from 23 other federal agencies and foundations, Add Health is the largest, most comprehensive, nationally-representative longitudinal survey of adolescents ever undertaken. Beginning with an in-school questionnaire administered to a nationally representative sample of students in grades 7-12, the study followed up with a series of in-home interviews conducted in 1995, 1996, 2001-02, 2008, and 2016-18. Add Health participants are now full-fledged adults, aged 33-44, and will soon be moving into midlife. Over the years, Add Health has added a substantial amount of additional data for users, including contextual data on the communities and states in which participants reside, genomic data and a range of biological health markers of participants, and parental survey data. The public-use data contain a subset of records and variables from the restricted-use full data set. The full data set requires a lengthy application process and meeting specific security standards. CSDE has a copy of most of the tables in the restricted-use data set on the UW Data Collaborative. We will be using the Wave 1 public-use Add Health data for most of the remainder of the term. This week we will briefly delve into the documentation and see how the data set use is supported by the documentation. 6.2 Documentation The Add Health data are very well documented. The PDFs contain the verbatim text of the survey questions, the range of encoded answers, and count tabulations of responses. See the full set of metadata PDFs: Wave1_InHome_Codebooks, and the comprehensive codebook. We will revisit the documentation later in this lesson. 6.3 Data sets The two data sets we will be using are AHwave1_v1.dta.zip and 21600-0001-Data.dta.zip. Download each file and unzip them, which will result in AHwave1_v1.dta, which we have encountered before, and 21600-0001-Data.dta. Both of these are Stata files. Stata files version 12 and below can be read with foreign::read.dta(), but version 13 and up require haven::read_dta() or readstata13::read.dta13(). One of the benefits of the Stata file formats, as compared to e.g., CSV or Excel, is that the Stata files can contain metadata about the variables. The imported data frames themselves may have cryptic variable names, but more extensive labels. The R import process can expose those labels, making the data more easy to interpret 6.3.1 AHwave1_v1.dta AHwave1_v1.dta is a Stata version 13 file. Here we will look at the two import options. 6.3.1.1 haven::read_dta() haven::read_dta() will read the data in as a data frame. Note for the code examples to run without modification, the assumption is that the data have been downloaded and unzipped in a subfolder named data within the current working directory. You can find out what the current working directory is by entering getwd() at the R prompt. # read the data if(!file.exists(&quot;data/AHwave1_v1.dta&quot;)){ unzip(zipfile = &quot;data/AHwave1_v1.dta.zip&quot;, exdir = &quot;data&quot;) } AHwave1_v1_haven &lt;- haven::read_dta(file = &quot;data/AHwave1_v1.dta&quot;) Each labeled variable has attributes can be perused by listing structure: str(AHwave1_v1_haven$imonth) ## dbl+lbl [1:6504] 6, 5, 6, 7, 7, 6, 5, 6, 6, 8, 9, 5, 6, 7, 5, 5, 7, 5, 8, 7, 6, 5, 7, 8, 7, 8, 6, 6, 4, 7, 7... ## @ label : chr &quot;MONTH OF INTERVIEW-W1&quot; ## @ format.stata: chr &quot;%13.0f&quot; ## @ labels : Named num [1:10] 1 4 5 6 7 8 9 10 11 12 ## ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;(1) January&quot; &quot;(4) April&quot; &quot;(5) May&quot; &quot;(6) June&quot; ... or the first few values (head()): head(AHwave1_v1_haven$bio_sex) ## &lt;labelled&lt;double&gt;[6]&gt;: BIOLOGICAL SEX-W1 ## [1] 2 2 1 1 2 1 ## ## Labels: ## value label ## 1 (1) Male ## 2 (2) Female ## 6 (6) Refused or listing the attributes of the variable itself, which provides a more verbose listing of the variable label, data format, class, and value labels: attributes(AHwave1_v1_haven$h1gi1m) ## $label ## [1] &quot;S1Q1 BIRTH MONTH-W1&quot; ## ## $format.stata ## [1] &quot;%13.0f&quot; ## ## $class ## [1] &quot;haven_labelled&quot; &quot;vctrs_vctr&quot; &quot;double&quot; ## ## $labels ## (1) January (2) February (3) March (4) April (5) May (6) June (7) July (8) August ## 1 2 3 4 5 6 7 8 ## (9) September (10) October (11) November (12) December (96) Refused ## 9 10 11 12 96 In order to access the metadata as a single object, one can use the lapply() function, because the data frame can also be treated as a list. Here, each variable has its name, label, data format, and values extracted to a single data frame and presented as a DT::datatable. This provides the metadata in a format that is probably easier to use than the PDF documentation. AHwave1_v1_haven_metadata &lt;- bind_cols( # variable name varname = colnames(AHwave1_v1_haven), # label varlabel = lapply(AHwave1_v1_haven, function(x) attributes(x)$label) %&gt;% unlist(), # format varformat = lapply(AHwave1_v1_haven, function(x) attributes(x)$format.stata) %&gt;% unlist(), # values varvalues = lapply(AHwave1_v1_haven, function(x) attributes(x)$labels) %&gt;% # names the variable label vector lapply(., function(x) names(x)) %&gt;% # as character as.character() %&gt;% # remove the c() construction str_remove_all(&quot;^c\\\\(|\\\\)$&quot;) ) DT::datatable(AHwave1_v1_haven_metadata) 6.3.1.2 readstata13::read.dta13() readstata13::read.dta13() will similarly read the data as a data frame. There are a number of different options for converting factors, so if you are dealing with a lot of Stata files you may want to become familiar with some of these options. For example, using all default options kicks out some warnings about double precision coding and missing factor labels. [Note: to hide these warnings, for better or worse (i.e., you might not want to hide them), use the code chunk option warning=FALSE]. # read the data AHwave1_v1_rs13 &lt;- readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;) ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr7a: ## Factor codes of type double or float detected - no labels assigned. ## Set option nonint.factors to TRUE to assign labels anyway. ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr8a: ## Missing factor labels - no labels assigned. ## Set option generate.factors=T to generate labels. ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr7b: ## Factor codes of type double or float detected - no labels assigned. ## Set option nonint.factors to TRUE to assign labels anyway. ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr8b: ## Missing factor labels - no labels assigned. ## Set option generate.factors=T to generate labels. ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr7c: ## Missing factor labels - no labels assigned. ## Set option generate.factors=T to generate labels. ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr8c: ## Missing factor labels - no labels assigned. ## Set option generate.factors=T to generate labels. ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr7d: ## Missing factor labels - no labels assigned. ## Set option generate.factors=T to generate labels. ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr8d: ## Missing factor labels - no labels assigned. ## Set option generate.factors=T to generate labels. ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr7e: ## Missing factor labels - no labels assigned. ## Set option generate.factors=T to generate labels. ## Warning in readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;): ## h1hr8e: ## Missing factor labels - no labels assigned. ## Set option generate.factors=T to generate labels. # read the data AHwave1_v1_rs13 &lt;- readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;, generate.factors = TRUE, nonint.factors = TRUE) Metadata can be generated similarly: AHwave1_v1_rs13_metadata &lt;- bind_cols( varname = colnames(AHwave1_v1_rs13), varlabel = attributes(AHwave1_v1_rs13)$var.labels, varformat = attributes(AHwave1_v1_rs13)$formats ) # value ranges; need to do this separately because those variables with no value labels were not accounted for varvalues &lt;- bind_cols( varname = names(attributes(AHwave1_v1_rs13)$label.table) %&gt;% tolower, vals = attributes(AHwave1_v1_rs13)$label.table %&gt;% lapply(., function(x) names(x)) %&gt;% as.character() %&gt;% str_remove_all(&quot;^c\\\\(|\\\\)$&quot;)) # join AHwave1_v1_rs13_metadata %&lt;&gt;% left_join(varvalues, by = &quot;varname&quot;) DT::datatable(AHwave1_v1_rs13_metadata) The default conversion creates factors, so the tables may be easy to read/interpret ... head(x = AHwave1_v1_rs13$imonth, n = 6) ## [1] (6) June (5) May (6) June (7) July (7) July (6) June ## 10 Levels: (1) January (4) April (5) May (6) June (7) July (8) August (9) September ... (12) December ... but programming will require more work because the factors would either need to be explicitly named, e.g., AHwave1_v1_rs13 %&gt;% head(10) %&gt;% filter(imonth == &quot;(6) June&quot;) %&gt;% select(aid, imonth, iday) ## aid imonth iday ## 1 57100270 (6) June 23 ## 2 57103171 (6) June 27 ## 3 57104649 (6) June 12 ## 4 57109625 (6) June 7 ## 5 57110897 (6) June 27 Because the factors are really just labelled numbers, one could use the numeric values, but care needs to be taken: levels(AHwave1_v1_rs13$imonth) %&gt;% t() %&gt;% t() ## [,1] ## [1,] &quot;(1) January&quot; ## [2,] &quot;(4) April&quot; ## [3,] &quot;(5) May&quot; ## [4,] &quot;(6) June&quot; ## [5,] &quot;(7) July&quot; ## [6,] &quot;(8) August&quot; ## [7,] &quot;(9) September&quot; ## [8,] &quot;(10) October&quot; ## [9,] &quot;(11) November&quot; ## [10,] &quot;(12) December&quot; Because not all months are represented in the data, the numerical value of the month may not be what you expect. For example, the 4th month factor level is &quot;(6) June&quot; rather than &quot;(4) April&quot;. Compare this with the results from haven::read_dta(). The values are not factors, but labelled double-precision numbers: head(AHwave1_v1_haven$imonth) ## &lt;labelled&lt;double&gt;[6]&gt;: MONTH OF INTERVIEW-W1 ## [1] 6 5 6 7 7 6 ## ## Labels: ## value label ## 1 (1) January ## 4 (4) April ## 5 (5) May ## 6 (6) June ## 7 (7) July ## 8 (8) August ## 9 (9) September ## 10 (10) October ## 11 (11) November ## 12 (12) December To perform a similar filter() &amp; select() operation with the haven version: AHwave1_v1_haven %&gt;% head(10) %&gt;% filter(imonth == 6) %&gt;% select(aid, imonth, iday) ## # A tibble: 5 x 3 ## aid imonth iday ## &lt;chr&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; ## 1 57100270 6 [(6) June] 23 ## 2 57103171 6 [(6) June] 27 ## 3 57104649 6 [(6) June] 12 ## 4 57109625 6 [(6) June] 7 ## 5 57110897 6 [(6) June] 27 Which approach do you prefer? 6.3.2 21600-0001-Data.dta 21600-0001-Data.dta is a much larger data set. It has the same count of records, but more columns than AHwave1_v1.dta. # read in the larger data set if(!file.exists(&quot;data/21600-0001-Data.dta&quot;)){ unzip(zipfile = &quot;data/21600-0001-Data.dta.zip&quot;, exdir = &quot;data&quot;) } data_21600_0001 &lt;- haven::read_dta(file = &quot;data/21600-0001-Data.dta&quot;) if(file.exists(&quot;data/21600-0001-Data.dta&quot;)){ file.remove(file = &quot;data/21600-0001-Data.dta&quot;) } ## [1] TRUE # dimensions of the two dim(AHwave1_v1_haven) ## [1] 6504 103 dim(data_21600_0001) ## [1] 6504 2794 In fact, AHwave1_v1.dta seems to be a subset of 21600-0001-Data.dta. We can show this by lower casing the column names and then using a select() for the same named columns # lowercase the column names colnames(data_21600_0001) %&lt;&gt;% str_to_lower() # select() some columns of the same name dat &lt;- data_21600_0001 %&gt;% select(colnames(AHwave1_v1_haven)) # identical? identical(dat, AHwave1_v1_haven) ## [1] TRUE if(file.exists(&quot;data/AHwave1_v1.dta&quot;)){ file.remove(&quot;data/AHwave1_v1.dta&quot;) } ## [1] TRUE We can build a similar table of metadata, but this time as a function: # a generic(?) function to generate metadata for a Stata file read by haven::read_dta() # x is a haven data frame f_haven_stata_metadata &lt;- function(x){ # variable names varname &lt;- colnames(x) # labels varlabel &lt;- x %&gt;% lapply(., function(x) attributes(x)$label) %&gt;% unlist() # format varformat &lt;- x %&gt;% lapply(., function(x) attributes(x)$format.stata) %&gt;% unlist() # values varvalues &lt;- x %&gt;% lapply(., function(x) attributes(x)$labels) %&gt;% # names the variable label vector lapply(., function(x) names(x)) %&gt;% # as character as.character() %&gt;% # remove the c() construction str_remove_all(&quot;^c\\\\(|\\\\)$&quot;) bind_cols(varname = varname, varlabel = varlabel, varformat = varformat, varvalues = varvalues) } # generate the metadata data_21600_0001_metadata &lt;- f_haven_stata_metadata(data_21600_0001) # print the metadata table as a DT::datatable DT::datatable(data_21600_0001_metadata) 6.4 Searching through documentation Good data sets have good documentation. Sometimes the documentation is voluminous, as is the case for the Add Health data. With voluminous metadata, are there good approaches to finding what you are interested in without opening each PDF file, reading the table of contents, searching for string matches, etc.? This section will cover two tools to make searching through PDF files less onerous and more efficient. The two utilities are pdfgrep and pdftools::pdf_text() 6.4.1 pdfgrep grep is a string-matching utility developed mainly for UNIX, now available for all common operating systems. It is also implemented in base R with the function grep(). The name comes from the ed command g/re/p (\\(\\underline{g}\\)lobally search for a \\(\\underline{r}\\)egular \\(\\underline{e}\\)xpression and \\(\\underline{p}\\)rint matching lines), typically used to print the line number of a text file containing the search pattern. If you are not familiar with regular expressions and you plan on doing computational social sciences, the sooner you learn, the better. See the R help topic for base::regex(). We won't be covering grep in general here, but will introduce some of the regular expression logic in pdfgrep. Start by installing a version of pdfgrep. These are three implementations, one for Mac and two for Windows. The demo today will use the Cygwin version. The native Windows version is not as powerful/customizable as the Cygwin version and will also likely be more comparable with the Mac version. Note: pdfgrep will only work on PDF files that contain text. PDFs that are composed solely from scanned images contain no text and are therefore not searchable using regular expressions. pdfgrep for native Windows pdfgrep for Cygwin under Windows pdfgrep for Mac A zipped file containing all of the metadata files for the In Home Questionnaire is available as Wave1_InHome_Codebooks.pdf.zip. Download the file and unzip it in an appropriate location. 6.4.1.1 A few use examples [Note: the images below may be hard to read; clicking them will open them in full-size; click with the middle mouose button to open in a new tab.] Here we will search through the entire set of PDF files for the regular expression black. First, let's list the PDF files using ls *.pdf The syntax for the search is pdfgrep black *.pdf This prints the file name and the matching text of each PDF containing the regular expression black. Suppose we wanted to search for black or Black or BLACK? Use the flag -i which is short for case \\(\\underline{i}\\)nsensitive. pdfgrep -i black *.pdf This shows all files that contain black in any case combination. We might want to know where to look (i.e., page number) in the file. Using the -n flag prints the page \\(\\underline{n}\\)umber. Seeing that there are several matches in inh25pub.pdf, the first match on page 13, let's view that: Let's look for another pattern, the word recreation: pdfgrep -n -i recreation *.pdf Seeing the matches, we might want to narrow the search to include only &quot;social or recreation&quot;al activity. Here, the regular expression is social.*recreation, where the .* regexp translates to &quot;any number of any characters.&quot; We will perform one more pattern match. Suppose we were interested in being tired or stressed. The regexp pattern &quot;pat1|pat2&quot; (note the quotes and the vertical bar). The quotes indicate to the shell that this is not a pipe, but part of the regexp. Here the full expression to show those metadata files that match either of these patterns. pdfgrep -i &quot;tired|stress&quot; *.pdf Why, you may ask, if we created those fancy metadata tables from the data, would we want to search for specific strings in the PDF documentation? Because the full documentation is likely to provide more complete explanations, whereas the metadata created from the data labels is only a brief description. 6.4.2 pdftools::pdf_text() Staying completely within R, we can perform similar searches through PDF files. We start with pdftools::pdf_text(), which converts PDFs to text vectors, where each page is converted to one vector element. This can be piped through text-matching functions, such as base::grep() or stringr::str_match() (stringr is loaded by tidyverse). Unlike pdfgrep, which can serially search through a set of files in a directory, pdf_text() requires additional work. Here is an example that mimics searching for the case-insensitive regular expression black in the set of PDFs. We create a function that searches through a single PDF and then loop the function over the set of PDFs in a specified folder, returning the file name list, the pattern we searched on, the page number with the match, and whether the search was case sensitive or not. # a function to get matching strings in a PDF, ignore case f_pdf_str_match &lt;- function(x, pat, ignore.case = TRUE){ # convert the PDF to text mytext &lt;- pdf_text(x) # pattern if(ignore.case){ mypat &lt;- regex(pat, ignore_case = TRUE) } else { mypat &lt;- pat } # match strings = pages pages &lt;- str_which(string = mytext, pattern = mypat) if(length(pages) == 0){ return(data.frame(fname = x, pat, page_num = as.integer(NA), ignore.case)) } # create a data frame data.frame(fname = x, pat, page_num = pages, ignore.case) } # a list of my PDFs mypdfs &lt;- list.files(path = &quot;data/metadata/Wave1_InHome_Codebooks&quot;, pattern = &quot;*.pdf$&quot;, full.names = TRUE) # an empty data frame x &lt;- NULL # run each one for(i in mypdfs){ x &lt;- rbind(x, f_pdf_str_match(i, &quot;black&quot;, ignore.case = TRUE)) } # ignore NAs x %&gt;% filter(!is.na(page_num)) ## fname pat page_num ignore.case ## 1 data/metadata/Wave1_InHome_Codebooks/inh01pub.pdf black 7 TRUE ## 2 data/metadata/Wave1_InHome_Codebooks/inh01pub.pdf black 9 TRUE ## 3 data/metadata/Wave1_InHome_Codebooks/inh25pub.pdf black 13 TRUE ## 4 data/metadata/Wave1_InHome_Codebooks/inh25pub.pdf black 56 TRUE ## 5 data/metadata/Wave1_InHome_Codebooks/inh25pub.pdf black 96 TRUE ## 6 data/metadata/Wave1_InHome_Codebooks/inh26pub.pdf black 13 TRUE ## 7 data/metadata/Wave1_InHome_Codebooks/inh26pub.pdf black 43 TRUE ## 8 data/metadata/Wave1_InHome_Codebooks/inh26pub.pdf black 69 TRUE ## 9 data/metadata/Wave1_InHome_Codebooks/inh26pub.pdf black 98 TRUE ## 10 data/metadata/Wave1_InHome_Codebooks/inh26pub.pdf black 120 TRUE ## 11 data/metadata/Wave1_InHome_Codebooks/inh26pub.pdf black 143 TRUE ## 12 data/metadata/Wave1_InHome_Codebooks/sectapub.pdf black 3 TRUE ## 13 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 2 TRUE ## 14 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 28 TRUE ## 15 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 31 TRUE ## 16 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 33 TRUE ## 17 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 37 TRUE ## 18 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 39 TRUE ## 19 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 41 TRUE ## 20 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 43 TRUE ## 21 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 46 TRUE ## 22 data/metadata/Wave1_InHome_Codebooks/w1ndxpub.pdf black 48 TRUE 6.5 Conclusion We will use these data sets and metadata for the next several lessons. The methods presented in today's lesson should increase efficiency and reduce busy-work. 6.6 Source code 06-week06.Rmd cat(readLines(con = &quot;06-week06.Rmd&quot;), sep = &#39;\\n&#39;) # Week 6 {#week6} ```{r, echo=FALSE, warning=FALSE, message=FALSE} library(tidyverse) library(magrittr) library(knitr) library(kableExtra) library(readstata13) library(haven) library(pdftools) ``` &lt;h2&gt;Topic: Add Health data: exploring variables and data documentation&lt;/h2&gt; ## The Add Health study data The Add Health [web site](https://data.cpc.unc.edu/projects/2/view) describes the study: &gt; Initiated in 1994 and supported by five program project grants from the Eunice Kennedy Shriver National Institute of Child Health and Human Development (NICHD) with co-funding from 23 other federal agencies and foundations, Add Health is the largest, most comprehensive, nationally-representative longitudinal survey of adolescents ever undertaken. Beginning with an in-school questionnaire administered to a nationally representative sample of students in grades 7-12, the study followed up with a series of in-home interviews conducted in 1995, 1996, 2001-02, 2008, and 2016-18. Add Health participants are now full-fledged adults, aged 33-44, and will soon be moving into midlife. Over the years, Add Health has added a substantial amount of additional data for users, including contextual data on the communities and states in which participants reside, genomic data and a range of biological health markers of participants, and parental survey data. The public-use data contain a subset of records and variables from the restricted-use full data set. The full data set requires a lengthy application process and meeting specific security standards. [CSDE](https://csde.washington.edu/) has a copy of most of the tables in the restricted-use data set on the [UW Data Collaborative](https://dcollab.uw.edu/data/add-health/). We will be using the Wave 1 public-use Add Health data for most of the remainder of the term. This week we will briefly delve into the documentation and see how the data set use is supported by the documentation. ## Documentation The Add Health data are very well documented. The PDFs contain the verbatim text of the survey questions, the range of encoded answers, and count tabulations of responses. See the full set of metadata PDFs: [Wave1_InHome_Codebooks](data/metadata/Wave1_InHome_Codebooks/), and the [comprehensive codebook](data/metadata/Wave1_Comprehensive_Codebook/). We will revisit the documentation later in this lesson. ## Data sets The two data sets we will be using are [AHwave1_v1.dta.zip](data/AHwave1_v1.dta.zip) and [21600-0001-Data.dta.zip](data/21600-0001-Data.dta.zip). Download each file and unzip them, which will result in `AHwave1_v1.dta`, which we have encountered before, and `21600-0001-Data.dta`. Both of these are Stata files. Stata files version 12 and below can be read with `foreign::read.dta()`, but version 13 and up require `haven::read_dta()` or `readstata13::read.dta13()`. One of the benefits of the Stata file formats, as compared to e.g., CSV or Excel, is that the Stata files can contain metadata about the variables. The imported data frames themselves may have cryptic variable names, but more extensive _labels_. The R import process can expose those labels, making the data more easy to interpret ### `AHwave1_v1.dta` `AHwave1_v1.dta` is a Stata version 13 file. Here we will look at the two import options. #### `haven::read_dta()` `haven::read_dta()` will read the data in as a data frame. Note for the code examples to run without modification, the assumption is that the data have been downloaded and unzipped in a subfolder named `data` within the current working directory. You can find out what the current working directory is by entering `getwd()` at the R prompt. ```{r} # read the data if(!file.exists(&quot;data/AHwave1_v1.dta&quot;)){ unzip(zipfile = &quot;data/AHwave1_v1.dta.zip&quot;, exdir = &quot;data&quot;) } AHwave1_v1_haven &lt;- haven::read_dta(file = &quot;data/AHwave1_v1.dta&quot;) ``` Each labeled variable has attributes can be perused by listing structure: ```{r} str(AHwave1_v1_haven$imonth) ``` or the first few values (`head()`): ```{r} head(AHwave1_v1_haven$bio_sex) ``` or listing the attributes of the variable itself, which provides a more verbose listing of the variable label, data format, class, and value labels: ```{r} attributes(AHwave1_v1_haven$h1gi1m) ``` In order to access the metadata as a single object, one can use the `lapply()` function, because the data frame can also be treated as a list. Here, each variable has its name, label, data format, and values extracted to a single data frame and presented as a `DT::datatable`. This provides the metadata in a format that is probably easier to use than the PDF documentation. ```{r} AHwave1_v1_haven_metadata &lt;- bind_cols( # variable name varname = colnames(AHwave1_v1_haven), # label varlabel = lapply(AHwave1_v1_haven, function(x) attributes(x)$label) %&gt;% unlist(), # format varformat = lapply(AHwave1_v1_haven, function(x) attributes(x)$format.stata) %&gt;% unlist(), # values varvalues = lapply(AHwave1_v1_haven, function(x) attributes(x)$labels) %&gt;% # names the variable label vector lapply(., function(x) names(x)) %&gt;% # as character as.character() %&gt;% # remove the c() construction str_remove_all(&quot;^c\\\\(|\\\\)$&quot;) ) DT::datatable(AHwave1_v1_haven_metadata) ``` #### `readstata13::read.dta13()` `readstata13::read.dta13()` will similarly read the data as a data frame. There are a number of different options for converting factors, so if you are dealing with a lot of Stata files you may want to become familiar with some of these options. For example, using all default options kicks out some warnings about double precision coding and missing factor labels. _[Note: to hide these warnings, for better or worse (i.e., you might not want to hide them), use the code chunk option `warning=FALSE`]._ ```{r} # read the data AHwave1_v1_rs13 &lt;- readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;) ``` ```{r} # read the data AHwave1_v1_rs13 &lt;- readstata13::read.dta13(file = &quot;data/AHwave1_v1.dta&quot;, generate.factors = TRUE, nonint.factors = TRUE) ``` Metadata can be generated similarly: ```{r} AHwave1_v1_rs13_metadata &lt;- bind_cols( varname = colnames(AHwave1_v1_rs13), varlabel = attributes(AHwave1_v1_rs13)$var.labels, varformat = attributes(AHwave1_v1_rs13)$formats ) # value ranges; need to do this separately because those variables with no value labels were not accounted for varvalues &lt;- bind_cols( varname = names(attributes(AHwave1_v1_rs13)$label.table) %&gt;% tolower, vals = attributes(AHwave1_v1_rs13)$label.table %&gt;% lapply(., function(x) names(x)) %&gt;% as.character() %&gt;% str_remove_all(&quot;^c\\\\(|\\\\)$&quot;)) # join AHwave1_v1_rs13_metadata %&lt;&gt;% left_join(varvalues, by = &quot;varname&quot;) DT::datatable(AHwave1_v1_rs13_metadata) ``` The default conversion creates factors, so the tables _may_ be easy to read/interpret ... ```{r} head(x = AHwave1_v1_rs13$imonth, n = 6) ``` ... but programming will require more work because the factors would either need to be explicitly named, e.g., ```{r} AHwave1_v1_rs13 %&gt;% head(10) %&gt;% filter(imonth == &quot;(6) June&quot;) %&gt;% select(aid, imonth, iday) ``` Because the factors are really just labelled numbers, one could use the numeric values, but care needs to be taken: ```{r} levels(AHwave1_v1_rs13$imonth) %&gt;% t() %&gt;% t() ``` Because not all months are represented in the data, the numerical value of the month may not be what you expect. For example, the 4th month factor level is &quot;(6) June&quot; rather than &quot;(4) April&quot;. Compare this with the results from `haven::read_dta()`. The values are not factors, but labelled double-precision numbers: ```{r} head(AHwave1_v1_haven$imonth) ``` To perform a similar `filter()` &amp; `select()` operation with the haven version: ```{r} AHwave1_v1_haven %&gt;% head(10) %&gt;% filter(imonth == 6) %&gt;% select(aid, imonth, iday) ``` ___Which approach do you prefer?___ ### `21600-0001-Data.dta` `21600-0001-Data.dta` is a much larger data set. It has the same count of records, but more columns than `AHwave1_v1.dta`. ```{r} # read in the larger data set if(!file.exists(&quot;data/21600-0001-Data.dta&quot;)){ unzip(zipfile = &quot;data/21600-0001-Data.dta.zip&quot;, exdir = &quot;data&quot;) } data_21600_0001 &lt;- haven::read_dta(file = &quot;data/21600-0001-Data.dta&quot;) if(file.exists(&quot;data/21600-0001-Data.dta&quot;)){ file.remove(file = &quot;data/21600-0001-Data.dta&quot;) } # dimensions of the two dim(AHwave1_v1_haven) dim(data_21600_0001) ``` In fact, `AHwave1_v1.dta` seems to be a subset of `21600-0001-Data.dta`. We can show this by lower casing the column names and then using a `select()` for the same named columns ```{r} # lowercase the column names colnames(data_21600_0001) %&lt;&gt;% str_to_lower() # select() some columns of the same name dat &lt;- data_21600_0001 %&gt;% select(colnames(AHwave1_v1_haven)) # identical? identical(dat, AHwave1_v1_haven) if(file.exists(&quot;data/AHwave1_v1.dta&quot;)){ file.remove(&quot;data/AHwave1_v1.dta&quot;) } ``` We can build a similar table of metadata, but this time as a function: ```{r} # a generic(?) function to generate metadata for a Stata file read by haven::read_dta() # x is a haven data frame f_haven_stata_metadata &lt;- function(x){ # variable names varname &lt;- colnames(x) # labels varlabel &lt;- x %&gt;% lapply(., function(x) attributes(x)$label) %&gt;% unlist() # format varformat &lt;- x %&gt;% lapply(., function(x) attributes(x)$format.stata) %&gt;% unlist() # values varvalues &lt;- x %&gt;% lapply(., function(x) attributes(x)$labels) %&gt;% # names the variable label vector lapply(., function(x) names(x)) %&gt;% # as character as.character() %&gt;% # remove the c() construction str_remove_all(&quot;^c\\\\(|\\\\)$&quot;) bind_cols(varname = varname, varlabel = varlabel, varformat = varformat, varvalues = varvalues) } # generate the metadata data_21600_0001_metadata &lt;- f_haven_stata_metadata(data_21600_0001) # print the metadata table as a DT::datatable DT::datatable(data_21600_0001_metadata) ``` ## Searching through documentation Good data sets have good documentation. Sometimes the documentation is voluminous, as is the case for the Add Health data. With voluminous metadata, are there good approaches to finding what you are interested in without opening each PDF file, reading the table of contents, searching for string matches, etc.? This section will cover two tools to make searching through PDF files less onerous and more efficient. The two utilities are `pdfgrep` and `pdftools::pdf_text()` ### `pdfgrep` `grep` is a string-matching utility developed mainly for UNIX, now available for all common operating systems. It is also implemented in base R with the function `grep()`. The name comes from the ed command g/re/p ($\\underline{g}$lobally search for a $\\underline{r}$egular $\\underline{e}$xpression and $\\underline{p}$rint matching lines), typically used to print the line number of a text file containing the search pattern. If you are not familiar with regular expressions and you plan on doing computational social sciences, the sooner you learn, the better. See the R help topic for `base::regex()`. We won&#39;t be covering `grep` in general here, but will introduce some of the regular expression logic in `pdfgrep`. Start by installing a version of `pdfgrep`. These are three implementations, one for Mac and two for Windows. The demo today will use the Cygwin version. The native Windows version is not as powerful/customizable as the Cygwin version and will also likely be more comparable with the Mac version. ___Note:___ `pdfgrep` will only work on PDF files that contain text. PDFs that are composed solely from scanned images contain no text and are therefore not searchable using regular expressions. [pdfgrep for native Windows](https://soft.rubypdf.com/software/pdfgrep-windows-version) [pdfgrep for Cygwin under Windows](https://cygwin.com/cgi-bin2/package-cat.cgi?file=x86%2Fpdfgrep%2Fpdfgrep-1.4.1-1&amp;grep=pdfgrep) [pdfgrep for Mac](http://macappstore.org/pdfgrep/) A zipped file containing all of the metadata files for the In Home Questionnaire is available as [Wave1_InHome_Codebooks.pdf.zip](data/metadata/Wave1_InHome_Codebooks/Wave1_InHome_Codebooks.pdf.zip). Download the file and unzip it in an appropriate location. #### A few use examples _[Note: the images below may be hard to read; clicking them will open them in full-size; click with the middle mouose button to open in a new tab.]_ Here we will search through the entire set of PDF files for the regular expression `black`. First, let&#39;s list the PDF files using ` ls *.pdf ` [![](images/week06/2021-02-11_21_31_11-_cygdrive_L.png)](images/week06/2021-02-11_21_31_11-_cygdrive_L.png) The syntax for the search is ` pdfgrep black *.pdf ` [![](images/week06/2021-02-11_21_45_41-_cygdrive_L.png)](images/week06/2021-02-11_21_45_41-_cygdrive_L.png) This prints the file name and the matching text of each PDF containing the regular expression `black`. Suppose we wanted to search for `black` or `Black` or `BLACK`? Use the flag `-i` which is short for case $\\underline{i}$nsensitive. ` pdfgrep -i black *.pdf ` [![](images/week06/2021-02-11_21_47_06-_cygdrive_L.png)](images/week06/2021-02-11_21_47_06-_cygdrive_L.png) This shows all files that contain `black` in any case combination. We might want to know where to look (i.e., page number) in the file. Using the `-n` flag prints the page $\\underline{n}$umber. [![](images/week06/2021-02-11_21_47_38-_cygdrive_L.png)](images/week06/2021-02-11_21_47_38-_cygdrive_L.png) Seeing that there are several matches in `inh25pub.pdf`, the first match on page 13, let&#39;s view that: [![](images/week06/2021-02-11_22_16_08-inh25pub.pdf.png)](images/week06/2021-02-11_22_16_08-inh25pub.pdf.png) Let&#39;s look for another pattern, the word `recreation`: ` pdfgrep -n -i recreation *.pdf ` [![](images/week06/2021-02-11_21_48_14-_cygdrive_L.png)](images/week06/2021-02-11_21_48_14-_cygdrive_L.png) Seeing the matches, we might want to narrow the search to include only &quot;social or recreation&quot;al activity. Here, the regular expression is `social.*recreation`, where the `.*` regexp translates to &quot;any number of any characters.&quot; [![](images/week06/2021-02-11_21_48_34-_cygdrive_L.png)](images/week06/2021-02-11_21_48_34-_cygdrive_L.png) We will perform one more pattern match. Suppose we were interested in being tired or stressed. The regexp pattern `&quot;pat1|pat2&quot;` (note the quotes and the vertical bar). The quotes indicate to the shell that [this is not a pipe](#magrittr), but part of the regexp. Here the full expression to show those metadata files that match either of these patterns. ` pdfgrep -i &quot;tired|stress&quot; *.pdf ` [![](images/week06/2021-02-11_21_54_04-_cygdrive_L.png)](images/week06/2021-02-11_21_54_04-_cygdrive_L.png) ___Why___, you may ask, if we created those fancy metadata tables from the data, would we want to search for specific strings in the PDF documentation? Because the full documentation is likely to provide more complete explanations, whereas the metadata created from the data labels is only a brief description. ### `pdftools::pdf_text()` Staying completely within R, we can perform similar searches through PDF files. We start with `pdftools::pdf_text()`, which converts PDFs to text vectors, where each page is converted to one vector element. This can be piped through text-matching functions, such as `base::grep()` or `stringr::str_match()` (`stringr` is loaded by `tidyverse`). Unlike `pdfgrep`, which can serially search through a set of files in a directory, `pdf_text()` requires additional work. Here is an example that mimics searching for the case-insensitive regular expression `black` in the set of PDFs. We create a function that searches through a single PDF and then loop the function over the set of PDFs in a specified folder, returning the file name list, the pattern we searched on, the page number with the match, and whether the search was case sensitive or not. ```{r} # a function to get matching strings in a PDF, ignore case f_pdf_str_match &lt;- function(x, pat, ignore.case = TRUE){ # convert the PDF to text mytext &lt;- pdf_text(x) # pattern if(ignore.case){ mypat &lt;- regex(pat, ignore_case = TRUE) } else { mypat &lt;- pat } # match strings = pages pages &lt;- str_which(string = mytext, pattern = mypat) if(length(pages) == 0){ return(data.frame(fname = x, pat, page_num = as.integer(NA), ignore.case)) } # create a data frame data.frame(fname = x, pat, page_num = pages, ignore.case) } # a list of my PDFs mypdfs &lt;- list.files(path = &quot;data/metadata/Wave1_InHome_Codebooks&quot;, pattern = &quot;*.pdf$&quot;, full.names = TRUE) # an empty data frame x &lt;- NULL # run each one for(i in mypdfs){ x &lt;- rbind(x, f_pdf_str_match(i, &quot;black&quot;, ignore.case = TRUE)) } # ignore NAs x %&gt;% filter(!is.na(page_num)) ``` ## Conclusion We will use these data sets and metadata for the next several lessons. The methods presented in today&#39;s lesson should increase efficiency and reduce busy-work. ## Source code [06-week06.Rmd](06-week06.Rmd) ```{r comment=&#39;&#39;} cat(readLines(con = &quot;06-week06.Rmd&quot;), sep = &#39;\\n&#39;) ``` "],["week7.html", "7 Week 7 7.1 Creating value labels 7.2 Tabulation 7.3 Source code", " 7 Week 7 Topic: Add Health data: variable creation and tabulation This week's lesson will provide more background on variable creation and tabulation of variables. 7.1 Creating value labels &quot;Labeled&quot; data are important for documentation of data sets. The labels can apply to different objects, e.g., columns (as we saw in the column labels used to &quot;decode&quot; the data set in AHwave1_v1.dta, Section 2.4), or to individual values of variables, e.g., the attribute labels of the variable h1gi1m: AHwave1_v1_haven &lt;- haven::read_dta(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta&quot;) attributes(AHwave1_v1_haven$h1gi1m)$labels ## (1) January (2) February (3) March (4) April (5) May (6) June (7) July (8) August ## 1 2 3 4 5 6 7 8 ## (9) September (10) October (11) November (12) December (96) Refused ## 9 10 11 12 96 Consider the difference between different file formats. Here we will save the data set, once as a CSV file and once an RDS file: # use Sys.getenv(&quot;TEMP&quot;) to get the system temp dir to save the CSV and RDS files tmpdir &lt;- Sys.getenv(&quot;TEMP&quot;) write.csv(x = AHwave1_v1_haven, file = file.path(tmpdir, &quot;AHwave1_v1_haven.csv&quot;), row.names = FALSE) saveRDS(object = AHwave1_v1_haven, file = file.path(tmpdir, &quot;AHwave1_v1_haven.RDS&quot;)) Then we will read them back in and investigate their structure. First, the CSV format: AHwave1_v1_haven_csv &lt;- read.csv(file = file.path(tmpdir, &quot;AHwave1_v1_haven.csv&quot;)) What kind of object is this? is(AHwave1_v1_haven_csv) ## [1] &quot;data.frame&quot; &quot;list&quot; &quot;oldClass&quot; &quot;vector&quot; It is a simple data frame. What attributes does this data set have? Here we list the attributes and enumerate the first 6 elements of each attribute AHwave1_v1_haven_csv %&gt;% attributes() %&gt;% map(~ head(.)) ## $names ## [1] &quot;aid&quot; &quot;imonth&quot; &quot;iday&quot; &quot;iyear&quot; &quot;bio_sex&quot; &quot;h1gi1m&quot; ## ## $class ## [1] &quot;data.frame&quot; ## ## $row.names ## [1] 1 2 3 4 5 6 There are three attributes, names, which are the individual column names; class, indicating this is a data frame, and row.names, in this case a serial number 1 .. n. Do the columns have any attributes? AHwave1_v1_haven_csv$h1gi1m %&gt;% attributes() ## NULL No, the columns have no attributes. Now we will read in the RDS file: AHwave1_v1_haven_rds &lt;- readRDS(file = file.path(tmpdir, &quot;AHwave1_v1_haven.RDS&quot;)) What kind of object is this? is(AHwave1_v1_haven_rds) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; &quot;list&quot; &quot;oldClass&quot; &quot;vector&quot; It is a data frame--but an example of the tidyr subclass tibble; see the documentation What attributes does this data set have? AHwave1_v1_haven_rds %&gt;% attributes() %&gt;% map(~ head(.)) ## $label ## [1] &quot;National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-200&quot; ## ## $names ## [1] &quot;aid&quot; &quot;imonth&quot; &quot;iday&quot; &quot;iyear&quot; &quot;bio_sex&quot; &quot;h1gi1m&quot; ## ## $row.names ## [1] 1 2 3 4 5 6 ## ## $class ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; The overall attributes are similar to the basic data frame, but there is an overall data set label, National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-200 (sic). We can also look at the attributes of specific columns: AHwave1_v1_haven_rds$h1gi1m %&gt;% attributes() ## $label ## [1] &quot;S1Q1 BIRTH MONTH-W1&quot; ## ## $format.stata ## [1] &quot;%13.0f&quot; ## ## $class ## [1] &quot;haven_labelled&quot; &quot;vctrs_vctr&quot; &quot;double&quot; ## ## $labels ## (1) January (2) February (3) March (4) April (5) May (6) June (7) July (8) August ## 1 2 3 4 5 6 7 8 ## (9) September (10) October (11) November (12) December (96) Refused ## 9 10 11 12 96 Here we see that all of the original column attributes were preserved when the data set was saved in RDS format. Importantly, saving a data set in CSV format loses any built-in metadata, whereas saving in RDS format maintains the built-in metadata. For other plain text formats, metadata will not be maintained; for other formats, it is worth determining whether such metadata are maintained. If metadata are not maintained in the file structure of the data set, it will be important to maintain the metadata in an external format (e.g., text, PDF). 7.1.1 Creating factor variables Factor variables are used in R to store categorical variables. These categorical variables can be nominal, in which each value is distinct and not ordered, such as race, classified as White Black/African American American Indian Asian/Pacific Islander other Factor variables can be ordered, where there is a difference in amount or intensity, such as self-reported health status: Excellent Very good Good Fair Poor Ordinal variables may or may not have equal intervals; for example, the &quot;distance&quot; between excellent and good health may not represent the same &quot;distance&quot; as the difference between good and fair health. Structurally, factor variables are stored as integers that can be linked to text labels. Operationally, the use of factor variables is important in statistical modeling, so that the variables are handled correctly as being categorical. Factor variables are created using the factor() or as_factor() functions. Here we will convert the self-reported general health variable (h1gh1) to a factor. First, let's look at the variable: AHwave1_v1_haven$h1gh1 %&gt;% attributes() ## $label ## [1] &quot;S3Q1 GENERAL HEALTH-W1&quot; ## ## $format.stata ## [1] &quot;%14.0f&quot; ## ## $class ## [1] &quot;haven_labelled&quot; &quot;vctrs_vctr&quot; &quot;double&quot; ## ## $labels ## (1) Excellent (2) Very good (3) Good (4) Fair (5) Poor (6) Refused (8) Don&#39;t know ## 1 2 3 4 5 6 8 This shows that there are values 1 through 6 and 8, with coding indicated in the labels attribute. Using head() also reveals the structure of the variable, including the label for the variable itself as well as the coding of the variable values: head(AHwave1_v1_haven$h1gh1) ## &lt;labelled&lt;double&gt;[6]&gt;: S3Q1 GENERAL HEALTH-W1 ## [1] 3 4 4 4 3 3 ## ## Labels: ## value label ## 1 (1) Excellent ## 2 (2) Very good ## 3 (3) Good ## 4 (4) Fair ## 5 (5) Poor ## 6 (6) Refused ## 8 (8) Don&#39;t know Here we convert the variable to a factor: AHwave1_v1_haven$health &lt;- factor(AHwave1_v1_haven$h1gh1) What is the result? We can see from the first few values; head() presents the values as well as the levels. # look at the first few values of the factor variable head(AHwave1_v1_haven$health) ## [1] 3 4 4 4 3 3 ## Levels: 1 2 3 4 5 6 8 Although the levels are in numerical order, there are no meaningful labels. We use the labels = argument to assign labels to each level. Simultaneously, because the factor is ordered in the same order as the alphanumeric ordering of the attributes, we can set the ordering based on those attributes. Finally, we reverse the order of the levels so that better health has a higher position in the order. # extract the labels from the column attribute health_levels &lt;- AHwave1_v1_haven$h1gh1 %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% names() # create the factor variable AHwave1_v1_haven$health &lt;- factor(AHwave1_v1_haven$h1gh1, labels = health_levels, ordered = TRUE) %&gt;% fct_relevel(rev) [Note that if the ordering is not alphanumeric, one should enter the list of values as ... labels = c(&quot;label1&quot;, &quot;label2, ..., &quot;labeln&quot;), ordered = TRUE ... to enforce correct ordering.] Let's compare the two variables through simple tabulation. Here is the &quot;raw&quot; variable: # &quot;raw&quot; variable (tab_h1gh1 &lt;- AHwave1_v1_haven %&gt;% group_by(h1gh1) %&gt;% summarise(n = n())) ## # A tibble: 7 x 2 ## h1gh1 n ## &lt;dbl+lbl&gt; &lt;int&gt; ## 1 1 [(1) Excellent] 1847 ## 2 2 [(2) Very good] 2608 ## 3 3 [(3) Good] 1605 ## 4 4 [(4) Fair] 408 ## 5 5 [(5) Poor] 28 ## 6 6 [(6) Refused] 3 ## 7 8 [(8) Don&#39;t know] 5 The &quot;raw&quot; variable shows that it is a labeled, double precision variable (&lt;dbl+lbl&gt;). Now the factor variable: # factor variable (tab_health &lt;- AHwave1_v1_haven %&gt;% group_by(health) %&gt;% summarise(n = n())) ## # A tibble: 7 x 2 ## health n ## &lt;ord&gt; &lt;int&gt; ## 1 (8) Don&#39;t know 5 ## 2 (6) Refused 3 ## 3 (5) Poor 28 ## 4 (4) Fair 408 ## 5 (3) Good 1605 ## 6 (2) Very good 2608 ## 7 (1) Excellent 1847 The counts are the same, but for the factor variable, the &lt;ord&gt; additionally indicates the ordering of health levels. Note that the order is different because (1) Excellent should have the highest numerical value. Bar plots also show the difference between the raw and factor variables. Here is a bar plot from the raw variable. ggplot(data = tab_h1gh1, aes(x = h1gh1, y = n)) + geom_bar(stat = &quot;identity&quot;) + coord_flip() Because the numerical values have no special meaning, the bar plot uses its default method of displaying the axes. Here is the bar plot created with the factor variable, which shows informative labels at the correct position on the axes. ggplot(data = tab_health, mapping = aes(x = health, y = n)) + geom_bar(stat = &quot;identity&quot;) + coord_flip() One of the potential down sides to using factor variables is that using the text values requires additional code. For example, to select (filter()) a subset of records, there are two methods. The first method uses the label. In this case because the factor is ordered, it is possible to use an ordinal comparison. # filter for Excellent or Very good y &lt;- AHwave1_v1_haven %&gt;% filter (health &lt;= &quot;(2) Very good&quot;) # tabulate table(y$health) ## ## (8) Don&#39;t know (6) Refused (5) Poor (4) Fair (3) Good (2) Very good (1) Excellent ## 5 3 28 408 1605 2608 0 The other method is to use as_numeric() to specify the underlying numerical values. In this case, because the value of 2 indicated Very good, we can filter for health %&gt;% as.numeric() &lt;= 2. x &lt;- AHwave1_v1_haven %&gt;% filter(health %&gt;% as.numeric() &lt;= 2) Using unordered factor variables shows that more coding is involved in specifying values in filter() statements. For example, let's create a factor variable for the interviewer's observed single race variable: # number of labels nlabs &lt;- length(unique(AHwave1_v1_haven$h1gi9)) # get the values, &quot;as.numeric()&quot; obsrace_values &lt;- AHwave1_v1_haven$h1gi9 %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% as.numeric() # get the labels, names() obsrace_labels &lt;- AHwave1_v1_haven$h1gi9 %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% names() # create the factor AHwave1_v1_haven$obsrace &lt;- factor(AHwave1_v1_haven$h1gi9, levels = obsrace_values, labels = obsrace_labels) Suppose we wanted to make a subset of only White and Black records, there are a few syntax methods: Here, each value is explicitly named, using the | &quot;or&quot; operator dat_wb1 &lt;- AHwave1_v1_haven %&gt;% filter(obsrace == &quot;(1) White&quot; | obsrace == &quot;(2) Black/African American&quot;) table(dat_wb1$obsrace) ## ## (1) White (2) Black/African American (3) American Indian/Native American ## 4291 1601 0 ## (4) Asian/Pacific Islander (5) Other (6) Refused ## 0 0 0 ## (8) Don&#39;t know (9) Not applicable ## 0 0 A different approach uses str_detect() with a regular expression to match any values of obsrace that contain the strings white or black in any upper/lower case combination. dat_wb2 &lt;- AHwave1_v1_haven %&gt;% filter(str_detect(obsrace, regex(&quot;white|black&quot;, ignore_case = TRUE))) table(dat_wb2$obsrace) ## ## (1) White (2) Black/African American (3) American Indian/Native American ## 4291 1601 0 ## (4) Asian/Pacific Islander (5) Other (6) Refused ## 0 0 0 ## (8) Don&#39;t know (9) Not applicable ## 0 0 Finally, if we know the numeric values representing the factors, we can use those directly: dat_wb3 &lt;- AHwave1_v1_haven %&gt;% filter(obsrace %&gt;% as.numeric() %in% c(1, 2)) table(dat_wb3$obsrace) ## ## (1) White (2) Black/African American (3) American Indian/Native American ## 4291 1601 0 ## (4) Asian/Pacific Islander (5) Other (6) Refused ## 0 0 0 ## (8) Don&#39;t know (9) Not applicable ## 0 0 The first method is the most verbose, requires the most code, and is probably the easiest to read. The other two methods may be easier to code (i.e., fewer keystrokes), but seem to be more difficult to interpret. As above, care needs to be taken in saving the data set to a file. If the factor has text labels, those will be written to an output CSV file. When they are read back in, they will be treated as character values rather than factors. For example, the health variable we created is an ordered factor: head(AHwave1_v1_haven$health) ## [1] (3) Good (4) Fair (4) Fair (4) Fair (3) Good (3) Good ## Levels: (8) Don&#39;t know &lt; (6) Refused &lt; (5) Poor &lt; (4) Fair &lt; (3) Good &lt; (2) Very good &lt; (1) Excellent But when cycled through a write/read CSV cycle, the variable is not maintained as a factor. write.csv(x = AHwave1_v1_haven, file = file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.csv&quot;), row.names = FALSE) y &lt;- read.csv(file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.csv&quot;)) head(y$health) ## [1] &quot;(3) Good&quot; &quot;(4) Fair&quot; &quot;(4) Fair&quot; &quot;(4) Fair&quot; &quot;(3) Good&quot; &quot;(3) Good&quot; Additional work would be needed to re-establish it as a factor. Fortunately, the alphanumeric sorting order of the character strings is the logical order; without the numeric values, the ordering would need to be explicitly set. For example, the vector in desired sorting order &quot;Excellent&quot;, &quot;Very good&quot;, &quot;Good&quot;, &quot;Fair&quot;, &quot;Poor&quot;, &quot;Refused&quot;, &quot;Don't know&quot; sorts as Don't know, Excellent, Fair, Good, Poor, Refused, Very good), which is not the proper sorting order. y$health &lt;- factor(y$health, labels = y$health %&gt;% unique() %&gt;% sort(), ordered = TRUE) head(y$health) ## [1] (3) Good (4) Fair (4) Fair (4) Fair (3) Good (3) Good ## Levels: (1) Excellent &lt; (2) Very good &lt; (3) Good &lt; (4) Fair &lt; (5) Poor &lt; (6) Refused &lt; (8) Don&#39;t know If you save the data set as RDS, the factor and other structures are maintained. write_rds(x = AHwave1_v1_haven, file = file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.Rds&quot;)) z &lt;- readRDS(file = file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.Rds&quot;)) head(z$health) ## [1] (3) Good (4) Fair (4) Fair (4) Fair (3) Good (3) Good ## Levels: (8) Don&#39;t know &lt; (6) Refused &lt; (5) Poor &lt; (4) Fair &lt; (3) Good &lt; (2) Very good &lt; (1) Excellent 7.1.2 Creating attributes In addition to creating factors, which can serve in some capacity as self-documenting (i.e., the value labels should be at least somewhat self-explanatory), we can create attributes as we have seen with the Stata .dta files. Let's start with the CSV file, which we know was stripped of its descriptive attributes: y &lt;- read.csv(file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.csv&quot;)) y %&gt;% attributes() %&gt;% map(~ head(.)) ## $names ## [1] &quot;aid&quot; &quot;imonth&quot; &quot;iday&quot; &quot;iyear&quot; &quot;bio_sex&quot; &quot;h1gi1m&quot; ## ## $class ## [1] &quot;data.frame&quot; ## ## $row.names ## [1] 1 2 3 4 5 6 First, an attribute of the data frame itself: attributes(y)$label &lt;- &quot;National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions&quot; ... which we can verify: y %&gt;% attributes() %&gt;% extract(&quot;label&quot;) ## $label ## [1] &quot;National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions&quot; Next, attributes for the health and obsrace variables, documenting the variables and values: # label for health attributes(y$health)$label &lt;- &quot;General health from public Add Health Wave 1 Section 3 question 1&quot; # values for health attributes(y$health)$levels &lt;- c(&quot;(1) Excellent&quot;, &quot;(2) Very good&quot;, &quot;(3) Good&quot;, &quot;(4) Fair&quot;, &quot;(5) Poor&quot;, &quot;(6) Refused&quot;, &quot;(8) Don&#39;t know&quot;) # label for obsrace attributes(y$obsrace)$label &lt;- &quot;Interviewer observation of race from public Add Health Wave 1 Section 1 question 9&quot; # values for obsrace attributes(y$obsrace)$levels &lt;- c(&quot;(1) White&quot;, &quot;(2) Black/African American&quot;, &quot;(3) American Indian/Native American&quot;, &quot;(4) Asian/Pacific Islander&quot;, &quot;(5) Other&quot;, &quot;(6) Refused&quot;, &quot;(8) Don&#39;t know&quot;, &quot;(9) Not applicable&quot;) Verify these were created: y$health %&gt;% attributes() ## $label ## [1] &quot;General health from public Add Health Wave 1 Section 3 question 1&quot; ## ## $levels ## [1] &quot;(1) Excellent&quot; &quot;(2) Very good&quot; &quot;(3) Good&quot; &quot;(4) Fair&quot; &quot;(5) Poor&quot; &quot;(6) Refused&quot; ## [7] &quot;(8) Don&#39;t know&quot; y$obsrace %&gt;% attributes() ## $label ## [1] &quot;Interviewer observation of race from public Add Health Wave 1 Section 1 question 9&quot; ## ## $levels ## [1] &quot;(1) White&quot; &quot;(2) Black/African American&quot; ## [3] &quot;(3) American Indian/Native American&quot; &quot;(4) Asian/Pacific Islander&quot; ## [5] &quot;(5) Other&quot; &quot;(6) Refused&quot; ## [7] &quot;(8) Don&#39;t know&quot; &quot;(9) Not applicable&quot; The same caveats apply to saving the data frame to files. 7.2 Tabulation We have seen a few examples of tabulation in previous exercises (Sections 2.4.2.5, 3.2, 4.2.1.2.1). This section will give a more complete treatment using the Add Health data as an example. 7.2.1 Raw counts The most basic tabulations simply give the count of observations in different strata. Those strata can be based on numeric ratio or interval data, using functions such as cut() or BAMMtools::getJenksBreaks(), nominal data (such as the Add Health interviewer's observation of respondents' single race), or ordinal data (such as the self-reported health status). We will use examples of each type of data. First, this code will load the full Add Health data set, which includes additional variables not present in the data set we have used previously. # download and unzip the larger data set myUrl &lt;- &quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip&quot; # zipfile in $temp zipfile &lt;- file.path(Sys.getenv(&quot;TEMP&quot;), basename(myUrl)) # dta file in $temp dtafile &lt;- tools::file_path_sans_ext(zipfile) # check if the dta file exists if(!file.exists(dtafile)){ # if the dta file doesn&#39;t exist, check for the zip file # check if the zip file exists, download if necessary if(!file.exists(zipfile)){ curl::curl_download(url = myUrl, destfile = zipfile) } # unzip the downloaded zip file unzip(zipfile = zipfile, exdir = Sys.getenv(&quot;TEMP&quot;)) } # if the data set has not been read, read it in if(!exists(&quot;ahcomplete&quot;)){ ahcomplete &lt;- haven::read_dta(dtafile) } # lowercase column names colnames(ahcomplete) %&lt;&gt;% str_to_lower() Present the metadata (variable names and labels): ahcomplete_metadata &lt;- bind_cols( varname = colnames(ahcomplete), varlabel = ahcomplete %&gt;% map(~ attributes(.)$label) %&gt;% unlist() ) DT::datatable(ahcomplete_metadata) Let's look at body mass index (BMI) data, which uses weight and height values. We find the variables representing weight and height from the metadata above. We need to determine if there are any invalid values: attributes(ahcomplete$h1gh59a)$labels ## (4) 4 feet (5) 5 feet (6) 6 feet (96) Refused (98) Don&#39;t know ## 4 5 6 96 98 attributes(ahcomplete$h1gh59b)$labels ## (0) 0 inches (1) 1 inch (2) 2 inches (3) 3 inches (4) 4 inches ## 0 1 2 3 4 ## (5) 5 inches (6) 6 inches (7) 7 inches (8) 8 inches (9) 9 inches ## 5 6 7 8 9 ## (10) 10 inches (11) 11 inches (96) Refused (98) Don&#39;t know (99) Not applicable ## 10 11 96 98 99 attributes(ahcomplete$h1gh60)$labels ## (996) Refused (998) Don&#39;t know (999) Not applicable ## 996 998 999 First, we need to select the variables representing feet and inches, then filter out invalid heights (&gt; 90) and weights (&gt; 900) identified above, and finally calculate height in m, weight in kg, and BMI (\\(\\frac{weight\\_{kg}}{{height\\_m}^2}\\)). For future use we will also select self-reported health and interviewer observed race as factors. # make the data frmae htwt &lt;- ahcomplete %&gt;% # select columns select(feet = h1gh59a, inches = h1gh59b, weight_lb = h1gh60, health = h1gh1, obsrace = h1gi9) %&gt;% # filter for valid values filter(feet &lt; 90 &amp; inches &lt; 90 &amp; weight_lb &lt; 900) %&gt;% # calculate mutate(height_m = (feet * 12 + inches) / 39.37008, weight_kg = weight_lb / 2.205, BMI = weight_kg / height_m^2) # factor: get values and labels healthvals &lt;- htwt$health %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% as.numeric() healthlabs &lt;- htwt$health %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% names() racevals &lt;- htwt$obsrace %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% as.numeric() racelabs &lt;- htwt$obsrace %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% names() htwt %&lt;&gt;% mutate(health = factor(health, levels = healthvals, labels = healthlabs), obsrace = factor(obsrace, levels = racevals, labels = racelabs)) A histogram shows the distribution of BMI for the respondents with vertical lines at the 5th and 85th percentile. This range is generally considered &quot;normal&quot; or &quot;healthy&quot; according to the CDC, although for a sample with varying age, sex, height, and weight ranges, it is difficult to interpret. Nevertheless the cut points can serve the purpose of demonstration. # get the 5th &amp; 85th percentile bmibreaks &lt;- quantile(x = htwt$BMI, probs = c(0.05, 0.85)) ggplot(htwt, aes(x = BMI)) + geom_histogram(bins = 30) + geom_vline(xintercept = bmibreaks) We assign the BMI class using these cut points, with cut() breaks at the minimum, 5%, 85%, and maximum BMI, and also assign labels and set ordering: htwt %&lt;&gt;% mutate(bmiclass = cut(x = BMI, breaks = c(min(BMI), bmibreaks, max(BMI)), labels = c(&quot;underweight&quot;, &quot;normal&quot;, &quot;overweight&quot;), include.lowest = TRUE) %&gt;% factor(ordered = TRUE)) The tabulation of count of respondents by weight class can be generated with the base R function table() or dplyr functions group_by() and summarise(). # base R table(htwt$bmiclass, useNA = &quot;ifany&quot;) ## ## underweight normal overweight ## 324 5023 944 # tidyR htwt %&gt;% group_by(bmiclass) %&gt;% summarise(n = n()) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) bmiclass n underweight 324 normal 5023 overweight 944 For variables that are already nominal or ordinal factors, tabulations can be made directly. Because these were converted to factors, the correct labels will show, rather than simple numeric values. htwt %&gt;% group_by(health) %&gt;% summarise(n = n()) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) health n Excellent 1803 Very good 2541 Good 1531 Fair 389 Poor 26 Don't know 1 htwt %&gt;% group_by(obsrace) %&gt;% summarise(n = n()) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) obsrace n White 4184 Black/African American 1525 American Indian/Native American 68 Asian/Pacific Islander 230 Other 280 Refused 1 Don't know 3 7.2.2 Proportions/percentages Proportions and percentages can be added to tabulations for greater interpretability. Using base R, the prop_table() function can be used as a wrapper around table() to generate proportions, optionally multiplying by 100 to generate a percentage. Remember to round as needed. For example: round(prop.table(table(htwt$bmiclass)), 2) ## ## underweight normal overweight ## 0.05 0.80 0.15 round(prop.table(table(htwt$bmiclass)) * 100, 0) ## ## underweight normal overweight ## 5 80 15 Not surprisingly, the BMI classes show 5% underweight and 15% overweight, because that is how the stratification was defined. The tidyR version requires a bit more coding but provides a more readable output. Because the percent sign is a special character, we enclose it in back ticks, %. Here we generate a tabulation of observed race. htwt %&gt;% group_by(obsrace) %&gt;% summarise(n = n()) %&gt;% mutate(`%` = n / sum(n) * 100) %&gt;% mutate(`%` = `%` %&gt;% round(1)) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) obsrace n % White 4184 66.5 Black/African American 1525 24.2 American Indian/Native American 68 1.1 Asian/Pacific Islander 230 3.7 Other 280 4.5 Refused 1 0.0 Don't know 3 0.0 7.2.3 Stratified tabulation Tabulations can be generated using multiple variables. Here we will examine BMI and race as well as BMI and health. The percentages sum to 100 based on the order of the grouping. Here, we see the relative percent of underweight, normal, and overweight within each race class: htwt %&gt;% group_by(obsrace, bmiclass) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(`%` = n / sum(n) * 100) %&gt;% mutate(`%` = `%` %&gt;% round(1)) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) obsrace bmiclass n % White underweight 234 5.6 White normal 3389 81.0 White overweight 561 13.4 Black/African American underweight 52 3.4 Black/African American normal 1188 77.9 Black/African American overweight 285 18.7 American Indian/Native American underweight 2 2.9 American Indian/Native American normal 39 57.4 American Indian/Native American overweight 27 39.7 Asian/Pacific Islander underweight 20 8.7 Asian/Pacific Islander normal 187 81.3 Asian/Pacific Islander overweight 23 10.0 Other underweight 16 5.7 Other normal 216 77.1 Other overweight 48 17.1 Refused normal 1 100.0 Don't know normal 3 100.0 And here we see the relative percent of different race groups within each BMI class. htwt %&gt;% group_by(bmiclass, obsrace) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(`%` = n / sum(n) * 100) %&gt;% mutate(`%` = `%` %&gt;% round(1)) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) bmiclass obsrace n % underweight White 234 72.2 underweight Black/African American 52 16.0 underweight American Indian/Native American 2 0.6 underweight Asian/Pacific Islander 20 6.2 underweight Other 16 4.9 normal White 3389 67.5 normal Black/African American 1188 23.7 normal American Indian/Native American 39 0.8 normal Asian/Pacific Islander 187 3.7 normal Other 216 4.3 normal Refused 1 0.0 normal Don't know 3 0.1 overweight White 561 59.4 overweight Black/African American 285 30.2 overweight American Indian/Native American 27 2.9 overweight Asian/Pacific Islander 23 2.4 overweight Other 48 5.1 Even though the n values are the same in the two tables (e.g., underweight White n = 234), the percentages are different due to grouping. That is, the percent of underweight persons among the White race stratum is different from the percent of White persons within the underweight stratum. Proper grouping is critical to answer specific questions about the data. Another way to understand the data, preferred by some, would be to make a graph. For example, BMI by race: bmi_race &lt;- htwt %&gt;% group_by(obsrace, bmiclass) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(`%` = n / sum(n) * 100) %&gt;% filter(!str_detect(obsrace, regex(&quot;refused|know&quot;, ignore_case = TRUE))) ggplot(data = bmi_race, mapping = aes(x = bmiclass, y = `%`)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + facet_grid(~obsrace) ggplot(data = bmi_race, mapping = aes(x = obsrace, y = `%`, fill = bmiclass)) + geom_bar(stat = &quot;identity&quot;) + coord_flip() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 7.3 Source code 07-week07.Rmd cat(readLines(con = &quot;07-week07.Rmd&quot;), sep = &#39;\\n&#39;) # Week 7 {#week7} ```{r, echo=FALSE, warning=FALSE, message=FALSE} library(tidyverse) library(magrittr) library(knitr) library(kableExtra) library(readstata13) library(haven) library(pdftools) library(curl) library(ggplot2) ``` &lt;h2&gt;Topic: Add Health data: variable creation and tabulation&lt;/h2&gt; This week&#39;s lesson will provide more background on variable creation and tabulation of variables. ## Creating value labels &quot;Labeled&quot; data are important for documentation of data sets. The labels can apply to different objects, e.g., columns (as we saw in the column labels used to &quot;decode&quot; the data set in `AHwave1_v1.dta`, Section \\@ref(tidyverse)), or to individual values of variables, e.g., the attribute `labels` of the variable `h1gi1m`: ```{r} AHwave1_v1_haven &lt;- haven::read_dta(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta&quot;) attributes(AHwave1_v1_haven$h1gi1m)$labels ``` Consider the difference between different file formats. Here we will save the data set, once as a CSV file and once an RDS file: ```{r} # use Sys.getenv(&quot;TEMP&quot;) to get the system temp dir to save the CSV and RDS files tmpdir &lt;- Sys.getenv(&quot;TEMP&quot;) write.csv(x = AHwave1_v1_haven, file = file.path(tmpdir, &quot;AHwave1_v1_haven.csv&quot;), row.names = FALSE) saveRDS(object = AHwave1_v1_haven, file = file.path(tmpdir, &quot;AHwave1_v1_haven.RDS&quot;)) ``` Then we will read them back in and investigate their structure. First, the CSV format: ```{r} AHwave1_v1_haven_csv &lt;- read.csv(file = file.path(tmpdir, &quot;AHwave1_v1_haven.csv&quot;)) ``` What kind of object is this? ```{r} is(AHwave1_v1_haven_csv) ``` It is a simple data frame. What attributes does this data set have? Here we list the attributes and enumerate the first 6 elements of each attribute ```{r} AHwave1_v1_haven_csv %&gt;% attributes() %&gt;% map(~ head(.)) ``` There are three attributes, `names`, which are the individual column names; `class`, indicating this is a data frame, and `row.names`, in this case a serial number 1 .. n. Do the columns have any attributes? ```{r} AHwave1_v1_haven_csv$h1gi1m %&gt;% attributes() ``` No, the columns have no attributes. Now we will read in the RDS file: ```{r} AHwave1_v1_haven_rds &lt;- readRDS(file = file.path(tmpdir, &quot;AHwave1_v1_haven.RDS&quot;)) ``` What kind of object is this? ```{r} is(AHwave1_v1_haven_rds) ``` It is a data frame--but an example of the `tidyr` subclass `tibble`; see the [documentation](https://www.rdocumentation.org/packages/tibble) What attributes does this data set have? ```{r} AHwave1_v1_haven_rds %&gt;% attributes() %&gt;% map(~ head(.)) ``` The overall attributes are similar to the basic data frame, but there is an overall data set label, ``r AHwave1_v1_haven_rds %&gt;% attributes() %&gt;% extract(&quot;label&quot;)`` (_sic_). We can also look at the attributes of specific columns: ```{r} AHwave1_v1_haven_rds$h1gi1m %&gt;% attributes() ``` Here we see that all of the original column attributes were preserved when the data set was saved in RDS format. __Importantly__, saving a data set in CSV format loses any built-in metadata, whereas saving in RDS format maintains the built-in metadata. For other plain text formats, metadata will not be maintained; for other formats, it is worth determining whether such metadata are maintained. If metadata are not maintained in the file structure of the data set, it will be important to maintain the metadata in an external format (e.g., text, PDF). ### Creating factor variables Factor variables are used in R to store categorical variables. These categorical variables can be nominal, in which each value is distinct and not ordered, such as race, classified as * White * Black/African American * American Indian * Asian/Pacific Islander * other Factor variables can be ordered, where there is a difference in amount or intensity, such as self-reported health status: 1. Excellent 1. Very good 1. Good 1. Fair 1. Poor Ordinal variables may or may not have equal intervals; for example, the &quot;distance&quot; between excellent and good health may not represent the same &quot;distance&quot; as the difference between good and fair health. Structurally, factor variables are stored as integers that can be linked to text labels. Operationally, __the use of factor variables is important in statistical modeling, so that the variables are handled correctly as being categorical__. Factor variables are created using the `factor()` or `as_factor()` functions. Here we will convert the self-reported general health variable (`h1gh1`) to a factor. First, let&#39;s look at the variable: ```{r} AHwave1_v1_haven$h1gh1 %&gt;% attributes() ``` This shows that there are values 1 through 6 and 8, with coding indicated in the `labels` attribute. Using `head()` also reveals the structure of the variable, including the label for the variable itself as well as the coding of the variable values: ```{r} head(AHwave1_v1_haven$h1gh1) ``` Here we convert the variable to a factor: ```{r} AHwave1_v1_haven$health &lt;- factor(AHwave1_v1_haven$h1gh1) ``` What is the result? We can see from the first few values; `head()` presents the values as well as the levels. ```{r} # look at the first few values of the factor variable head(AHwave1_v1_haven$health) ``` Although the levels are in numerical order, there are no meaningful labels. We use the `labels = ` argument to assign labels to each level. Simultaneously, because the factor is ordered in the same order as the alphanumeric ordering of the attributes, we can set the ordering based on those attributes. Finally, we reverse the order of the levels so that better health has a higher position in the order. ```{r} # extract the labels from the column attribute health_levels &lt;- AHwave1_v1_haven$h1gh1 %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% names() # create the factor variable AHwave1_v1_haven$health &lt;- factor(AHwave1_v1_haven$h1gh1, labels = health_levels, ordered = TRUE) %&gt;% fct_relevel(rev) ``` _[Note that if the ordering is not alphanumeric, one should enter the list of values as `... labels = c(&quot;label1&quot;, &quot;label2, ..., &quot;labeln&quot;), ordered = TRUE ...` to enforce correct ordering.]_ Let&#39;s compare the two variables through simple tabulation. Here is the &quot;raw&quot; variable: ```{r} # &quot;raw&quot; variable (tab_h1gh1 &lt;- AHwave1_v1_haven %&gt;% group_by(h1gh1) %&gt;% summarise(n = n())) ``` The &quot;raw&quot; variable shows that it is a labeled, double precision variable (`&lt;dbl+lbl&gt;`). Now the factor variable: ```{r} # factor variable (tab_health &lt;- AHwave1_v1_haven %&gt;% group_by(health) %&gt;% summarise(n = n())) ``` The counts are the same, but for the factor variable, the `&lt;ord&gt;` additionally indicates the ordering of health levels. Note that the order is different because `(1) Excellent` should have the highest numerical value. Bar plots also show the difference between the raw and factor variables. Here is a bar plot from the raw variable. ```{r, warning=FALSE, message=FALSE} ggplot(data = tab_h1gh1, aes(x = h1gh1, y = n)) + geom_bar(stat = &quot;identity&quot;) + coord_flip() ``` Because the numerical values have no special meaning, the bar plot uses its default method of displaying the axes. Here is the bar plot created with the factor variable, which shows informative labels at the correct position on the axes. ```{r} ggplot(data = tab_health, mapping = aes(x = health, y = n)) + geom_bar(stat = &quot;identity&quot;) + coord_flip() ``` One of the potential down sides to using factor variables is that using the text values requires additional code. For example, to select (`filter()`) a subset of records, there are two methods. The first method uses the label. In this case because the factor is ordered, it is possible to use an ordinal comparison. ```{r} # filter for Excellent or Very good y &lt;- AHwave1_v1_haven %&gt;% filter (health &lt;= &quot;(2) Very good&quot;) # tabulate table(y$health) ``` The other method is to use `as_numeric()` to specify the underlying numerical values. In this case, because the value of 2 indicated `Very good`, we can filter for `health %&gt;% as.numeric() &lt;= 2`. ```{r} x &lt;- AHwave1_v1_haven %&gt;% filter(health %&gt;% as.numeric() &lt;= 2) ``` Using unordered factor variables shows that more coding is involved in specifying values in `filter()` statements. For example, let&#39;s create a factor variable for the interviewer&#39;s observed single race variable: ```{r} # number of labels nlabs &lt;- length(unique(AHwave1_v1_haven$h1gi9)) # get the values, &quot;as.numeric()&quot; obsrace_values &lt;- AHwave1_v1_haven$h1gi9 %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% as.numeric() # get the labels, names() obsrace_labels &lt;- AHwave1_v1_haven$h1gi9 %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% names() # create the factor AHwave1_v1_haven$obsrace &lt;- factor(AHwave1_v1_haven$h1gi9, levels = obsrace_values, labels = obsrace_labels) ``` Suppose we wanted to make a subset of only White and Black records, there are a few syntax methods: Here, each value is explicitly named, using the `|` &quot;or&quot; operator ```{r} dat_wb1 &lt;- AHwave1_v1_haven %&gt;% filter(obsrace == &quot;(1) White&quot; | obsrace == &quot;(2) Black/African American&quot;) table(dat_wb1$obsrace) ``` A different approach uses `str_detect()` with a regular expression to match any values of `obsrace` that contain the strings `white` or `black` in any upper/lower case combination. ```{r} dat_wb2 &lt;- AHwave1_v1_haven %&gt;% filter(str_detect(obsrace, regex(&quot;white|black&quot;, ignore_case = TRUE))) table(dat_wb2$obsrace) ``` Finally, if we know the numeric values representing the factors, we can use those directly: ```{r} dat_wb3 &lt;- AHwave1_v1_haven %&gt;% filter(obsrace %&gt;% as.numeric() %in% c(1, 2)) table(dat_wb3$obsrace) ``` The first method is the most verbose, requires the most code, and is probably the easiest to read. The other two methods may be easier to code (i.e., fewer keystrokes), but seem to be more difficult to interpret. As above, care needs to be taken in saving the data set to a file. If the factor has text labels, those will be written to an output CSV file. When they are read back in, they will be treated as character values rather than factors. For example, the `health` variable we created is an ordered factor: ```{r} head(AHwave1_v1_haven$health) ``` But when cycled through a write/read CSV cycle, the variable is not maintained as a factor. ```{r} write.csv(x = AHwave1_v1_haven, file = file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.csv&quot;), row.names = FALSE) y &lt;- read.csv(file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.csv&quot;)) head(y$health) ``` Additional work would be needed to re-establish it as a factor. Fortunately, the alphanumeric sorting order of the character strings is the logical order; without the numeric values, the ordering would need to be explicitly set. For example, the vector in desired sorting order `&quot;Excellent&quot;, &quot;Very good&quot;, &quot;Good&quot;, &quot;Fair&quot;, &quot;Poor&quot;, &quot;Refused&quot;, &quot;Don&#39;t know&quot;` sorts as ``r c(&quot;Excellent&quot;, &quot;Very good&quot;, &quot;Good&quot;, &quot;Fair&quot;, &quot;Poor&quot;, &quot;Refused&quot;, &quot;Don&#39;t know&quot;) %&gt;% sort()``), which is not the proper sorting order. ```{r} y$health &lt;- factor(y$health, labels = y$health %&gt;% unique() %&gt;% sort(), ordered = TRUE) head(y$health) ``` If you save the data set as RDS, the factor and other structures are maintained. ```{r} write_rds(x = AHwave1_v1_haven, file = file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.Rds&quot;)) z &lt;- readRDS(file = file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.Rds&quot;)) head(z$health) ``` ### Creating attributes In addition to creating factors, which can serve in some capacity as self-documenting (i.e., the value labels should be at least somewhat self-explanatory), we can create attributes as we have seen with the Stata `.dta` files. Let&#39;s start with the CSV file, which we know was stripped of its descriptive attributes: ```{r} y &lt;- read.csv(file.path(Sys.getenv(&quot;TEMP&quot;), &quot;foo.csv&quot;)) y %&gt;% attributes() %&gt;% map(~ head(.)) ``` First, an attribute of the data frame itself: ```{r} attributes(y)$label &lt;- &quot;National Longitudinal Study of Adolescent to Adult Health (Add Health), 1994-2000 with some variable additions&quot; ``` ... which we can verify: ```{r} y %&gt;% attributes() %&gt;% extract(&quot;label&quot;) ``` Next, attributes for the `health` and `obsrace` variables, documenting the variables and values: ```{r} # label for health attributes(y$health)$label &lt;- &quot;General health from public Add Health Wave 1 Section 3 question 1&quot; # values for health attributes(y$health)$levels &lt;- c(&quot;(1) Excellent&quot;, &quot;(2) Very good&quot;, &quot;(3) Good&quot;, &quot;(4) Fair&quot;, &quot;(5) Poor&quot;, &quot;(6) Refused&quot;, &quot;(8) Don&#39;t know&quot;) # label for obsrace attributes(y$obsrace)$label &lt;- &quot;Interviewer observation of race from public Add Health Wave 1 Section 1 question 9&quot; # values for obsrace attributes(y$obsrace)$levels &lt;- c(&quot;(1) White&quot;, &quot;(2) Black/African American&quot;, &quot;(3) American Indian/Native American&quot;, &quot;(4) Asian/Pacific Islander&quot;, &quot;(5) Other&quot;, &quot;(6) Refused&quot;, &quot;(8) Don&#39;t know&quot;, &quot;(9) Not applicable&quot;) ``` Verify these were created: ```{r} y$health %&gt;% attributes() y$obsrace %&gt;% attributes() ``` The same caveats apply to saving the data frame to files. ## Tabulation We have seen a few examples of tabulation in previous exercises (Sections \\@ref(summarizingaggregating-data), \\@ref(tables-in-r-markdown), \\@ref(default-values-for-arguments)). This section will give a more complete treatment using the Add Health data as an example. ### Raw counts The most basic tabulations simply give the count of observations in different strata. Those strata can be based on numeric ratio or interval data, using functions such as `cut()` or `BAMMtools::getJenksBreaks()`, nominal data (such as the Add Health interviewer&#39;s observation of respondents&#39; single race), or ordinal data (such as the self-reported health status). We will use examples of each type of data. First, this code will load the full Add Health data set, which includes additional variables not present in the data set we have used previously. ```{r} # download and unzip the larger data set myUrl &lt;- &quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip&quot; # zipfile in $temp zipfile &lt;- file.path(Sys.getenv(&quot;TEMP&quot;), basename(myUrl)) # dta file in $temp dtafile &lt;- tools::file_path_sans_ext(zipfile) # check if the dta file exists if(!file.exists(dtafile)){ # if the dta file doesn&#39;t exist, check for the zip file # check if the zip file exists, download if necessary if(!file.exists(zipfile)){ curl::curl_download(url = myUrl, destfile = zipfile) } # unzip the downloaded zip file unzip(zipfile = zipfile, exdir = Sys.getenv(&quot;TEMP&quot;)) } # if the data set has not been read, read it in if(!exists(&quot;ahcomplete&quot;)){ ahcomplete &lt;- haven::read_dta(dtafile) } # lowercase column names colnames(ahcomplete) %&lt;&gt;% str_to_lower() ``` Present the metadata (variable names and labels): ```{r} ahcomplete_metadata &lt;- bind_cols( varname = colnames(ahcomplete), varlabel = ahcomplete %&gt;% map(~ attributes(.)$label) %&gt;% unlist() ) DT::datatable(ahcomplete_metadata) ``` \\ Let&#39;s look at body mass index (BMI) data, which uses weight and height values. We find the variables representing weight and height from the metadata above. We need to determine if there are any invalid values: ```{r} attributes(ahcomplete$h1gh59a)$labels attributes(ahcomplete$h1gh59b)$labels attributes(ahcomplete$h1gh60)$labels ``` First, we need to select the variables representing feet and inches, then filter out invalid heights (&gt; 90) and weights (&gt; 900) identified above, and finally calculate height in m, weight in kg, and BMI ($\\frac{weight\\_{kg}}{{height\\_m}^2}$). For future use we will also select self-reported health and interviewer observed race as factors. ```{r} # make the data frmae htwt &lt;- ahcomplete %&gt;% # select columns select(feet = h1gh59a, inches = h1gh59b, weight_lb = h1gh60, health = h1gh1, obsrace = h1gi9) %&gt;% # filter for valid values filter(feet &lt; 90 &amp; inches &lt; 90 &amp; weight_lb &lt; 900) %&gt;% # calculate mutate(height_m = (feet * 12 + inches) / 39.37008, weight_kg = weight_lb / 2.205, BMI = weight_kg / height_m^2) # factor: get values and labels healthvals &lt;- htwt$health %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% as.numeric() healthlabs &lt;- htwt$health %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% names() racevals &lt;- htwt$obsrace %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% as.numeric() racelabs &lt;- htwt$obsrace %&gt;% attributes() %&gt;% extract2(&quot;labels&quot;) %&gt;% names() htwt %&lt;&gt;% mutate(health = factor(health, levels = healthvals, labels = healthlabs), obsrace = factor(obsrace, levels = racevals, labels = racelabs)) ``` A histogram shows the distribution of BMI for the respondents with vertical lines at the 5th and 85th percentile. This range is generally considered &quot;normal&quot; or &quot;healthy&quot; according to the CDC, although for a sample with varying age, sex, height, and weight ranges, it is difficult to interpret. Nevertheless the cut points can serve the purpose of demonstration. ```{r} # get the 5th &amp; 85th percentile bmibreaks &lt;- quantile(x = htwt$BMI, probs = c(0.05, 0.85)) ggplot(htwt, aes(x = BMI)) + geom_histogram(bins = 30) + geom_vline(xintercept = bmibreaks) ``` We assign the BMI class using these cut points, with `cut()` breaks at the minimum, 5%, 85%, and maximum BMI, and also assign labels and set ordering: ```{r} htwt %&lt;&gt;% mutate(bmiclass = cut(x = BMI, breaks = c(min(BMI), bmibreaks, max(BMI)), labels = c(&quot;underweight&quot;, &quot;normal&quot;, &quot;overweight&quot;), include.lowest = TRUE) %&gt;% factor(ordered = TRUE)) ``` The tabulation of count of respondents by weight class can be generated with the base R function `table()` or `dplyr` functions `group_by()` and `summarise()`. ```{r} # base R table(htwt$bmiclass, useNA = &quot;ifany&quot;) ``` ```{r} # tidyR htwt %&gt;% group_by(bmiclass) %&gt;% summarise(n = n()) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` For variables that are already nominal or ordinal factors, tabulations can be made directly. Because these were converted to factors, the correct labels will show, rather than simple numeric values. ```{r} htwt %&gt;% group_by(health) %&gt;% summarise(n = n()) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` ```{r} htwt %&gt;% group_by(obsrace) %&gt;% summarise(n = n()) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` ### Proportions/percentages Proportions and percentages can be added to tabulations for greater interpretability. Using base R, the `prop_table()` function can be used as a wrapper around `table()` to generate proportions, optionally multiplying by 100 to generate a percentage. Remember to round as needed. For example: ```{r} round(prop.table(table(htwt$bmiclass)), 2) round(prop.table(table(htwt$bmiclass)) * 100, 0) ``` Not surprisingly, the BMI classes show 5% underweight and 15% overweight, because that is how the stratification was defined. The `tidyR` version requires a bit more coding but provides a more readable output. Because the percent sign is a special character, we enclose it in back ticks, ``%``. Here we generate a tabulation of observed race. ```{r} htwt %&gt;% group_by(obsrace) %&gt;% summarise(n = n()) %&gt;% mutate(`%` = n / sum(n) * 100) %&gt;% mutate(`%` = `%` %&gt;% round(1)) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` ### Stratified tabulation Tabulations can be generated using multiple variables. Here we will examine BMI and race as well as BMI and health. The percentages sum to 100 based on the order of the grouping. Here, we see the relative percent of underweight, normal, and overweight within each race class: ```{r} htwt %&gt;% group_by(obsrace, bmiclass) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(`%` = n / sum(n) * 100) %&gt;% mutate(`%` = `%` %&gt;% round(1)) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` And here we see the relative percent of different race groups within each BMI class. ```{r} htwt %&gt;% group_by(bmiclass, obsrace) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(`%` = n / sum(n) * 100) %&gt;% mutate(`%` = `%` %&gt;% round(1)) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` Even though the `n` values are the same in the two tables (e.g., underweight White n = `r htwt %&gt;% filter(str_detect(obsrace, &quot;White&quot;) &amp; str_detect(bmiclass, &quot;under&quot;)) %&gt;% nrow()`), the percentages are different due to grouping. That is, the percent of underweight persons among the White race stratum is different from the percent of White persons within the underweight stratum. Proper grouping is critical to answer specific questions about the data. Another way to understand the data, preferred by some, would be to make a graph. For example, BMI by race: ```{r} bmi_race &lt;- htwt %&gt;% group_by(obsrace, bmiclass) %&gt;% summarise(n = n(), .groups = &quot;drop_last&quot;) %&gt;% mutate(`%` = n / sum(n) * 100) %&gt;% filter(!str_detect(obsrace, regex(&quot;refused|know&quot;, ignore_case = TRUE))) ggplot(data = bmi_race, mapping = aes(x = bmiclass, y = `%`)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + facet_grid(~obsrace) ggplot(data = bmi_race, mapping = aes(x = obsrace, y = `%`, fill = bmiclass)) + geom_bar(stat = &quot;identity&quot;) + coord_flip() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) ``` ## Source code [07-week07.Rmd](07-week07.Rmd) ```{r comment=&#39;&#39;} cat(readLines(con = &quot;07-week07.Rmd&quot;), sep = &#39;\\n&#39;) ``` "],["week8.html", "8 Week 8 8.1 Scale scoring 8.2 Reordering values 8.3 Source code", " 8 Week 8 Topic: Add Health data: variable creation and scale scoring This week's lesson will provide more background on variable creation and scale scoring. The scale scoring exercise will be used to create a single variable that represents how well respondents did overall on a subset of questions. 8.1 Scale scoring We will be using data from the Knowledge Quiz. Download or open 21600-0001-Codebook_Questionnaire.pdf in a new window or tab and go to page 203, or search for the string H1KQ1A. We will be using the file AHwave1_v1.dta, which is downloaded and read in the following code chunk, along with presentation of the column names, labels, and values. dat &lt;- haven::read_dta(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta&quot;) metadata &lt;- bind_cols( # variable name varname = colnames(dat), # label varlabel = lapply(dat, function(x) attributes(x)$label) %&gt;% unlist(), # values varvalues = lapply(dat, function(x) attributes(x)$labels) %&gt;% # names the variable label vector lapply(., function(x) names(x)) %&gt;% # as character as.character() %&gt;% # remove the c() construction str_remove_all(&quot;^c\\\\(|\\\\)$&quot;) ) DT::datatable(metadata) Questions H1KQ1A, H1KQ2A, ..., H1KQ10A are factual questions about contraception that are administered to participants \\(\\ge\\) age 15. We will be creating a single score that sums up all the correct answers across these questions for each participant \\(\\ge\\) age 15. Because the set of questions is paired, with question &quot;a&quot; being the factual portion and &quot;b&quot; being the level of confidence, we want only those questions with column names ending with &quot;a&quot;. 8.1.1 Selecting specific columns There are several ways of selecting the desired columns into a new data frame. Here is brute force approach: # create a data frame of some columns and age &gt;= 15 mydat_bruteforce &lt;- dat %&gt;% # drop those under 15 y filter(h1kq1a != 7) %&gt;% # get answers select( aid, # subject ID h1kq1a, h1kq2a, h1kq3a, h1kq4a, h1kq5a, h1kq6a, h1kq7a, h1kq8a, h1kq9a, h1kq10a ) Although there were only 10 columns with this name pattern, what if there had been 30 or 50? You would not want to have to enter each column name separately. Not only would this be tedious, there would always be the possibility of making a keyboarding mistake. Instead of the brute force approach, we can use the matches() function with a regular expression. The regular expression here is ^h1kq.*a$, which translates to &quot;at the start of the string, match h1kq, then any number of any characters, then a followed by the end of the string&quot;. mydat &lt;- dat %&gt;% filter(h1kq1a != 7) %&gt;% select( aid, matches(&quot;h1kq.*a&quot;) ) We check that both processes yielded the same result: identical(mydat_bruteforce, mydat) ## [1] TRUE 8.1.2 Comparing participant answers to correct answers Now that we have a data frame limited to the participants in the correct age range and only the questions we want, we need to set up tests for whether the questions were answered correctly or not. From the metadata we can see that for some questions, the correct answer was (1) true and for some, the correct answer was (2) false. We can scan through the questions in the metadata to create a vector of correct answers: # the correct answers correct &lt;- c(2, 1, 2, 2, 2, 2, 2, 1, 2, 2) # make a named vector of the answers using the selected column names names(correct) &lt;- str_subset(string = names(mydat), pattern = &quot;h1kq.*a&quot;) What we now need to do is compare this vector to a vector constructed of the answers in mydat. There are a few approaches that could be taken. A brute force approach could use a loop to iterate over each record in the answers, and for each record to iterate over each answer: # time this t0 &lt;- Sys.time() # make an output ans_loop &lt;- NULL # iterate over rows #testing: #for(i in 1:3){ for(i in 1:nrow(mydat)){ # init a vector Q &lt;- NULL # iterate over columns, ignoring the first &quot;aid&quot; column for(j in 2:ncol(mydat)){ # get the value of the answer ans_subj &lt;- mydat[i, j] # get the correct answer ans_actual &lt;- correct[j - 1] # compare cmp &lt;- ans_actual == ans_subj # append Q &lt;- c(Q, cmp) } # append ans_loop &lt;- rbind(ans_loop, Q) } # package it up nicely ans_loop %&lt;&gt;% data.frame() colnames(ans_loop) &lt;- names(correct) row.names(ans_loop) &lt;- NULL # timing t1 &lt;- Sys.time() runtime_loop &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(1) It took 44.2 s to run. This low performance is because the algorithm is visiting every cell and comparing one-by-on with a rotating value for the correct answer from the vector of correct answers. Each object is required to be handled separately in RAM as the process continues. Another approach uses plyr::adply(), which runs a function over a set of rows. The plyr package contains a set of tools for splitting data, applying functions, and recombining. # time this t0 &lt;- Sys.time() ans_adply &lt;- mydat %&gt;% select(-1) %&gt;% plyr::adply(.margins = 1, function(x) x == correct) t1 &lt;- Sys.time() runtime_adply &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(1) The adply() version takes far less coding, but still took 41 s to run. Yet another different approach compares the data frame of participant answers to the vector of correct answers. The correct answers vector will get recycled until all values have been processed. The problem with this method is that the comparison runs down columns rather than across rows. This demonstrates the problem. Table 8.1 shows a pattern of &quot;correct&quot; values, and Table 8.2 shows a table of responses # make a pattern to match against pat1 &lt;- c(1, 2, 3, 4) names(pat1) &lt;- paste(&quot;question&quot;, 1:4, sep=&quot;_&quot;) pat1 %&gt;% t() %&gt;% data.frame() %&gt;% kable(caption = &#39;A pattern of &quot;correct&quot; values&#39;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) Table 8.1: A pattern of &quot;correct&quot; values question_1 question_2 question_3 question_4 1 2 3 4 # make a data frame to process d1 &lt;- cbind(rep(1, 3), rep(2, 3), rep(3,3), rep(4, 3)) %&gt;% data.frame() names(d1) &lt;- names(pat1) d1 %&gt;% kable(caption = &quot;A table of responses&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) Table 8.2: A table of responses question_1 question_2 question_3 question_4 1 2 3 4 1 2 3 4 1 2 3 4 The pattern matches the first row of data (Table 8.3) (pat1 == d1[1,]) %&gt;% kable(caption = &quot;Matches for the first row&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) Table 8.3: Matches for the first row question_1 question_2 question_3 question_4 TRUE TRUE TRUE TRUE The patterns do not match the overall table as might be expected (??). (d1 == pat1) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) question_1 question_2 question_3 question_4 TRUE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE TRUE In order to match the pattern to each row, a transpose is required. The following code performs the transpose, pattern match, and re-transpose, with results in 8.4 # transpose, check for matching and transpose back (d1 %&gt;% t() == pat1) %&gt;% t() %&gt;% kable(caption = &quot;Expected pattern matches&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) Table 8.4: Expected pattern matches question_1 question_2 question_3 question_4 TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE So the trick is to use a transpose (t()) to swap rows and columns. Then unlist() will enforce the correct ordering. After running the comparison, the data are transposed again to recreate the original structure. # time this t0 &lt;- Sys.time() # transpose and compare ans_unlist &lt;- mydat %&gt;% select(-1) %&gt;% t(.) %&gt;% unlist(.) == correct # re-transpose and make a data frame ans_unlist %&lt;&gt;% t(.) %&gt;% data.frame() # column names colnames(ans_unlist) &lt;- names(correct) t1 &lt;- Sys.time() runtime_unlist &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(2) This method took 0.01 s to complete. Yet another method similarly uses the double transpose method. # time this t0 &lt;- Sys.time() # strip the ID column and transpose z &lt;- mydat %&gt;% select(-1) %&gt;% t() # compare, transpose, and make a data frame ans_tranpose &lt;- (z == correct) %&gt;% t(.) %&gt;% data.frame() t1 &lt;- Sys.time() runtime_transpose &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(2) This method took 0.01 s to complete. The final and most direct method uses base::sweep(), which can be used to compare a vector against all rows or columns in a data frame. In order to use this function, the data frame needs to have the same number of rows (or columns) as the comparison vector. So any additional rows or columns need to be stripped. Because we may have additional columns (e.g., aid), those must be removed before running sweep(), then added back in again. Additionally, the result of sweep() is a matrix, so it needs to be converted to a data frame for greater functionality. t0 &lt;- Sys.time() ans_sweep &lt;- mydat %&gt;% # drop the aid column select(-aid) %&gt;% # run the wweep sweep(x = ., MARGIN = 2, STATS = correct, FUN = &quot;==&quot;) %&gt;% # convert to data frame data.frame() t1 &lt;- Sys.time() runtime_sweep &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(3) The sweep() method took 0.019 s. We should check that the methods all gave identical answers. Vectorize(identical, &#39;x&#39;)(list(ans_loop, ans_adply, ans_tranpose, ans_unlist), ans_loop) ## [1] TRUE TRUE TRUE TRUE 8.1.3 Scoring across columns Now that we have a data frame indicating for each participant whether they answered each question correctly, we can total the number of correct answers for each participant. The rowSums() function allows sums across rows. Because the logical values are automatically converted to numerical values (TRUE = 1; FALSE = 0), the sums provide the total number of correct answers per participant. Also because the data frame only consists of answers 1 .. 10, we can use an unqualified rowSums(), otherwise it would be necessary to specify which columns would be included by either position or column name. We also bring the subject identifier (aid) back in and reorder the columns with select(). Note that after the specified aid and total h1kqNa_sum columns, we can use everything() to select the remainder of the columns. ans_loop %&lt;&gt;% # calculate the rowSums mutate(h1kqNa_sum = rowSums(.)) %&gt;% # bring the ID back in mutate(aid = mydat$aid) %&gt;% # reorder columns select(aid, h1kqNa_sum, everything()) To show differences in total score by sex, we can join the main data back using the aid identifier and create a simple graph. Figure 8.1 shows that more females than males had overall higher counts of correct scores on the Knowledge Quiz. ans_loop %&lt;&gt;% left_join(dat, by = &quot;aid&quot;) %&gt;% mutate( sex = case_when( bio_sex == 1 ~ &#39;male&#39;, bio_sex == 2 ~ &#39;female&#39; ) ) ggplot(data = ans_loop, mapping = aes(x = h1kqNa_sum))+ geom_histogram(stat = &quot;count&quot;) + facet_grid(sex ~ .) + xlab(&quot;correct answers on Knowledge Quiz&quot;) + scale_x_continuous(breaks=0:10) ## Warning: Ignoring unknown parameters: binwidth, bins, pad Figure 8.1: Histogram of count of correct answers on Knowledge Quiz stratified by sex of respondent 8.2 Reordering values Sometimes variables are provided in the reverse order of what you might want. For example, the answers pertaining to confidence in the Knowledge Quiz are in this specific order: attributes(dat$h1kq1b)$labels %&gt;% t() %&gt;% t() %&gt;% data.frame() ## . ## (1) Very 1 ## (2) Moderately 2 ## (3) Slightly 3 ## (4) Not at all 4 ## (6) Refused 6 ## (7) Legitimate skip (less than 15) 7 ## (8) Don&#39;t know 8 ## (9) Not applicable 9 To come up with a scale score for these, it would be better to have Very valued as a 4 and Not at all as a 1 so that row-wise sums would yield higher values for those who were more confident in many answers. One could use the existing values, but then the interpretation of an overall confidence score might be difficult, with the most confidence for the lowest overall score. Changing these values is quite straightforward. The case_when() function can be used: # for comparison, make a backup data frame datbak &lt;- dat2 &lt;- dat # reassign values dat %&lt;&gt;% mutate(h1kq1b = case_when( # main changes h1kq1b == 4 ~ 1, h1kq1b == 3 ~ 2, h1kq1b == 2 ~ 3, h1kq1b == 1 ~ 4, # anythng that is not in the above list gets its original value TRUE ~ as.numeric(h1kq1b)) ) It is a bit more awkward to deal with multiple columns. One might be tempted to use a brute force method by copy/paste/edit but using the mutate_at() function can help through the use of regular expression pattern matching for column names. The same function will be performed on multiple columns. Here we use a similar regular expression to find the columns representing confidence in answers to the Knowledge Quiz (h1kq.*b). The use of the dot (.) is shorthand for &quot;the current object&quot; which in this case is the specified column. dat2 %&lt;&gt;% mutate_at(.vars = vars(matches(&quot;h1kq.*b&quot;)), funs( case_when( . == 4 ~ 1, . == 3 ~ 2, . == 2 ~ 3, . == 1 ~ 4, TRUE ~ as.numeric(.) ) ) ) For the sake of comparison to show that the single bit of code acted on multiple columns: orig1 &lt;- table(datbak$h1kq1b) %&gt;% data.frame() mod1 &lt;- table(dat2$h1kq1b) %&gt;% data.frame() orig2 &lt;- table(datbak$h1kq2b) %&gt;% data.frame() mod2 &lt;- table(dat2$h1kq2b) %&gt;% data.frame() cbind(orig1, mod1, orig2, mod2) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) %&gt;% add_header_above(rep(c(&quot;original&quot; = 2, &quot;modified&quot; = 2), 2)) %&gt;% add_header_above(c(&quot;h1kq1b&quot; = 4, &quot;h1kq2b&quot; = 4)) h1kq1b h1kq2b original modified original modified Var1 Freq Var1 Freq Var1 Freq Var1 Freq 1 1070 1 373 1 1658 1 289 2 1723 2 1109 2 1542 2 800 3 1109 3 1723 3 800 3 1542 4 373 4 1070 4 289 4 1658 6 27 6 27 6 32 6 32 7 2039 7 2039 7 2039 7 2039 8 162 8 162 8 143 8 143 9 1 9 1 9 1 9 1 # too many unique combinations! # dat2 %&gt;% # group_by_at(vars(matches(&quot;h1kq.*b&quot;))) %&gt;% # dplyr::summarise(n = n()) Now that the values are reordered, they can be used in multiple-column scale scoring as demonstrated above. 8.3 Source code 08-week08.Rmd cat(readLines(con = &quot;08-week08.Rmd&quot;), sep = &#39;\\n&#39;) # Week 8 {#week8} ```{r, echo=FALSE, warning=FALSE, message=FALSE} library(tidyverse) library(magrittr) library(knitr) library(kableExtra) library(haven) library(pdftools) library(curl) library(ggplot2) ``` &lt;h2&gt;Topic: Add Health data: variable creation and scale scoring&lt;/h2&gt; This week&#39;s lesson will provide more background on variable creation and scale scoring. The scale scoring exercise will be used to create a single variable that represents how well respondents did overall on a subset of questions. ## Scale scoring We will be using data from the Knowledge Quiz. Download or open [21600-0001-Codebook_Questionnaire.pdf](http://staff.washington.edu/phurvitz/csde502_winter_2021/data/metadata/Wave1_Comprehensive_Codebook/21600-0001-Codebook_Questionnaire.pdf) in a new window or tab and go to page 203, or search for the string `H1KQ1A`. We will be using the file `AHwave1_v1.dta`, which is downloaded and read in the following code chunk, along with presentation of the column names, labels, and values. ```{r} dat &lt;- haven::read_dta(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/AHwave1_v1.dta&quot;) metadata &lt;- bind_cols( # variable name varname = colnames(dat), # label varlabel = lapply(dat, function(x) attributes(x)$label) %&gt;% unlist(), # values varvalues = lapply(dat, function(x) attributes(x)$labels) %&gt;% # names the variable label vector lapply(., function(x) names(x)) %&gt;% # as character as.character() %&gt;% # remove the c() construction str_remove_all(&quot;^c\\\\(|\\\\)$&quot;) ) DT::datatable(metadata) ``` Questions `H1KQ1A`, `H1KQ2A`, ..., `H1KQ10A` are factual questions about contraception that are administered to participants $\\ge$ age 15. We will be creating a single score that sums up all the correct answers across these questions for each participant $\\ge$ age 15. Because the set of questions is paired, with question &quot;a&quot; being the factual portion and &quot;b&quot; being the level of confidence, we want only those questions with column names ending with &quot;a&quot;. ### Selecting specific columns There are several ways of selecting the desired columns into a new data frame. Here is brute force approach: ```{r} # create a data frame of some columns and age &gt;= 15 mydat_bruteforce &lt;- dat %&gt;% # drop those under 15 y filter(h1kq1a != 7) %&gt;% # get answers select( aid, # subject ID h1kq1a, h1kq2a, h1kq3a, h1kq4a, h1kq5a, h1kq6a, h1kq7a, h1kq8a, h1kq9a, h1kq10a ) ``` Although there were only 10 columns with this name pattern, what if there had been 30 or 50? You would not want to have to enter each column name separately. Not only would this be tedious, there would always be the possibility of making a keyboarding mistake. Instead of the brute force approach, we can use the `matches()` function with a regular expression. The regular expression here is `^h1kq.*a$`, which translates to &quot;at the start of the string, match `h1kq`, then any number of any characters, then `a` followed by the end of the string&quot;. ```{r} mydat &lt;- dat %&gt;% filter(h1kq1a != 7) %&gt;% select( aid, matches(&quot;h1kq.*a&quot;) ) ``` We check that both processes yielded the same result: ```{r} identical(mydat_bruteforce, mydat) ``` ### Comparing participant answers to correct answers Now that we have a data frame limited to the participants in the correct age range and only the questions we want, we need to set up tests for whether the questions were answered correctly or not. From the metadata we can see that for some questions, the correct answer was `(1) true` and for some, the correct answer was `(2) false`. We can scan through the questions in the metadata to create a vector of correct answers: ```{r} # the correct answers correct &lt;- c(2, 1, 2, 2, 2, 2, 2, 1, 2, 2) # make a named vector of the answers using the selected column names names(correct) &lt;- str_subset(string = names(mydat), pattern = &quot;h1kq.*a&quot;) ``` What we now need to do is compare this vector to a vector constructed of the answers in `mydat`. There are a few approaches that could be taken. A brute force approach could use a loop to iterate over each record in the answers, and for each record to iterate over each answer: ```{r} # time this t0 &lt;- Sys.time() # make an output ans_loop &lt;- NULL # iterate over rows #testing: #for(i in 1:3){ for(i in 1:nrow(mydat)){ # init a vector Q &lt;- NULL # iterate over columns, ignoring the first &quot;aid&quot; column for(j in 2:ncol(mydat)){ # get the value of the answer ans_subj &lt;- mydat[i, j] # get the correct answer ans_actual &lt;- correct[j - 1] # compare cmp &lt;- ans_actual == ans_subj # append Q &lt;- c(Q, cmp) } # append ans_loop &lt;- rbind(ans_loop, Q) } # package it up nicely ans_loop %&lt;&gt;% data.frame() colnames(ans_loop) &lt;- names(correct) row.names(ans_loop) &lt;- NULL # timing t1 &lt;- Sys.time() runtime_loop &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(1) ``` It took `r runtime_loop` s to run. This low performance is because the algorithm is visiting every cell and comparing one-by-on with a rotating value for the correct answer from the vector of correct answers. Each object is required to be handled separately in RAM as the process continues. Another approach uses `plyr::adply()`, which runs a function over a set of rows. The [`plyr`](https://www.rdocumentation.org/packages/plyr/) package contains a set of tools for splitting data, applying functions, and recombining. ```{r} # time this t0 &lt;- Sys.time() ans_adply &lt;- mydat %&gt;% select(-1) %&gt;% plyr::adply(.margins = 1, function(x) x == correct) t1 &lt;- Sys.time() runtime_adply &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(1) ``` The `adply()` version takes far less coding, but still took `r runtime_adply` s to run. Yet another different approach compares the data frame of participant answers to the vector of correct answers. The correct answers vector will get recycled until all values have been processed. The problem with this method is that the comparison runs down columns rather than across rows. This demonstrates the problem. Table \\@ref(tab:pat1vector) shows a pattern of &quot;correct&quot; values, and Table \\@ref(tab:d1dataframe) shows a table of responses ```{r pat1vector} # make a pattern to match against pat1 &lt;- c(1, 2, 3, 4) names(pat1) &lt;- paste(&quot;question&quot;, 1:4, sep=&quot;_&quot;) pat1 %&gt;% t() %&gt;% data.frame() %&gt;% kable(caption = &#39;A pattern of &quot;correct&quot; values&#39;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` ```{r d1dataframe} # make a data frame to process d1 &lt;- cbind(rep(1, 3), rep(2, 3), rep(3,3), rep(4, 3)) %&gt;% data.frame() names(d1) &lt;- names(pat1) d1 %&gt;% kable(caption = &quot;A table of responses&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` The pattern matches the first row of data (Table \\@ref(tab:patmatchonerow)) ```{r patmatchonerow} (pat1 == d1[1,]) %&gt;% kable(caption = &quot;Matches for the first row&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` The patterns do not match the overall table as might be expected (\\@ref(tab:patmatchdfbad)). ```{r patmatchdfbad, fig.cap=&quot;Unexpected pattern matches&quot;} (d1 == pat1) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` In order to match the pattern to each row, a transpose is required. The following code performs the transpose, pattern match, and re-transpose, with results in \\@ref(tab:patmatchdfgood) ```{r patmatchdfgood} # transpose, check for matching and transpose back (d1 %&gt;% t() == pat1) %&gt;% t() %&gt;% kable(caption = &quot;Expected pattern matches&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` So the trick is to use a transpose (`t()`) to swap rows and columns. Then `unlist()` will enforce the correct ordering. After running the comparison, the data are transposed again to recreate the original structure. ```{r} # time this t0 &lt;- Sys.time() # transpose and compare ans_unlist &lt;- mydat %&gt;% select(-1) %&gt;% t(.) %&gt;% unlist(.) == correct # re-transpose and make a data frame ans_unlist %&lt;&gt;% t(.) %&gt;% data.frame() # column names colnames(ans_unlist) &lt;- names(correct) t1 &lt;- Sys.time() runtime_unlist &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(2) ``` This method took `r runtime_unlist` s to complete. Yet another method similarly uses the double transpose method. ```{r} # time this t0 &lt;- Sys.time() # strip the ID column and transpose z &lt;- mydat %&gt;% select(-1) %&gt;% t() # compare, transpose, and make a data frame ans_tranpose &lt;- (z == correct) %&gt;% t(.) %&gt;% data.frame() t1 &lt;- Sys.time() runtime_transpose &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(2) ``` This method took `r runtime_transpose` s to complete. The final and most direct method uses `base::sweep()`, which can be used to compare a vector against all rows or columns in a data frame. In order to use this function, the data frame needs to have the same number of rows (or columns) as the comparison vector. So any additional rows or columns need to be stripped. Because we may have additional columns (e.g., `aid`), those must be removed before running `sweep()`, then added back in again. Additionally, the result of `sweep()` is a matrix, so it needs to be converted to a data frame for greater functionality. ```{r} t0 &lt;- Sys.time() ans_sweep &lt;- mydat %&gt;% # drop the aid column select(-aid) %&gt;% # run the wweep sweep(x = ., MARGIN = 2, STATS = correct, FUN = &quot;==&quot;) %&gt;% # convert to data frame data.frame() t1 &lt;- Sys.time() runtime_sweep &lt;- difftime(t1, t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(3) ``` The `sweep()` method took `r runtime_sweep` s. We should check that the methods all gave identical answers. ```{r} Vectorize(identical, &#39;x&#39;)(list(ans_loop, ans_adply, ans_tranpose, ans_unlist), ans_loop) ``` ### Scoring across columns{#scoring-across-columns} Now that we have a data frame indicating for each participant whether they answered each question correctly, we can total the number of correct answers for each participant. The `rowSums()` function allows sums across rows. Because the logical values are automatically converted to numerical values (TRUE = 1; FALSE = 0), the sums provide the total number of correct answers per participant. Also because the data frame only consists of answers 1 .. 10, we can use an unqualified `rowSums()`, otherwise it would be necessary to specify which columns would be included by either position or column name. We also bring the subject identifier (`aid`) back in and reorder the columns with `select()`. Note that after the specified `aid` and total `h1kqNa_sum` columns, we can use `everything()` to select the remainder of the columns. ```{r} ans_loop %&lt;&gt;% # calculate the rowSums mutate(h1kqNa_sum = rowSums(.)) %&gt;% # bring the ID back in mutate(aid = mydat$aid) %&gt;% # reorder columns select(aid, h1kqNa_sum, everything()) ``` To show differences in total score by sex, we can join the main data back using the `aid` identifier and create a simple graph. Figure \\@ref(fig:hist) shows that more females than males had overall higher counts of correct scores on the Knowledge Quiz. ```{r hist, fig.cap=&quot;Histogram of count of correct answers on Knowledge Quiz stratified by sex of respondent&quot;} ans_loop %&lt;&gt;% left_join(dat, by = &quot;aid&quot;) %&gt;% mutate( sex = case_when( bio_sex == 1 ~ &#39;male&#39;, bio_sex == 2 ~ &#39;female&#39; ) ) ggplot(data = ans_loop, mapping = aes(x = h1kqNa_sum))+ geom_histogram(stat = &quot;count&quot;) + facet_grid(sex ~ .) + xlab(&quot;correct answers on Knowledge Quiz&quot;) + scale_x_continuous(breaks=0:10) ``` ## Reordering values Sometimes variables are provided in the reverse order of what you might want. For example, the answers pertaining to confidence in the Knowledge Quiz are in this specific order: ```{r} attributes(dat$h1kq1b)$labels %&gt;% t() %&gt;% t() %&gt;% data.frame() ``` To come up with a scale score for these, it would be better to have `Very` valued as a `4` and `Not at all` as a `1` so that row-wise sums would yield higher values for those who were more confident in many answers. One could use the existing values, but then the interpretation of an overall confidence score might be difficult, with the most confidence for the lowest overall score. Changing these values is quite straightforward. The `case_when()` function can be used: ```{r} # for comparison, make a backup data frame datbak &lt;- dat2 &lt;- dat # reassign values dat %&lt;&gt;% mutate(h1kq1b = case_when( # main changes h1kq1b == 4 ~ 1, h1kq1b == 3 ~ 2, h1kq1b == 2 ~ 3, h1kq1b == 1 ~ 4, # anythng that is not in the above list gets its original value TRUE ~ as.numeric(h1kq1b)) ) ``` It is a bit more awkward to deal with multiple columns. One might be tempted to use a brute force method by copy/paste/edit but using the `mutate_at()` function can help through the use of regular expression pattern matching for column names. The same function will be performed on multiple columns. Here we use a similar regular expression to find the columns representing confidence in answers to the Knowledge Quiz (`h1kq.*b`). The use of the dot (`.`) is shorthand for &quot;the current object&quot; which in this case is the specified column. ```{r, warning=FALSE} dat2 %&lt;&gt;% mutate_at(.vars = vars(matches(&quot;h1kq.*b&quot;)), funs( case_when( . == 4 ~ 1, . == 3 ~ 2, . == 2 ~ 3, . == 1 ~ 4, TRUE ~ as.numeric(.) ) ) ) ``` For the sake of comparison to show that the single bit of code acted on multiple columns: ```{r} orig1 &lt;- table(datbak$h1kq1b) %&gt;% data.frame() mod1 &lt;- table(dat2$h1kq1b) %&gt;% data.frame() orig2 &lt;- table(datbak$h1kq2b) %&gt;% data.frame() mod2 &lt;- table(dat2$h1kq2b) %&gt;% data.frame() cbind(orig1, mod1, orig2, mod2) %&gt;% kable() %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) %&gt;% add_header_above(rep(c(&quot;original&quot; = 2, &quot;modified&quot; = 2), 2)) %&gt;% add_header_above(c(&quot;h1kq1b&quot; = 4, &quot;h1kq2b&quot; = 4)) # too many unique combinations! # dat2 %&gt;% # group_by_at(vars(matches(&quot;h1kq.*b&quot;))) %&gt;% # dplyr::summarise(n = n()) ``` Now that the values are reordered, they can be used in multiple-column scale scoring as demonstrated above. ## Source code [08-week08.Rmd](08-week08.Rmd) ```{r comment=&#39;&#39;} cat(readLines(con = &quot;08-week08.Rmd&quot;), sep = &#39;\\n&#39;) ``` "],["week9.html", "9 Week 9 9.1 Substituting text 9.2 Showing progress 9.3 Turning text into code: eval(parse(text = &quot;some string&quot;)) 9.4 SQL in R with RSQLite and sqldf 9.5 Downloading files from password-protected web sites 9.6 Dates and time stamps: POSIXct and lubridate 9.7 Timing with Sys.time() and difftime() 9.8 Faster files with fst() 9.9 Getting US Census data with tigris, tidycensus 9.10 Easier regular expressions with RVerbalExpressions 9.11 Quick copy from Excel (Windows only) 9.12 Running system commands 9.13 Code styling 9.14 Session information 9.15 Comment out Rmd/HTML code 9.16 Source code", " 9 Week 9 Topic: Miscellaneous data processing This week's lesson will cover a set of miscellaneous data processing topics. Mostly this is a set of coded examples with explanations 9.1 Substituting text 9.1.1 paste(), paste0() Pasting text allows you to substitute variables within a text string. For example, if you are running a long loop over a series of files and you want to know which file name and loop iteration you are on. The function paste() combines a set of strings and adds a space between the strings, e.g., combining the first values from the LETTERS and the letters built-in vectors: paste(LETTERS[1], letters[1]) ## [1] &quot;A a&quot; whereas paste0 does not add spaces: paste0(LETTERS[1], letters[1]) ## [1] &quot;Aa&quot; Download the file quickfox to an arbitrary location on your computer. The code below assumes it was stored in C:/Users/phurvitz/AppData/Local/Temp. # a temp location--get dirname of dirname of the tempdir tmp &lt;- tempdir() %&gt;% dirname() # zip file zipfile &lt;- file.path(tmp, &quot;quickfox.zip&quot;) # unzip unzip(zipfile = zipfile, overwrite = TRUE, exdir = tmp) # files in the zipfile fnames &lt;- unzip(zipfile = file.path(tmp, &quot;quickfox.zip&quot;), list = TRUE) %&gt;% pull(Name) %&gt;% file.path(tmp, .) # read each file for (i in seq_len(length(fnames))) { # the file name fname &lt;- fnames[i] # read the file mytext &lt;- scan(file = fname, what = &quot;character&quot;, quiet = TRUE) # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv # make a string using `paste()` mystr &lt;- paste(mytext, &quot; &quot;, i, &quot;of&quot;, length(fnames), fname) # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ # print the message message(mystr) } ## the 1 of 9 C:/Users/phurvitz/AppData/Local/Temp/str_0017e602b137e88.txt ## quick 2 of 9 C:/Users/phurvitz/AppData/Local/Temp/str_0027e604fa83778.txt ## brown 3 of 9 C:/Users/phurvitz/AppData/Local/Temp/str_0037e60bc634af.txt ## fox 4 of 9 C:/Users/phurvitz/AppData/Local/Temp/str_0047e60195772f.txt ## jumps 5 of 9 C:/Users/phurvitz/AppData/Local/Temp/str_0057e60229c264.txt ## over 6 of 9 C:/Users/phurvitz/AppData/Local/Temp/str_0067e606cfd4207.txt ## the 7 of 9 C:/Users/phurvitz/AppData/Local/Temp/str_0077e601b5b742d.txt ## lazy 8 of 9 C:/Users/phurvitz/AppData/Local/Temp/str_0087e604c1a30c5.txt ## dog 9 of 9 C:/Users/phurvitz/AppData/Local/Temp/str_0097e6038323213.txt 9.1.2 sprintf() sprintf() can be used to format text. Here are just a few examples. The result is a formatted text string. 9.1.2.1 Formatting numerical values Leading zeros Numeric values can be formatted with a specific number of decimal places or leading zeros. For example, ZIP codes imported from CSV files often are converted to integers. The following code chunk converts some numerical ZIP code-like values to text values with the correct format. Bad ZIP codes: # some numerical ZIP codes (zip_bad &lt;- data.frame(id = 1:3, zipcode = c(90201, 02134, 00501))) ## id zipcode ## 1 1 90201 ## 2 2 2134 ## 3 3 501 Good ZIP codes: # fix them up (zip_good &lt;- zip_bad %&gt;% mutate( zipcode = sprintf(&quot;%05d&quot;, zipcode) )) ## id zipcode ## 1 1 90201 ## 2 2 02134 ## 3 3 00501 Decimal places Numerical values with different numbers of decimal places can be rendered with a specific number of decimal places. # numers with a variety of decimal places v &lt;- c(1.2, 2.345, 1e+5 + 00005) # four fixed decimal places v %&gt;% sprintf(&quot;%0.4f&quot;, .) ## [1] &quot;1.2000&quot; &quot;2.3450&quot; &quot;100005.0000&quot; Note that this is distinct from round(), which results in a numeric vector: # round to 4 places v %&gt;% round(., 4) ## [1] 1.200 2.345 100005.000 9.1.2.2 String substitutions sprintf() can also be used to achieve the same substitution in the file reading loop above. Each %s is substituted in order of the position of the arguments following the string. Also note that \\t inserts a TAB character. # read each file for (i in seq_len(length(fnames))) { # the file name fname &lt;- fnames[i] # read the file mytext &lt;- scan(file = fname, what = &quot;character&quot;, quiet = TRUE) # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv # make a string using `paste()` mystr &lt;- sprintf(&quot;%s\\t%s of %s:\\t%s&quot;, mytext, i, length(fnames), fname) # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ # print the message cat(mystr) } ## the 1 of 9: C:/Users/phurvitz/AppData/Local/Temp/str_0017e602b137e88.txtquick 2 of 9: C:/Users/phurvitz/AppData/Local/Temp/str_0027e604fa83778.txtbrown 3 of 9: C:/Users/phurvitz/AppData/Local/Temp/str_0037e60bc634af.txtfox 4 of 9: C:/Users/phurvitz/AppData/Local/Temp/str_0047e60195772f.txtjumps 5 of 9: C:/Users/phurvitz/AppData/Local/Temp/str_0057e60229c264.txtover 6 of 9: C:/Users/phurvitz/AppData/Local/Temp/str_0067e606cfd4207.txtthe 7 of 9: C:/Users/phurvitz/AppData/Local/Temp/str_0077e601b5b742d.txtlazy 8 of 9: C:/Users/phurvitz/AppData/Local/Temp/str_0087e604c1a30c5.txtdog 9 of 9: C:/Users/phurvitz/AppData/Local/Temp/str_0097e6038323213.txt 9.1.3 str_replace(), str_replace_all() The stringr functions str_replace() and str_replace_all() can be used to substitute specific strings in other strings. For example, we might create a generic function to run over a set of subject IDs that generates a file for each subject. subjects &lt;- c(&quot;a1&quot;, &quot;b2&quot;, &quot;c3&quot;) f &lt;- function(id) { # create an output filename by substituting in the subject ID outfname &lt;- &quot;C:/temp/xIDx.csv&quot; %&gt;% str_replace(pattern = &quot;xIDx&quot;, id) # ... do a bunch of stuff, for example val &lt;- rnorm(1) # write the file message(paste0(&quot;writing&quot;)) write.csv(x = val, file = outfname) } for (i in subjects) { f(i) } ## writing ## writing ## writing 9.2 Showing progress A text-based progress bar can be shown using txtProgressBar(). Here we run the same loop for reading the text files, but rather than printing the loop iteration and file names, we show the progress bar and the file contents. If no text is printed to the console (unlike what is demonstrated below with cat()), the progress bar will not print on several lines. n_fnames &lt;- length(fnames) # create progress bar pb &lt;- txtProgressBar(min = 0, max = n_fnames, style = 3) ## | | | 0% for (i in 1:n_fnames) { # delay a bit Sys.sleep(0.1) # update progress bar setTxtProgressBar(pb, i) # read and print from the file txt &lt;- scan(fnames[i], what = &quot;character&quot;, quiet = TRUE) cat(&quot;\\n&quot;, txt, &quot;\\n&quot;) } ## | |============ | 11% ## the ## | |======================= | 22% ## quick ## | |=================================== | 33% ## brown ## | |============================================== | 44% ## fox ## | |========================================================== | 56% ## jumps ## | |===================================================================== | 67% ## over ## | |================================================================================= | 78% ## the ## | |============================================================================================ | 89% ## lazy ## | |========================================================================================================| 100% ## dog close(pb) 9.3 Turning text into code: eval(parse(text = &quot;some string&quot;)) Sometimes you may have variables whose values that you want to use in a command or function. For example, suppose you wanted to write a set of files, one for each ZIP code in a data frame, with a file name including the ZIP code. We would not want to use the column name zipcode, but we want the actual value. We can generate a command using some kind of text substitution as above with sprintf() for (i in zip_good %&gt;% pull(zipcode)) { # do some stuff vals &lt;- rnorm(n = 3) y &lt;- bind_cols(zipcode = i, v = vals) # a writing command using sprintf() to substitute %s = ZIP code cmd &lt;- sprintf(&quot;write.csv(x = y, file = &#39;C:/temp/%s.csv&#39;, row.names = FALSE)&quot;, i) # this runs the command eval(parse(text = cmd)) } 9.4 SQL in R with RSQLite and sqldf Sometimes R's syntax for processing data can be difficult and confusing. For programmers who are familiar with structured query language (SQL), it is possible to run SQL statements within R using a supported database back end (by default SQLite) and the sqldf() function. For example, the mean sepal length by species from the built-in iris data set can be obtained, presented in Table 9.1 library(sqldf) sqlc &lt;- &#39;select &quot;Species&quot; as species , avg(&quot;Sepal.Length&quot;) as mean_sepal_length from iris group by &quot;Species&quot;; &#39; iris_summary &lt;- sqldf(x = sqlc) iris_summary %&gt;% kable(caption = &quot;Mean sepal length from the iris data set&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) Table 9.1: Mean sepal length from the iris data set species mean_sepal_length setosa 5.006 versicolor 5.936 virginica 6.588 9.5 Downloading files from password-protected web sites Some web sites are protected by simple username/password protection. For example, try opening [http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected] (http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected). The username/password pair is csde/502, which will allow you to see the contents of the web folder. If you try downloading the file through R, you will get an error because no password is supplied. try( read.csv(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv&quot;) ) ## id zipcode ## 1 1 2134 However, the username and password can be supplied as part of the URL, as below. When the username and password are supplied, they will be cached for that site for the duration of the R session. try( read.csv(&quot;http://csde:502@staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv&quot;) ) ## id zipcode ## 1 1 2134 9.6 Dates and time stamps: POSIXct and lubridate R uses POSIX-style time stamps, which are stored internally as the number of fractional seconds from January 1, 1970. It is imperative that the control over time stamps is commensurate with the temporal accuracy and precision your data. For example, in the measurement of years of residence, precision is not substantially important. For measurement of chemical reactions, fractional seconds may be very important. For applications such as merging body-worn sensor data from GPS units and accelerometers for estimating where and when physical activity occurs, minutes of error can result in statistically significant mis-estimations. For example, you can see the numeric value of these seconds as options(digits = 22); Sys.time() %&gt;% as.numeric(). options(digits = 22) Sys.time() %&gt;% as.numeric() ## [1] 1615062338.7390621 If you have time stamps in text format, they can be converted to POSIX time stamps, e.g., the supposed time Neil Armstrong stepped on the moon: (eagle &lt;- as.POSIXct(x = &quot;7/20/69 10:56 PM&quot;, tz = &quot;CST6CDT&quot;, format = &quot;%m/%d/%y %H:%M&quot;)) ## [1] &quot;1969-07-20 10:56:00 CDT&quot; Formats can be specified using specific codes, see strptime(). The lubridate package has a large number of functions for handling date and time stamps. For example, if you want to convert a time stamp in the current time zone to a different time zone, first we get the current time library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union # set the option for fractional seconds options(digits.secs = 3) (now &lt;- Sys.time() %&gt;% strptime(&quot;%Y-%m-%d %H:%M:%OS&quot;)) ## [1] &quot;2021-03-06 12:25:39.028 PST&quot; And convert to UTC: # show this at time zone UTC (with_tz(time = now, tzone = &quot;UTC&quot;)) ## [1] &quot;2021-03-06 20:25:39.028 UTC&quot; or show in a different format: # in different format now %&gt;% format(&quot;%A, %B %d, %Y %l:%m %p %Z&quot;) ## [1] &quot;Saturday, March 06, 2021 12:03 PM PST&quot; 9.7 Timing with Sys.time() and difftime() It is easy to determine how long a process takes by using sequential Sys.time() calls, one before and one after the process, and getting the difference with difftime(). For example, # mark time and run a process t0 &lt;- Sys.time() Sys.sleep(5) t1 &lt;- Sys.time() # difftime() unqualified will make its best decision about what to print (difftime(time1 = t1, time2 = t0)) ## Time difference of 5.155155 secs # time between moon step and now-ish (difftime(time1 = t0, time2 = eagle)) ## Time difference of 18857.19 days difftime() can also be forced to report the time difference in the units of choice: (difftime(time1 = t1, time2 = t0, units = &quot;secs&quot;) %&gt;% as.numeric()) %&gt;% round(0) ## [1] 5 (difftime(time1 = t1, time2 = t0, units = &quot;mins&quot;) %&gt;% as.numeric()) %&gt;% round(2) ## [1] 0.09 (difftime(time1 = t1, time2 = t0, units = &quot;hours&quot;) %&gt;% as.numeric()) %&gt;% round(4) ## [1] 0.0014 (difftime(time1 = t1, time2 = t0, units = &quot;days&quot;) %&gt;% as.numeric()) %&gt;% round(6) ## [1] 6e-05 9.8 Faster files with fst() The fst package is great for rapid reading and writing of data frames. The format can also result in much smaller file sizes using compression. Here we will examine the large Add Health file. First, a download, unzip, and read as necessary: library(fst) ## fst package v0.9.4 ## (OpenMP detected, using 4 threads) myUrl &lt;- &quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip&quot; # zipfile in $temp tmp &lt;- tempdir() %&gt;% dirname() zipfile &lt;- file.path(tmp, basename(myUrl)) # dta file in $temp dtafname &lt;- tools::file_path_sans_ext(zipfile) # check if the dta file exists if (!file.exists(dtafname)) { # if the dta file doesn&#39;t exist, check for the zip file # check if the zip file exists, download if necessary if (!file.exists(zipfile)) { curl::curl_download(url = myUrl, destfile = zipfile) } # unzip the downloaded zip file unzip(zipfile = zipfile, exdir = Sys.getenv(&quot;TEMP&quot;)) } # read the file dat &lt;- read_dta(dtafname) # save as a CSV, along with timing t0 &lt;- Sys.time() csvfname &lt;- dtafname %&gt;% str_replace(pattern = &quot;dta&quot;, replacement = &quot;csv&quot;) write.csv(x = dat, file = csvfname, row.names = FALSE) t1 &lt;- Sys.time() csvwrite_time &lt;- difftime(time1 = t1, time2 = t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(1) # file size csvsize &lt;- file.info(csvfname) %&gt;% pull(size) %&gt;% sprintf(&quot;%0.f&quot;, .) # save as FST, along with timing t0 &lt;- Sys.time() fstfname &lt;- dtafname %&gt;% str_replace(pattern = &quot;dta&quot;, replacement = &quot;fst&quot;) write.fst(x = dat, path = fstfname) t1 &lt;- Sys.time() # file size fstsize &lt;- file.info(fstfname) %&gt;% pull(size) %&gt;% sprintf(&quot;%0.f&quot;, .) fstwrite_time &lt;- difftime(time1 = t1, time2 = t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(1) It took 51.6 s to write 41823590 bytes as CSV, and 0.7 s to write 19064839 bytes as a FST file (with the default compression amount of 50). Reading speeds are comparable. It should be noted that some file attributes will not be saved in FST format and therefore it should be used with caution if you have a highly attributed data set (e.g., a Stata DTA file with extensive labeling). You will lose those attributes! But for data sets with a simple structure, including factors, the FST format is a good option. 9.9 Getting US Census data with tigris, tidycensus Dealing with US Census data can be overwhelming, particularly if using the raw text-based data. The Census Bureau has an API that allows more streamlined downloads of variables (as data frames) and geographies (as simple format shapes). It is necessary to get an API key, available for free. See tidycensus and tidycensus basic usage. tidycensus uses tigris, which downloads the geographic data portion of the census files. A simple example will download the variables representing the count of White, Black/African American, American Indian/Native American, and Asian persons from the American Community Survey (ACS) data for King County in 2019. The labels from the census API are: &quot;Estimate!!Total&quot; &quot;Estimate!!Total!!White alone&quot; &quot;Estimate!!Total!!Black or African American alone&quot; &quot;Estimate!!Total!!American Indian and Alaska Native alone&quot; &quot;Estimate!!Total!!Asian alone&quot; library(tidycensus) # the census variables census_vars &lt;- c( p_denom_race = &quot;B02001_001&quot;, p_n_white = &quot;B02001_002&quot;, p_n_afram = &quot;B02001_003&quot;, p_n_aian = &quot;B02001_004&quot;, p_n_asian = &quot;B02001_005&quot; ) # get the data ctdat &lt;- get_acs( geography = &quot;tract&quot;, variables = census_vars, cache_table = TRUE, year = 2019, output = &quot;wide&quot;, state = &quot;WA&quot;, county = &quot;King&quot;, geometry = TRUE, survey = &quot;acs5&quot; ) ## Getting data from the 2015-2019 5-year ACS ## Downloading feature geometry from the Census website. To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`. ## Using FIPS code &#39;53&#39; for state &#39;WA&#39; ## Using FIPS code &#39;033&#39; for &#39;King County&#39; A few values are shown in Table 9.2, and a simple map is shown in ??, with percent African American residents and tract identifier. # print a few records ctdat %&gt;% head() %&gt;% kable(caption = &quot;Selected census tract variables from the 5-year ACS from 2019 for King County, WA&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) Table 9.2: Selected census tract variables from the 5-year ACS from 2019 for King County, WA GEOID NAME p_denom_raceE p_denom_raceM p_n_whiteE p_n_whiteM p_n_aframE p_n_aframM p_n_aianE p_n_aianM p_n_asianE p_n_asianM geometry 53033011300 Census Tract 113, King County, Washington 6656 447 3412 323 480 209 133 100 880 409 MULTIPOLYGON (((-122.3551 4... 53033004900 Census Tract 49, King County, Washington 7489 605 6469 654 15 25 18 24 520 225 MULTIPOLYGON (((-122.3555 4... 53033026801 Census Tract 268.01, King County, Washington 6056 642 2561 615 542 426 184 162 777 378 MULTIPOLYGON (((-122.3551 4... 53033006400 Census Tract 64, King County, Washington 3739 192 3101 231 62 45 38 35 231 115 MULTIPOLYGON (((-122.3126 4... 53033005100 Census Tract 51, King County, Washington 3687 236 3066 230 116 135 8 14 228 58 MULTIPOLYGON (((-122.3364 4... 53033002000 Census Tract 20, King County, Washington 3854 271 3129 290 54 76 9 13 431 139 MULTIPOLYGON (((-122.3177 4... library(leaflet) library(htmltools) library(sf) # define the CRS st_crs(ctdat) &lt;- 4326 # proportion Black ctdat %&lt;&gt;% mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %&gt;% round(1)) # a label labels &lt;- sprintf(&quot;%s&lt;br/&gt;%s%s&quot;, ctdat$GEOID, ctdat$pct_black, &quot;%&quot;) %&gt;% lapply(htmltools::HTML) bins &lt;- 0:50 pal &lt;- colorBin(palette = &quot;Reds&quot;, domain = ctdat$pct_black, bins = bins) bins2 &lt;- seq(0, 50, by = 10) pal2 &lt;- colorBin(palette = &quot;Reds&quot;, domain = ctdat$pct_black, bins = bins2) # the leaflet map m &lt;- leaflet(height = &quot;500px&quot;) %&gt;% # add polygons from tracts addPolygons( data = ctdat, weight = 1, fillOpacity = 0.8, # fill using the palette fillColor = ~pal(pct_black), # highlighting highlight = highlightOptions( weight = 5, color = &quot;#666&quot;, fillOpacity = 0.7, bringToFront = TRUE), # popup labels label = labels, labelOptions = labelOptions( style = list(&quot;font-weight&quot; = &quot;normal&quot;, padding = &quot;3px 8px&quot;), textsize = &quot;15px&quot;, direction = &quot;auto&quot;)) %&gt;% addLegend(position = &quot;bottomright&quot;, pal = pal2, values = ctdat$pct_black, title = &quot;% African American&quot;, opacity = 1) m %&gt;% addTiles() Figure 9.1: Percent African American in census tracts in King County, 2019 ACS 5-year estimate 9.10 Easier regular expressions with RVerbalExpressions Regular expressions are powerful but take some time and trial-and-error to master. The RVerbalExpresions package can be used to more easily generate regular expressions. See the help for rx() and associated functions. These examples show two constructions of regular expressions for matching two similar but different URLs. library(RVerbalExpressions) # a pattern x &lt;- rx_start_of_line() %&gt;% rx_find(&quot;http&quot;) %&gt;% rx_maybe(&quot;s&quot;) %&gt;% rx_find(&quot;://&quot;) %&gt;% rx_maybe(&quot;www.&quot;) %&gt;% rx_anything_but(&quot; &quot;) %&gt;% rx_end_of_line() # print the expression (x) ## [1] &quot;^(http)(s)?(\\\\://)(www\\\\.)?([^ ]*)$&quot; # search for a pattern in some URLs urls &lt;- c( &quot;http://www.google.com&quot;, &quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/&quot; ) grepl(pattern = x, x = urls) ## [1] TRUE TRUE # a different pattern y &lt;- rx_start_of_line() %&gt;% rx_find(&quot;http&quot;) %&gt;% rx_maybe(&quot;s&quot;) %&gt;% rx_find(&quot;://&quot;) %&gt;% rx_find(&quot;www.&quot;) %&gt;% rx_anything_but(&quot; &quot;) %&gt;% rx_end_of_line() # print the expression (y) ## [1] &quot;^(http)(s)?(\\\\://)(www\\\\.)([^ ]*)$&quot; # search for a pattern in the two URLs, matches one, does not match the other grepl(pattern = y, x = urls) ## [1] TRUE FALSE 9.11 Quick copy from Excel (Windows only) Under Windows, it is possible to copy selected cells from an Excel worksheet directly to R. This is not an endorsement for using Excel, but there are some cases in which Excel may be able to produce some quick data that you don't want to develop in other ways. As a demonstration, you can use analysis.xlsx. Download and open the file. Here is shown a selection of cells that was copied. The code below shows how the data can be copied. xlsclip &lt;- read.table(file = &quot;clipboard&quot;, sep = &quot;\\t&quot;, header = TRUE) xlsclip %&gt;% kable() %&gt;% kable_styling( full_width = FALSE, position = &quot;left&quot; ) word lcase n_chars first_letter A a 1 a aa aa 2 a aal aal 3 a aalii aalii 5 a aam aam 3 a Aani aani 4 a aardvark aardvark 8 a aardwolf aardwolf 8 a Aaron aaron 5 a Aaronic aaronic 7 a Aaronical aaronical 9 a Aaronite aaronite 8 a 9.12 Running system commands R can run arbitrary system commands that you would normally run in a terminal or command window. The system() function is used to run commands, optionally with the results returned as a character vector. Under Mac and Linux, the usage is quite straightforward, for example, to list files in a specific directory: tempdirfiles &lt;- system(&quot;ls /tmp&quot;, intern = TRUE) Under Windows, it takes a bit of extra code. To do the same requires the prefix cmd /c in the system() call before the command itself. Also any backslashes in path names need to be specified as double-backslashes for R. # R prefers and automatically generates forward slashes # under Windows, path delimiters are backslashes so need to be rendered in R as double backslashes tmpdir &lt;- dirname(tempdir()) %&gt;% str_replace_all(&quot;/&quot;, &quot;\\\\\\\\&quot;) # construct a system command # under Windows cmd &lt;- sprintf(&quot;cmd /c dir %s&quot;, tmpdir) tempdirfiles &lt;- system(command = cmd, intern = TRUE) If you are running other programs or utilities that are executed in a terminal or command window, this can be very helpful. 9.13 Code styling Good code should meet at least the two functional requirements of getting the job done and being able able to read. Code that gets the job done but that is not easy to read will cause problems later when you try to figure out how or why you did something. The styler package can help clean up your code so that it conforms to a specific style such as that in the tidyverse style guide. styler can be integrated into RStudio for interactive use. It can reformat selected code, an entire file, or an entire project. An example is shown: lintr is also useful for identifying potential style errors. 9.14 Session information It may be helpful in troubleshooting or complete documentation to report the complete session information. For example, sometimes outdated versions of packages may contain errors. The session information is printed with sessionInfo(). sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows &gt;= 8 x64 (build 9200) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] RVerbalExpressions_0.1.0 fst_0.9.4 lubridate_1.7.10 pdftools_2.3.1 ## [5] captioner_2.2.3 animation_2.6 psych_2.0.12 pander_0.6.3 ## [9] stargazer_5.2.2 readstata13_0.9.2 sf_0.9-7 htmltools_0.5.1.1 ## [13] leaflet_2.0.4.1 tidycensus_0.11.4 sqldf_0.4-11 RSQLite_2.2.3 ## [17] gsubfn_0.7 proto_1.0.0 shiny_1.6.0 curl_4.3 ## [21] haven_2.3.1 kableExtra_1.3.4 knitr_1.31 magrittr_2.0.1 ## [25] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.5 purrr_0.3.4 ## [29] readr_1.4.0 tidyr_1.1.3 tibble_3.1.0 ggplot2_3.3.3 ## [33] tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 uuid_0.1-4 backports_1.2.1 systemfonts_1.0.1 ## [5] plyr_1.8.6 lazyeval_0.2.2 sp_1.4-5 crosstalk_1.1.1 ## [9] digest_0.6.27 rsconnect_0.8.16 leaflet.providers_1.9.0 fansi_0.4.2 ## [13] memoise_2.0.0 remotes_2.2.0 modelr_0.1.8 svglite_2.0.0 ## [17] askpass_1.1 colorspace_2.0-0 blob_1.2.1 rvest_0.3.6 ## [21] rappdirs_0.3.3 xfun_0.21 rgdal_1.5-23 tcltk_4.0.4 ## [25] callr_3.5.1 crayon_1.4.1 jsonlite_1.7.2 tigris_1.0 ## [29] glue_1.4.2 xmlparsedata_1.0.5 gtable_0.3.0 webshot_0.5.2 ## [33] questionr_0.7.4 scales_1.1.1 qpdf_1.1 DBI_1.1.1 ## [37] miniUI_0.1.1.1 Rcpp_1.0.6 viridisLite_0.3.0 xtable_1.8-4 ## [41] tmvnsim_1.0-2 units_0.7-0 foreign_0.8-81 bit_4.0.4 ## [45] DT_0.17 htmlwidgets_1.5.3 rex_1.2.0 httr_1.4.2 ## [49] RColorBrewer_1.1-2 ellipsis_0.3.1 pkgconfig_2.0.3 farver_2.1.0 ## [53] sass_0.3.1 dbplyr_2.1.0 utf8_1.1.4 tidyselect_1.1.0 ## [57] labeling_0.4.2 rlang_0.4.10 later_1.1.0.1 munsell_0.5.0 ## [61] cellranger_1.1.0 tools_4.0.4 cachem_1.0.4 cli_2.3.1 ## [65] generics_0.1.0 broom_0.7.5 evaluate_0.14 fastmap_1.1.0 ## [69] yaml_2.2.1 rematch2_2.1.2 processx_3.4.5 bit64_4.0.5 ## [73] fs_1.5.0 nlme_3.1-152 mime_0.10 xml2_1.3.2 ## [77] compiler_4.0.4 rstudioapi_0.13 png_0.1-7 e1071_1.7-4 ## [81] reprex_1.0.0 bslib_0.2.4 stringi_1.5.3 cyclocomp_1.1.0 ## [85] highr_0.8 ps_1.6.0 desc_1.2.0 lattice_0.20-41 ## [89] classInt_0.4-3 styler_1.3.2 vctrs_0.3.6 pillar_1.5.1 ## [93] lifecycle_1.0.0 jquerylib_0.1.3 data.table_1.14.0 maptools_1.0-2 ## [97] httpuv_1.5.5 Rmisc_1.5 R6_2.5.0 bookdown_0.21 ## [101] promises_1.2.0.1 KernSmooth_2.23-18 codetools_0.2-18 assertthat_0.2.1 ## [105] chron_2.3-56 rprojroot_2.0.2 withr_2.4.1 mnormt_2.0.2 ## [109] parallel_4.0.4 hms_1.0.0 lintr_2.0.1 grid_4.0.4 ## [113] labelled_2.7.0 class_7.3-18 rmarkdown_2.7 9.15 Comment out Rmd/HTML code To comment out entire parts of your Rmd so they do not appear in your rendered HTML, use HTML comments, which are specified with the delimiters &lt;!-- and --&gt;. 9.16 Source code 09-week09.Rmd cat(readLines(con = &quot;09-week09.Rmd&quot;), sep = &quot;\\n&quot;) # Week 9 {#week9} ```{r, echo=FALSE, warning=FALSE, message=FALSE} library(tidyverse) library(magrittr) library(knitr) library(kableExtra) library(haven) library(curl) library(ggplot2) ``` &lt;h2&gt;Topic: Miscellaneous data processing &lt;/h2&gt; This week&#39;s lesson will cover a set of miscellaneous data processing topics. Mostly this is a set of coded examples with explanations ## Substituting text ### `paste()`, `paste0()` Pasting text allows you to substitute variables within a text string. For example, if you are running a long loop over a series of files and you want to know which file name and loop iteration you are on. The function `paste()` combines a set of strings and adds a space between the strings, e.g., combining the first values from the `LETTERS` and the `letters` built-in vectors: ```{r} paste(LETTERS[1], letters[1]) ``` whereas `paste0` does not add spaces: ```{r} paste0(LETTERS[1], letters[1]) ``` Download the file [quickfox](files/quickfox.zip) to an arbitrary location on your computer. The code below assumes it was stored in `r dirname(tempdir())`. ```{r} # a temp location--get dirname of dirname of the tempdir tmp &lt;- tempdir() %&gt;% dirname() # zip file zipfile &lt;- file.path(tmp, &quot;quickfox.zip&quot;) # unzip unzip(zipfile = zipfile, overwrite = TRUE, exdir = tmp) # files in the zipfile fnames &lt;- unzip(zipfile = file.path(tmp, &quot;quickfox.zip&quot;), list = TRUE) %&gt;% pull(Name) %&gt;% file.path(tmp, .) # read each file for (i in seq_len(length(fnames))) { # the file name fname &lt;- fnames[i] # read the file mytext &lt;- scan(file = fname, what = &quot;character&quot;, quiet = TRUE) # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv # make a string using `paste()` mystr &lt;- paste(mytext, &quot; &quot;, i, &quot;of&quot;, length(fnames), fname) # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ # print the message message(mystr) } ``` ### `sprintf()` `sprintf()` can be used to format text. Here are just a few examples. The result is a formatted text string. #### Formatting numerical values &lt;u&gt;Leading zeros&lt;/u&gt; Numeric values can be formatted with a specific number of decimal places or leading zeros. For example, ZIP codes imported from CSV files often are converted to integers. The following code chunk converts some numerical ZIP code-like values to text values with the correct format. Bad ZIP codes: ```{r} # some numerical ZIP codes (zip_bad &lt;- data.frame(id = 1:3, zipcode = c(90201, 02134, 00501))) ``` Good ZIP codes: ```{r} # fix them up (zip_good &lt;- zip_bad %&gt;% mutate( zipcode = sprintf(&quot;%05d&quot;, zipcode) )) ``` &lt;u&gt;Decimal places&lt;/u&gt; Numerical values with different numbers of decimal places can be rendered with a specific number of decimal places. ```{r} # numers with a variety of decimal places v &lt;- c(1.2, 2.345, 1e+5 + 00005) # four fixed decimal places v %&gt;% sprintf(&quot;%0.4f&quot;, .) ``` Note that this is distinct from `round()`, which results in a numeric vector: ```{r} # round to 4 places v %&gt;% round(., 4) ``` #### String substitutions `sprintf()` can also be used to achieve the same substitution in the file reading loop above. Each `%s` is substituted in order of the position of the arguments following the string. Also note that `\\t` inserts a `TAB` character. ```{r} # read each file for (i in seq_len(length(fnames))) { # the file name fname &lt;- fnames[i] # read the file mytext &lt;- scan(file = fname, what = &quot;character&quot;, quiet = TRUE) # vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv # make a string using `paste()` mystr &lt;- sprintf(&quot;%s\\t%s of %s:\\t%s&quot;, mytext, i, length(fnames), fname) # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ # print the message cat(mystr) } ``` ### `str_replace()`, `str_replace_all()` The `stringr` functions `str_replace()` and `str_replace_all()` can be used to substitute specific strings in other strings. For example, we might create a generic function to run over a set of subject IDs that generates a file for each subject. ```{r} subjects &lt;- c(&quot;a1&quot;, &quot;b2&quot;, &quot;c3&quot;) f &lt;- function(id) { # create an output filename by substituting in the subject ID outfname &lt;- &quot;C:/temp/xIDx.csv&quot; %&gt;% str_replace(pattern = &quot;xIDx&quot;, id) # ... do a bunch of stuff, for example val &lt;- rnorm(1) # write the file message(paste0(&quot;writing&quot;)) write.csv(x = val, file = outfname) } for (i in subjects) { f(i) } ``` ## Showing progress A text-based progress bar can be shown using `txtProgressBar()`. Here we run the same loop for reading the text files, but rather than printing the loop iteration and file names, we show the progress bar and the file contents. If no text is printed to the console (unlike what is demonstrated below with `cat()`), the progress bar will not print on several lines. ```{r} n_fnames &lt;- length(fnames) # create progress bar pb &lt;- txtProgressBar(min = 0, max = n_fnames, style = 3) for (i in 1:n_fnames) { # delay a bit Sys.sleep(0.1) # update progress bar setTxtProgressBar(pb, i) # read and print from the file txt &lt;- scan(fnames[i], what = &quot;character&quot;, quiet = TRUE) cat(&quot;\\n&quot;, txt, &quot;\\n&quot;) } close(pb) ``` ## Turning text into code: `eval(parse(text = &quot;some string&quot;))` Sometimes you may have variables whose values that you want to use in a command or function. For example, suppose you wanted to write a set of files, one for each ZIP code in a data frame, with a file name including the ZIP code. We would not want to use the column name `zipcode`, but we want the actual value. We can generate a command using some kind of text substitution as above with `sprintf()` ```{r} for (i in zip_good %&gt;% pull(zipcode)) { # do some stuff vals &lt;- rnorm(n = 3) y &lt;- bind_cols(zipcode = i, v = vals) # a writing command using sprintf() to substitute %s = ZIP code cmd &lt;- sprintf(&quot;write.csv(x = y, file = &#39;C:/temp/%s.csv&#39;, row.names = FALSE)&quot;, i) # this runs the command eval(parse(text = cmd)) } ``` ## SQL in R with `RSQLite` and `sqldf` Sometimes R&#39;s syntax for processing data can be difficult and confusing. For programmers who are familiar with structured query language (SQL), it is possible to run SQL statements within R using a supported database back end (by default SQLite) and the `sqldf()` function. For example, the mean sepal length by species from the built-in `iris` data set can be obtained, presented in Table \\@ref(tab:iris) ```{r iris} library(sqldf) sqlc &lt;- &#39;select &quot;Species&quot; as species , avg(&quot;Sepal.Length&quot;) as mean_sepal_length from iris group by &quot;Species&quot;; &#39; iris_summary &lt;- sqldf(x = sqlc) iris_summary %&gt;% kable(caption = &quot;Mean sepal length from the iris data set&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` ## Downloading files from password-protected web sites Some web sites are protected by simple username/password protection. For example, try opening [http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected] (http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected). The username/password pair is csde/502, which will allow you to see the contents of the web folder. If you try downloading the file through R, you will get an error because no password is supplied. ```{r} try( read.csv(&quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv&quot;) ) ``` However, the username and password can be supplied as part of the URL, as below. When the username and password are supplied, they will be cached for that site for the duration of the R session. ```{r} try( read.csv(&quot;http://csde:502@staff.washington.edu/phurvitz/csde502_winter_2021/password_protected/foo.csv&quot;) ) ``` ## Dates and time stamps: `POSIXct` and `lubridate` R uses POSIX-style time stamps, which are stored internally as the number of fractional seconds from January 1, 1970. It is imperative that the control over time stamps is commensurate with the temporal accuracy and precision your data. For example, in the measurement of years of residence, precision is not substantially important. For measurement of chemical reactions, fractional seconds may be very important. For applications such as merging body-worn sensor data from GPS units and accelerometers for estimating where and when physical activity occurs, minutes of error can result in statistically significant mis-estimations. For example, you can see the numeric value of these seconds as `options(digits = 22); Sys.time() %&gt;% as.numeric()`. ```{r} options(digits = 22) Sys.time() %&gt;% as.numeric() ``` If you have time stamps in text format, they can be converted to POSIX time stamps, e.g., the supposed time Neil Armstrong stepped on the moon: ```{r} (eagle &lt;- as.POSIXct(x = &quot;7/20/69 10:56 PM&quot;, tz = &quot;CST6CDT&quot;, format = &quot;%m/%d/%y %H:%M&quot;)) ``` Formats can be specified using specific codes, see `strptime()`. The `lubridate` package has a large number of functions for handling date and time stamps. For example, if you want to convert a time stamp in the current time zone to a different time zone, first we get the current time ```{r} library(lubridate) # set the option for fractional seconds options(digits.secs = 3) (now &lt;- Sys.time() %&gt;% strptime(&quot;%Y-%m-%d %H:%M:%OS&quot;)) ``` And convert to UTC: ```{r} # show this at time zone UTC (with_tz(time = now, tzone = &quot;UTC&quot;)) ``` or show in a different format: ```{r} # in different format now %&gt;% format(&quot;%A, %B %d, %Y %l:%m %p %Z&quot;) ``` ```{r, echo=FALSE} # reset the digits options(digits = 7) ``` ## Timing with `Sys.time()` and `difftime()` It is easy to determine how long a process takes by using sequential `Sys.time()` calls, one before and one after the process, and getting the difference with `difftime()`. For example, ```{r} # mark time and run a process t0 &lt;- Sys.time() Sys.sleep(5) t1 &lt;- Sys.time() # difftime() unqualified will make its best decision about what to print (difftime(time1 = t1, time2 = t0)) # time between moon step and now-ish (difftime(time1 = t0, time2 = eagle)) ``` `difftime()` can also be forced to report the time difference in the units of choice: ```{r} (difftime(time1 = t1, time2 = t0, units = &quot;secs&quot;) %&gt;% as.numeric()) %&gt;% round(0) (difftime(time1 = t1, time2 = t0, units = &quot;mins&quot;) %&gt;% as.numeric()) %&gt;% round(2) (difftime(time1 = t1, time2 = t0, units = &quot;hours&quot;) %&gt;% as.numeric()) %&gt;% round(4) (difftime(time1 = t1, time2 = t0, units = &quot;days&quot;) %&gt;% as.numeric()) %&gt;% round(6) ``` ## Faster files with `fst()` The `fst` package is great for rapid reading and writing of data frames. The format can also result in much smaller file sizes using compression. Here we will examine the large Add Health file. First, a download, unzip, and read as necessary: ```{r} library(fst) myUrl &lt;- &quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/data/21600-0001-Data.dta.zip&quot; # zipfile in $temp tmp &lt;- tempdir() %&gt;% dirname() zipfile &lt;- file.path(tmp, basename(myUrl)) # dta file in $temp dtafname &lt;- tools::file_path_sans_ext(zipfile) # check if the dta file exists if (!file.exists(dtafname)) { # if the dta file doesn&#39;t exist, check for the zip file # check if the zip file exists, download if necessary if (!file.exists(zipfile)) { curl::curl_download(url = myUrl, destfile = zipfile) } # unzip the downloaded zip file unzip(zipfile = zipfile, exdir = Sys.getenv(&quot;TEMP&quot;)) } # read the file dat &lt;- read_dta(dtafname) # save as a CSV, along with timing t0 &lt;- Sys.time() csvfname &lt;- dtafname %&gt;% str_replace(pattern = &quot;dta&quot;, replacement = &quot;csv&quot;) write.csv(x = dat, file = csvfname, row.names = FALSE) t1 &lt;- Sys.time() csvwrite_time &lt;- difftime(time1 = t1, time2 = t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(1) # file size csvsize &lt;- file.info(csvfname) %&gt;% pull(size) %&gt;% sprintf(&quot;%0.f&quot;, .) # save as FST, along with timing t0 &lt;- Sys.time() fstfname &lt;- dtafname %&gt;% str_replace(pattern = &quot;dta&quot;, replacement = &quot;fst&quot;) write.fst(x = dat, path = fstfname) t1 &lt;- Sys.time() # file size fstsize &lt;- file.info(fstfname) %&gt;% pull(size) %&gt;% sprintf(&quot;%0.f&quot;, .) fstwrite_time &lt;- difftime(time1 = t1, time2 = t0, units = &quot;secs&quot;) %&gt;% as.numeric() %&gt;% round(1) ``` It took `r csvwrite_time` s to write `r csvsize` bytes as CSV, and `r fstwrite_time` s to write `r fstsize` bytes as a FST file (with the default compression amount of 50). Reading speeds are comparable. ___It should be noted___ that some file attributes will not be saved in FST format and therefore it should be used with caution if you have a highly attributed data set (e.g., a Stata DTA file with extensive labeling). You will lose those attributes! But for data sets with a simple structure, including factors, the FST format is a good option. ## Getting US Census data with `tigris`, `tidycensus` Dealing with US Census data can be overwhelming, particularly if using the raw text-based data. The Census Bureau has an API that allows more streamlined downloads of variables (as data frames) and geographies (as simple format shapes). It is necessary to get an API key, available for free. See [tidycensus](https://walker-data.com/tidycensus/) and [tidycensus basic usage](https://walker-data.com/tidycensus/articles/basic-usage.html). `tidycensus` uses [`tigris`](https://www.rdocumentation.org/packages/tigris/versions/1.0), which downloads the geographic data portion of the census files. A simple example will download the variables representing the count of White, Black/African American, American Indian/Native American, and Asian persons from the American Community Survey (ACS) data for King County in 2019. The labels from the census API are: ``` &quot;Estimate!!Total&quot; &quot;Estimate!!Total!!White alone&quot; &quot;Estimate!!Total!!Black or African American alone&quot; &quot;Estimate!!Total!!American Indian and Alaska Native alone&quot; &quot;Estimate!!Total!!Asian alone&quot; ``` ```{r, warning=FALSE} library(tidycensus) # the census variables census_vars &lt;- c( p_denom_race = &quot;B02001_001&quot;, p_n_white = &quot;B02001_002&quot;, p_n_afram = &quot;B02001_003&quot;, p_n_aian = &quot;B02001_004&quot;, p_n_asian = &quot;B02001_005&quot; ) # get the data ctdat &lt;- get_acs( geography = &quot;tract&quot;, variables = census_vars, cache_table = TRUE, year = 2019, output = &quot;wide&quot;, state = &quot;WA&quot;, county = &quot;King&quot;, geometry = TRUE, survey = &quot;acs5&quot; ) ``` A few values are shown in Table \\@ref(tab:census), and a simple map is shown in \\@ref(fig:ct), with percent African American residents and tract identifier. ```{r census} # print a few records ctdat %&gt;% head() %&gt;% kable(caption = &quot;Selected census tract variables from the 5-year ACS from 2019 for King County, WA&quot;) %&gt;% kable_styling(full_width = FALSE, position = &quot;left&quot;) ``` ```{r, fig.cap=&quot;Percent African American in census tracts in King County, 2019 ACS 5-year estimate&quot;, warning=FALSE, message=FALSE} library(leaflet) library(htmltools) library(sf) # define the CRS st_crs(ctdat) &lt;- 4326 # proportion Black ctdat %&lt;&gt;% mutate(pct_black = (p_n_aframE / p_denom_raceE * 100) %&gt;% round(1)) # a label labels &lt;- sprintf(&quot;%s&lt;br/&gt;%s%s&quot;, ctdat$GEOID, ctdat$pct_black, &quot;%&quot;) %&gt;% lapply(htmltools::HTML) bins &lt;- 0:50 pal &lt;- colorBin(palette = &quot;Reds&quot;, domain = ctdat$pct_black, bins = bins) bins2 &lt;- seq(0, 50, by = 10) pal2 &lt;- colorBin(palette = &quot;Reds&quot;, domain = ctdat$pct_black, bins = bins2) # the leaflet map m &lt;- leaflet(height = &quot;500px&quot;) %&gt;% # add polygons from tracts addPolygons( data = ctdat, weight = 1, fillOpacity = 0.8, # fill using the palette fillColor = ~pal(pct_black), # highlighting highlight = highlightOptions( weight = 5, color = &quot;#666&quot;, fillOpacity = 0.7, bringToFront = TRUE), # popup labels label = labels, labelOptions = labelOptions( style = list(&quot;font-weight&quot; = &quot;normal&quot;, padding = &quot;3px 8px&quot;), textsize = &quot;15px&quot;, direction = &quot;auto&quot;)) %&gt;% addLegend(position = &quot;bottomright&quot;, pal = pal2, values = ctdat$pct_black, title = &quot;% African American&quot;, opacity = 1) m %&gt;% addTiles() ``` ## Easier regular expressions with `RVerbalExpressions` Regular expressions are powerful but take some time and trial-and-error to master. The `RVerbalExpresions` package can be used to more easily generate regular expressions. See the help for `rx()` and associated functions. These examples show two constructions of regular expressions for matching two similar but different URLs. ```{r} library(RVerbalExpressions) # a pattern x &lt;- rx_start_of_line() %&gt;% rx_find(&quot;http&quot;) %&gt;% rx_maybe(&quot;s&quot;) %&gt;% rx_find(&quot;://&quot;) %&gt;% rx_maybe(&quot;www.&quot;) %&gt;% rx_anything_but(&quot; &quot;) %&gt;% rx_end_of_line() # print the expression (x) # search for a pattern in some URLs urls &lt;- c( &quot;http://www.google.com&quot;, &quot;http://staff.washington.edu/phurvitz/csde502_winter_2021/&quot; ) grepl(pattern = x, x = urls) # a different pattern y &lt;- rx_start_of_line() %&gt;% rx_find(&quot;http&quot;) %&gt;% rx_maybe(&quot;s&quot;) %&gt;% rx_find(&quot;://&quot;) %&gt;% rx_find(&quot;www.&quot;) %&gt;% rx_anything_but(&quot; &quot;) %&gt;% rx_end_of_line() # print the expression (y) # search for a pattern in the two URLs, matches one, does not match the other grepl(pattern = y, x = urls) ``` ## Quick copy from Excel (Windows only) Under Windows, it is possible to copy selected cells from an Excel worksheet directly to R. This is not an endorsement for using Excel, but there are some cases in which Excel may be able to produce some quick data that you don&#39;t want to develop in other ways. As a demonstration, you can use [analysis.xlsx](files/words_analysis.xlsx). Download and open the file. Here is shown a selection of cells that was copied. ![](images/week09/excel.png) The code below shows how the data can be copied. ```{r, echo=FALSE} xlsclip &lt;- fst::read.fst(&quot;files/xlsclip.fst&quot;) ``` ```{r, eval=FALSE} xlsclip &lt;- read.table(file = &quot;clipboard&quot;, sep = &quot;\\t&quot;, header = TRUE) xlsclip %&gt;% kable() %&gt;% kable_styling( full_width = FALSE, position = &quot;left&quot; ) ``` ```{r, echo=FALSE} xlsclip %&gt;% kable() %&gt;% kable_styling( full_width = FALSE, position = &quot;left&quot; ) ``` ## Running system commands R can run arbitrary system commands that you would normally run in a terminal or command window. The `system()` function is used to run commands, optionally with the results returned as a character vector. Under Mac and Linux, the usage is quite straightforward, for example, to list files in a specific directory: ``` tempdirfiles &lt;- system(&quot;ls /tmp&quot;, intern = TRUE) ``` Under Windows, it takes a bit of extra code. To do the same requires the prefix `cmd /c` in the `system()` call before the command itself. Also any backslashes in path names need to be specified as double-backslashes for R. ```{r} # R prefers and automatically generates forward slashes # under Windows, path delimiters are backslashes so need to be rendered in R as double backslashes tmpdir &lt;- dirname(tempdir()) %&gt;% str_replace_all(&quot;/&quot;, &quot;\\\\\\\\&quot;) # construct a system command # under Windows cmd &lt;- sprintf(&quot;cmd /c dir %s&quot;, tmpdir) tempdirfiles &lt;- system(command = cmd, intern = TRUE) ``` If you are running other programs or utilities that are executed in a terminal or command window, this can be very helpful. ## Code styling Good code should meet at least the two functional requirements of getting the job done and being able able to read. Code that gets the job done but that is not easy to read will cause problems later when you try to figure out how or why you did something. The [`styler`](https://github.com/r-lib/styler) package can help clean up your code so that it conforms to a specific style such as that in the [tidyverse style guide](https://style.tidyverse.org/). `styler` can be integrated into RStudio for interactive use. It can reformat selected code, an entire file, or an entire project. An example is shown: ![](images/week09/styler_0.1.gif) [`lintr`](https://github.com/jimhester/lintr) is also useful for identifying potential style errors. ## Session information It may be helpful in troubleshooting or complete documentation to report the complete session information. For example, sometimes outdated versions of packages may contain errors. The session information is printed with `sessionInfo()`. ```{r} sessionInfo() ``` ## Comment out Rmd/HTML code To comment out entire parts of your Rmd so they do not appear in your rendered HTML, use HTML comments, which are specified with the delimiters `&lt;!--` and `--&gt;`. ## Source code [09-week09.Rmd](09-week09.Rmd) ```{r comment=&#39;&#39;} cat(readLines(con = &quot;09-week09.Rmd&quot;), sep = &quot;\\n&quot;) ``` "],["zoom.html", "10 Zoom Recordings 10.1 Start Time: Jan 8, 2021 10:27 AM 10.2 Start Time: Jan 22, 2021 10:21 AM 10.3 Start Time: Jan 29, 2021 10:25 AM 10.4 Start Time: Feb 5, 2021 10:28 AM 10.5 Start Time: Feb 12, 2021 10:27 AM 10.6 Start Time: Feb 19, 2021 10:21 AM 10.7 Start Time : Feb 26, 2021 10:29 AM", " 10 Zoom Recordings 10.1 Start Time: Jan 8, 2021 10:27 AM Meeting Recording: https://washington.zoom.us/rec/share/Ah1PgU-1l51k2n2fDyPwOvQCfeMa44-Ntn23A79LJyJ8E7VqwuN7pwH0AzETjFmV.hsK9roKarnnlc5ko 10.2 Start Time: Jan 22, 2021 10:21 AM Meeting Recording: https://washington.zoom.us/rec/share/1iVOz1MATixAK8FavsgmDRXjIjmxug4PcmRpNVMdu_g2ocDV3dkCmKhbVlQ90C4.9mnZZ6jz-sqR7QBk 10.3 Start Time: Jan 29, 2021 10:25 AM Meeting Recording: https://washington.zoom.us/rec/share/aPmtmBFD646imBvu1uW5-OdTEUGnui9uQ90UoWlhlfGIai3ekpkx9eta7ze36ltX.Hh_P5zs-TJVBwR3I 10.4 Start Time: Feb 5, 2021 10:28 AM Meeting Recording: https://washington.zoom.us/rec/share/hOasYyzi5cwwCK9Dn8wZTvC3RLhh0JHD6Xy8YLNET_O5AqaHbR_o9GT37kQwoFG3.cHNVd2u2CYR1BRYN 10.5 Start Time: Feb 12, 2021 10:27 AM Meeting Recording: https://washington.zoom.us/rec/share/37XAthQ2uQ76HI-jiDLe9pM-MxKdiDV8kAfv7F_itTSBD8lcwCS8YxvIe0DyS0RG.DBzpMQ9g3jJydypK 10.6 Start Time: Feb 19, 2021 10:21 AM Meeting Recording: https://washington.zoom.us/rec/share/qArE20DId_TfFuQiQJwFv_dx4h7cRQMH3XCr6RoLOEim604wW66JZzgVp0MezjGe.Ad80c8--5xVeDt4_ 10.7 Start Time : Feb 26, 2021 10:29 AM Meeting Recording: https://washington.zoom.us/rec/share/9kIV26dT8PKX9AgiPDRMYZA2Us-bChZdgHzMgSkQc-4rmlU7hUO-wdRjwczjdSvt.wvEeJ83Y6KqRDOwo "]]
